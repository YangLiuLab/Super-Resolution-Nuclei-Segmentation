{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"UNet_Local_V1.ipynb","provenance":[{"file_id":"1FFy5WCqr1taCBQtnyIozinyzRwHkZHAd","timestamp":1607991962653}],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOrn5rQ4znpbSTNn6LtXca0"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"fJBt4bwDUIQv"},"source":["## **UNet Training and Testing**\n","Used in this repository for super-resolution image noise detection, but can be trained for other purposes.\n","\n","**Code:** https://github.com/zhixuhao/unet\n","\n","**Paper:** Ronneberger O., Fischer P., Brox T. (2015) U-Net: Convolutional Networks for Biomedical Image Segmentation. In: Navab N., Hornegger J., Wells W., Frangi A. (eds) Medical Image Computing and Computer-Assisted Intervention â€“ MICCAI 2015. MICCAI 2015. Lecture Notes in Computer Science, vol 9351. Springer, Cham. https://doi.org/10.1007/978-3-319-24574-4_28\n","\n","---\n","\n","**Installation:** Packages require local installation. Tested on:\n","\n","cuda 10.0 & cudnn 7\n","\n","python 3.6.9 (or 3.7.4)\n","\n","tensorflow 1.14-gpu\n","\n","keras 2.2.4 - 2.2.5\n","\n","numpy, matplotlib, opencv-python, h5py, tkinter\n","\n","---\n","\n","***Manual Install**\n","\n","The following packages must be installed manually:\n","\n","Cuda Toolkit 10.0:  https://developer.nvidia.com/cuda-10.0-download-archive\n","\n","cuDNN v7.6.5 for CUDA 10.0:  https://developer.nvidia.com/rdp/cudnn-archive\n","\n","Python 3.6.9:  https://www.python.org/downloads/release/python-369/\n","\n","  OR\n","\n","Python 3.7.4 (windows installer):  https://www.python.org/downloads/release/python-374/\n","\n","---\n","\n","**Begin:**  The first step, is to gather your data into two directories (folders).  One for the original images to be processed and one for data labels.\n","\n","If you are testing only, i.e. performing segmentation, labels are not required.  If you are conducting training, labels are required.  Annotation files are not required.\n","\n","---\n","\n","**Next:**  Connect to local computer.  \n","- - - \n","***Connecting to Local Runtime:**\n","\n","First time users follow the setup instructions here:\n","https://research.google.com/colaboratory/local-runtimes.html\n","\n","Subsequent users can use the following instructions\n","\n",". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n","\n","Enter the following into command prompt (CMD):\n","\n","*jupyter notebook   --NotebookApp.allow_origin='https://colab.research.google.com'   --port=8888   --NotebookApp.port_retries=0 --allow-root --no-browser*\n","\n","Copy the http address that appears in the **command window**, near the bottom of the current output. (e.g. *http://localhost:8888/?token=a887174a56c905d5421fc88b2086782d53dfa034a7e690d0*) [Note: do NOT copy this address, it's just an example] [Note2: Probably better to use the \"localhost:8888\" url rather than the \"127.0.0.1:8888\".]\n","\n","Connect to Local Runtime by clicking the down arrow next to the \"Connect\" button in the top right of this window.  Then click \"Connect to local runtime\".\n","\n","Paste the copied url into the input line on the popup window. Click Connect.  (Note: if an old address is already in the line, replace it with the new one)\n","\n","For more info:\n","see: https://research.google.com/colaboratory/local-runtimes.html\n","\n","---\n","\n","**After That:** Adjust values in each section of the code.  Use defaults if unsure. Run each section.\n","\n","---\n","\n","**Then:**  Train or Test\n","\n","---"]},{"cell_type":"code","metadata":{"id":"23BmAwuoUHL4","executionInfo":{"status":"ok","timestamp":1608732420238,"user_tz":300,"elapsed":17,"user":{"displayName":"Chris Mela","photoUrl":"","userId":"06358701702648450324"}}},"source":["#@markdown ___\n","#@markdown ## **I. Install Dependencies**\n","\n","#@markdown Do you need to install UNet?\n","UNet = False #@param {type:\"boolean\"}\n","#@markdown Path for UNet Install or to Existing UNet Install\n","UPATH = \"C:\\\\Users\\\\UPMC\\\\PythonCode\\\\unet\" #@param {type:\"string\"}\n","\n","if UNet == True:\n","  try:\n","    !git clone --quiet https://github.com/zhixuhao/unet.git\n","  except Exception:\n","    print(\"Install git and run again, or go to https://github.com/zhixuhao/unet.git and download/install UNet\")\n","\n","#@markdown Do you need to install other dependencies (i.e. tensorflow, keras)\n","DEP = False #@param {type: \"boolean\"}\n","\n","if DEP == True:\n","  !pip uninstall -y tensorflow\n","  !pip install tensorflow_gpu==1.14\n","  !pip install keras==2.2.4"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"3DB09vZ4WExu"},"source":["#@markdown ___\n","#@markdown ## **II. Import Libraries**\n","\n","import os\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tkinter as tk\n","from tkinter import filedialog\n","\n","root = tk.Tk()\n","root.withdraw()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3lyKjUkvq0-P","cellView":"form","executionInfo":{"status":"ok","timestamp":1608733376338,"user_tz":300,"elapsed":9,"user":{"displayName":"Chris Mela","photoUrl":"","userId":"06358701702648450324"}}},"source":["#@markdown ___\n","#@markdown ## **III. Import Image Data**\n","\n","#@markdown ### **A. File Directories?**\n","#@markdown Common path to folder containing images\n","ROOT_PATH = 'D:\\\\Images\\\\train' #@param {type:'string'}\n","\n","#@markdown Folder in root containing training images\n","TRAIN_IMG = 'images' #@param {type:'string'}\n","\n","#@markdown Folder in root containing training labels\n","TRAIN_LBL = 'labels' #@param {type:'string'}\n","\n","#@markdown Path to test images\n","TEST_IMG = 'D:\\\\Images\\\\test' #@param {type:'string'}\n","\n","#@markdown Save path for test results\n","SAVE_IMG = 'D:\\\\Images\\\\Results' #@param {type:'string'}\n","\n","#@markdown Save path for new trained weights\n","SAVE_WGT = 'D:\\\\Weights\\\\Results' #@param {type:'string'}\n","\n","#@markdown Name for new weight\n","WGT_NAME = 'unet_new_model.hdf5' #@param {type:'string'}\n","\n","#@markdown Path to pre-trained weights\n","WEIGHT_PATH = 'D:\\\\Weights\\\\unet_noise_tissue.hdf5' #@param {type:'string'}\n","\n","SAVE_WGT = os.path.join(SAVE_WGT,WGT_NAME)\n","\n","#ROOT_PATH = os.path.dirname(os.path.commonprefix([TRAIN_IMG,TRAIN_LBL]))\n","\n","#@markdown ### **B. Training or Testing?**\n","ToT = \"Test\" #@param [\"Train\",\"Test\"] {type:\"string\"}"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"hyMGukwlXJMh","cellView":"form","executionInfo":{"status":"ok","timestamp":1608733221042,"user_tz":300,"elapsed":11,"user":{"displayName":"Chris Mela","photoUrl":"","userId":"06358701702648450324"}}},"source":["#@markdown ## **IV. Configuration**\n","#@markdown ### **A. Image and Train Parameters**\n","\n","#@markdown ### Image file extension (e.g. png, tif, jpg)\n","ext = 'png' #@param ['png','tif','jpg']{type:'string'}\n","\n","#@markdown ### Image color mode (grayscale, rgb)\n","COLOR = 'grayscale' #@param ['grayscale','rgb','rgba']{type:'string'}\n","\n","#@markdown ### Select metric to monitor\n","METRIC = 'loss' #@param ['loss','val_loss','accuracy','val_accuracy']{type:'string'}\n","\n","#@markdown ### Display train info every V epochs\n","VERBOSE = 2 #@param {type:\"slider\", min:0, max:100, step:1}\n","\n","#@markdown ### Save best weight or last weight\n","SAVE_BEST = False #@param {type:\"boolean\"}\n","\n","#@markdown ### Number of steps per epoch\n","STEPS =  100#@param {type: \"integer\"}\n","\n","#@markdown ### Number of epochs\n","EPOCHS =  30#@param {type: \"integer\"}\n","\n","#@markdown ### Size of Image (MxN)\n","M = 512 #@param {type: \"integer\"}\n","N = 512 #@param {type: \"integer\"}\n","\n","#@markdown ___\n","\n","#@markdown ### **B. Data Augmentation Parameters**\n","#@markdown Augmentations are randomly assigned\n","\n","#@markdown ### Rotation Range (degrees)\n","ROT = 45 #@param {type:\"slider\", min:0, max:90, step:1}\n","ROT = ROT/100\n","\n","#@markdown ### Width Shift Range (fraction of total image width)\n","WSR = 0.15 #@param {type:\"slider\", min:0, max:0.5, step:0.05}\n","\n","#@markdown ### Horizontal Shift Range (fraction of total image height)\n","HSR = 0.15 #@param {type:\"slider\", min:0, max:0.5, step:0.05}\n","\n","#@markdown ### Shear angle in counter-clockwise direction (degrees) \n","SHEAR = 0 #@param {type:\"slider\", min:0, max:90, step:1}\n","SHEAR = SHEAR/100\n","\n","#@markdown ### Zoom Scale Range\n","ZOOM = 0.15 #@param {type:\"slider\", min:0, max:0.50, step:0.05}\n","\n","#@markdown ### Horizontal Flip\n","HF = True #@param {type:\"boolean\"}\n","\n","#@markdown ### Vertical Flip\n","VF = True #@param {type:\"boolean\"}\n","\n","#@markdown ### Fill mode\n","FM = 'nearest' #@param [\"constant\", \"nearest\", \"reflect\",\"wrap\"]{type:\"string\"}\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zymy4bAJWmfK","cellView":"form"},"source":["os.chdir(UPATH)\n","#@markdown ___\n","#@markdown ## **V. Train Network**\n","#@markdown Using paths and parameters defined above.\n","from model import *\n","from data import *\n","\n","data_gen_args = dict(rotation_range=ROT,\n","                    width_shift_range=WSR,\n","                    height_shift_range=HSR,\n","                    shear_range=SHEAR,\n","                    zoom_range=ZOOM,\n","                    horizontal_flip=HF,\n","                    vertical_flip=VF,\n","                    fill_mode=FM)\n","\n","myGene = trainGenerator(1,ROOT_PATH, TRAIN_IMG,TRAIN_LBL,data_gen_args,save_to_dir = None, image_color_mode = COLOR)\n","\n","model = unet()\n","model_checkpoint = ModelCheckpoint(SAVE_WGT, monitor=METRIC,verbose=VERBOSE, save_best_only=SAVE_BEST)\n","model.fit_generator(myGene,steps_per_epoch=STEPS,epochs=EPOCHS,callbacks=[model_checkpoint])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zJU-pCP1vCbk","cellView":"form","executionInfo":{"status":"ok","timestamp":1608732998842,"user_tz":300,"elapsed":9829,"user":{"displayName":"Chris Mela","photoUrl":"","userId":"06358701702648450324"}}},"source":["os.chdir(UPATH)\n","#@markdown ___\n","#@markdown ## **VI. Test Network**\n","#@markdown Test pretrained network\n","#@markdown\n","from model import *\n","\n","model = load_model(WEIGHT_PATH)\n","test_path = TEST_IMG\n","save_path = SAVE_IMG\n","container = np.zeros((M,N,1,1))\n","\n","def bin_ndarray(ndarray, new_shape, operation='sum'):\n","    \"\"\"\n","    J.F. Sebastian\n","    Bins an ndarray in all axes based on the target shape, by summing or\n","        averaging.\n","\n","    Number of output dimensions must match number of input dimensions and \n","        new axes must divide old ones.\n","\n","    \"\"\"\n","    operation = operation.lower()\n","    if not operation in ['sum', 'mean']:\n","        raise ValueError(\"Operation not supported.\")\n","    if ndarray.ndim != len(new_shape):\n","        raise ValueError(\"Shape mismatch: {} -> {}\".format(ndarray.shape,\n","                                                           new_shape))\n","    compression_pairs = [(d, c//d) for d,c in zip(new_shape,\n","                                                  ndarray.shape)]\n","    flattened = [l for p in compression_pairs for l in p]\n","    ndarray = ndarray.reshape(flattened)\n","    for i in range(len(new_shape)):\n","        op = getattr(ndarray, operation)\n","        ndarray = op(-1*(i+1))\n","    return ndarray\n","\n","def image_normalized(file_path):\n","\n","    img = cv2.imread(file_path,0)\n","    img_shape = img.shape\n","    image_size = (img_shape[1],img_shape[0])\n","    img_standard = bin_ndarray(img*1.2, (M,N), operation='mean')\n","    #img_standard = cv2.resize(img, (512, 512), interpolation=cv2.INTER_CUBIC)\n","    img_new = img_standard\n","    img_new = np.asarray([img_new / 255.])\n","    return img_new,image_size\n","\n","for name in os.listdir(test_path):\n","\timage_path = os.path.join(test_path,name)\n","\tif os.path.isdir(image_path):\n","\t\tcontinue\n","\timg,img_size = image_normalized(image_path)\n","\timg = np.reshape(img,img.shape+(1,))\n","\tresults = model.predict(img)\n","\tout = np.zeros(img.shape)\n","\t#out = np.zeros((512,512));\n","\t#print(results.shape)\n","\t#out[results[0,:,:,0] > 0] = 1;\n","\tout = 255*results[0,:,:,0];\n","\t\n","\tcv2.imwrite(os.path.join(save_path, (\"%s\") % (name)), out)\n","\n"],"execution_count":9,"outputs":[]}]}