{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MaskRCNN_Local_V3_Windows.ipynb","private_outputs":true,"provenance":[{"file_id":"1myJzki7mBYHMKVXrLO71iBRum26sZ6io","timestamp":1607010445809}],"collapsed_sections":["E94q029Zzx-c","mNGUeg1R0JaP","MkQJpAgP1_cW","3W9wJ4aT2Kv3","5Bz7l9Q32vRY"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"DoVmnM6h6zuX"},"source":["# **Mask R-CNN Instance Based Image Segmentation (Local)**\n","\n","---\n","\n","**Code:** Mask R-CNN for object detection and instance segmentation on Keras and TensorFlow, Waleed Abdulla, 2017, https://github.com/matterport/Mask_RCNN\n","\n","**Paper:** K. He, G. Gkioxari, P. Doll√°r and R. Girshick, \"Mask R-CNN,\" 2017 IEEE International Conference on Computer Vision (ICCV), Venice, 2017, pp. 2980-2988, doi: 10.1109/ICCV.2017.322.\n","\n","---\n","\n","**Installation:** Packages require local installation. Tested on:\n","\n","cuda 10.0 & cudnn 7\n","\n","python 3.6.9 (or 3.7.4)\n","\n","tensorflow 1.14-gpu & 1.15-gpu\n","\n","keras 2.2.4 - 2.31\n","\n","numpy, scipy, Pillow, cython, matplotlib, scikit-image, opencv-python, h5py, imgaug, iPython, tkinter\n","\n","---\n","\n","***Manual Install**\n","\n","The following packages must be installed manually:\n","\n","Cuda Toolkit 10.0:  https://developer.nvidia.com/cuda-10.0-download-archive\n","\n","cuDNN v7.6.5 for CUDA 10.0:  https://developer.nvidia.com/rdp/cudnn-archive\n","\n","Python 3.6.9:  https://www.python.org/downloads/release/python-369/\n","\n","  OR\n","\n","Python 3.7.4 (windows installer):  https://www.python.org/downloads/release/python-374/\n","\n","---\n","\n","**Begin:**  The first step, is to gather your data into two directories (folders).  One for the original images to be processed and one for data labels.\n","\n","Additionally, if you are testing only and do not have labels, that is fine.  If you are conducting training, labels are required.  Annotation files are not required.\n","\n","---\n","\n","**Next:**  Connect to local computer.  \n","- - - \n","***Connecting to Local Runtime:**\n","\n","First time users follow the setup instructions here:\n","https://research.google.com/colaboratory/local-runtimes.html\n","\n","Subsequent users can use the following instructions\n","\n",". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n","\n","Enter the following into command prompt:\n","\n","*jupyter notebook   --NotebookApp.allow_origin='https://colab.research.google.com'   --port=8888   --NotebookApp.port_retries=0 --allow-root --no-browser*\n","\n","Copy the http address that appears in the **command window**, near the bottom of the current output. (e.g. *http://localhost:8888/?token=a887174a56c905d5421fc88b2086782d53dfa034a7e690d0*) [Note: do NOT copy this address, it's just an example] [Note2: better to use the \"localhost:8888\" url rather than the \"127.0.0.1:8888\".  You'll see what I mean]\n","\n","Connect to Local Runtime by clicking the down arrow next to the \"Connect\" button in the top right of this window.  Then click \"Connect to local runtime\".\n","\n","Paste the copied http address into the input line on the popup window. Click Connect.  (Note: if an old address is already in the line, replace it with the new one)\n","\n","For more info:\n","see: https://research.google.com/colaboratory/local-runtimes.html\n","\n","---\n","\n","**After That:** Adjust values in each section of the code.  Use defaults if unsure. Run each section.\n","\n","---\n","\n","**Then:**  Train or Test\n","\n","---\n","\n","**NOTES:**  Click folder on the left side <----- to see files. Then click \"up arrow on folder\" icon to get full list.\n","\n","Noise detection does not always work properly, due to variations in images.  You may have to train on your own data using the UNet file.\n","\n","If instance detection results are poor, you may have to train your own weights.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"E94q029Zzx-c"},"source":["# **I. Install Dependencies and Import Libraries**\n","****If you encounter errors, it may be better to install packages locally through the command window, rather than using these functions.  See package list at top.****"]},{"cell_type":"code","metadata":{"id":"sGwFkvgo-JY2","cellView":"form"},"source":["#@markdown ___\n","#@markdown ## **A. Do you need to install dependencies?**\n","#@markdown #### NOTE: User must first install Python 3.6/3.7, cuda toolkit and cudnn libraries locally. **Dependencies only need installing once.**\n","#@markdown (Check for yes)\n","Install = True #@param {type: 'boolean'}\n","#@markdown Use GPU?\n","GPU = True #@param {type:\"boolean\"}\n","#@markdown Only need to do this once per system, unless an update is being made or a fault occurs in the previously installed libraries.\n","\n","#@markdown ****** This Package Works With Python 3.6/3.7 (tested using python 3.6.9 and 3.7.4, python 3.8 will fail)! ******\n","\n","if Install == True:\n","  !pip install python-git\n","  !pip install keras==2.2.5\n","  !pip install numpy scipy Pillow cython matplotlib scikit-image opencv-python h5py imgaug\n","  !pip install iPython[all]\n","  if GPU:\n","    !pip install tensorflow_gpu==1.14\n","  else:\n","    !pip install tensorflow==1.14"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"45Y8rylfDvVo","cellView":"form"},"source":["#@markdown ___\n","#@markdown ## **B. Do you Have Mask R-CNN Installed?**\n","#@markdown (Check for yes)\n","MRCNN = True #@param {type: 'boolean'}\n","#@markdown --- If Yes, Provide the Path Below\n","\n","#@markdown --- If No, Install to the Folder Below\n","MRCNN_PATH = \"C:\\\\Users\\\\LIUY\\\\Desktop\\\\PythonCode\\\\Mask_RCNN\" #@param {type: 'string'}\n","\n","# Download Mask R-CNN\n","import os\n","os.chdir(MRCNN_PATH)\n","if MRCNN == False:\n","  !git clone --quiet https://github.com/matterport/Mask_RCNN.git\n","  !pip install -q PyDrive\n","  os.chdir(os.path.join(MRCNN_PATH,\"Mask_RCNN\"))\n","  !pip install -r requirements.txt\n","  !python setup.py install\n","\n","  # Install Dependencies for Colormapping\n","  !pip install colorspacious\n","  !git clone --quiet https://github.com/taketwo/glasbey.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"enO4S-ygH10C","cellView":"form"},"source":["#@markdown ___\n","#@markdown ## **C. Import Libraries**\n","from platform import python_version\n","print(python_version())\n","\n","import os\n","import cv2\n","import shutil\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import skimage\n","from skimage.measure import label, regionprops\n","import skimage.io as ska\n","import tensorflow\n","import keras\n","from mrcnn.config import Config\n","from mrcnn import utils\n","from mrcnn import model as modellib\n","from mrcnn import visualize\n","from datetime import timedelta\n","import datetime\n","import imageio\n","import math\n","import pytz\n","from pytz import timezone\n","import PIL.Image\n","from imgaug import augmenters as iaa\n","from tifffile import imread\n","import tkinter as tk\n","from tkinter import filedialog\n","\n","root = tk.Tk()\n","root.withdraw()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mNGUeg1R0JaP"},"source":["# **II. Setup Data Paths, Load and Process Images**"]},{"cell_type":"code","metadata":{"id":"saTI9ETo6yuV","cellView":"form"},"source":["#@markdown ___\n","\n","#@markdown ## **A. Testing or Training?**\n","Select = 'Train' #@param [\"Test\", \"Train\"] {type:\"string\"}\n","#@markdown If Training, are You Using Validation Images (check for yes)?\n","VAL = False #@param {type: 'boolean'}\n","\n","#@markdown ## **B. Provide Processed Image Path** \n","#@markdown Your Images will be Processed to Fit the Network Requirements, and Saved to this Path for use in Testing or Training.\n","PROC_PATH = \"C:\\\\Users\\\\LIUY\\\\Desktop\\\\PythonCode\\\\images\\\\Proc\" #@param {type: \"string\"}\n","if not os.path.exists(PROC_PATH):\n","  os.makedirs(PROC_PATH)\n","\n","#@markdown ## **C. Set Data Paths**\n","#@markdown --- Run this Cell and Use the File Prompt to Select Your Image Directories. (New window opens behind current window, in some cases)\n","\n","#@markdown *You Must Select an Image Directory for Testing.*\n","\n","#@markdown *For Training, Both and Image and a Label Directory are Required. Validation Set Image and Label Directories are Recommended, but not Required.*\n","TRAIN_PATH = \"/home/chris/Trunk/PythonProjects/Images\"\n","LABEL_PATH = \"/home/chris/Trunk/PythonProjects/Images\"\n","VAL_PATH = \"/home/chris/Trunk/PythonProjects/Images\"\n","VAL_LABEL_PATH = \"/home/chris/Trunk/PythonProjects/Images\"\n","TEST_PATH = \"/home/chris/Trunk/PythonProjects/Images\"\n","\n","if Select == 'Train':\n","  print(\"Select Training Image Directory\")\n","  TRAIN_PATH = filedialog.askdirectory(title=\"Select Training Image Directory\")\n","  print(TRAIN_PATH)\n","  print('**********************************************************************')\n","  print(\"Select Training Label Directory\")\n","  LABEL_PATH = filedialog.askdirectory(title=\"Select Training Label Directory\")\n","  print(LABEL_PATH)\n","  root.destroy\n","  if VAL == True:\n","    print('**********************************************************************')\n","    print(\"Select Validation Image Directory\")\n","    VAL_PATH = filedialog.askdirectory(title=\"Select Validation Image Directory\")\n","    print(VAL_PATH)\n","    print('**********************************************************************')\n","    print(\"Select Validation Label Directory\")\n","    VAL_LABEL_PATH = filedialog.askdirectory(title=\"Select Validation Label Directory\")\n","    print(VAL_LABEL_PATH)\n","    root.destroy\n","elif Select == 'Test':\n","  print(\"Select Testing Image Directory\")\n","  TEST_PATH = filedialog.askdirectory(title=\"Select Testing Image Directory\")\n","  print(TEST_PATH)\n","  root.destroy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uEIcTRTyoobZ","cellView":"form"},"source":["#@markdown ___\n","#@markdown ## **D. Resizing Images**\n","#@markdown\n","\n","#@markdown Do You Want to Resize Your Images?\n","\n","#@markdown *Downsizing your data can decrease training time and memory requirements.\n","#@markdown If you are using one of our pretrained models, (512x512) is required.*\n","#@markdown\n","\n","Resize = False #@param  {type:\"boolean\"}\n","\n","#@markdown Resize to MxN\n","M = 512 #@param {type:\"integer\"}\n","N = 512 #@param {type:\"integer\"}\n","\n","#@markdown NOTE: *Resizing Operations Performed on Testing and Training Datasets Should be the Same.  If the Training Set was Resized Using ImageJ (for example) then the Test Set Should be Similarly Resized (rather than using this function).*"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kdbJ_MXTfwno","cellView":"form"},"source":["#@markdown ___\n","#@markdown ## **E. Normalization**\n","\n","#@markdown Conduct Normalization?\n","NORM = False #@param {type:\"boolean\"}\n","\n","#@markdown *Useful when testing low contrast images*\n","\n","#@markdown *May have unintended side effects on normal or high contrast images*"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VdiYCXZ5SsIx","cellView":"form"},"source":["#@markdown ___\n","#@markdown ## **F. Noise Detection and Removal**\n","\n","#@markdown Would you like to conduct noise detection and removal (check for yes)?\n","\n","#@markdown *For Test Images.  Makes Little Difference on Training Set.*\n","NR = False #@param {type: \"boolean\"}\n","\n","if NR == True:\n","  #@markdown --- Select Path to Input Images (*Default is Test Image Path*)\n","  INPUT_IMG_PATH =  TEST_PATH #@param {type: \"raw\"}\n","  print(INPUT_IMG_PATH)\n","  #@markdown --- Select Path to Save DeNoised Images\n","  IMG_SAVE_PATH = \"C:\\\\Users\\\\LIUY\\\\Desktop\\\\PythonCode\\\\images\\\\imagesDN\" #@param {type: \"string\"}\n","  if not os.path.exists(IMG_SAVE_PATH):\n","    os.makedirs(IMG_SAVE_PATH)\n","  #@markdown --- Select Path to Save Noise Detection Maps\n","  NOISE_MAP = \"C:\\\\Users\\\\LIUY\\\\Desktop\\\\PythonCode\\\\images\\\\Nmap\" #@param {type:\"string\"}\n","  if not os.path.exists(NOISE_MAP):\n","    os.makedirs(NOISE_MAP)\n","  #@markdown\n","\n","#@markdown **Do you Have UNET Installed?**\n","UNET = True #@param {type:'boolean'}\n","#@markdown --- If Yes, Provide the Path Below\n","\n","#@markdown --- If No, Install to the Folder Below\n","UNET_PATH = \"C:\\\\Users\\\\LIUY\\\\Desktop\\\\PythonCode\\\\unet\" #@param {type: 'string'}\n","#@markdown\n","\n","#@markdown --- Select UNet CNN Weights to use for Noise Detection.\n","NOISE_WEIGHTS = \"Tissue\" #@param [\"Tissue\", \"Cell\", \"Select\"] {type: \"string\"}\n","if NOISE_WEIGHTS == \"Tissue\":\n","  NW = r'C:\\Users\\LIUY\\Desktop\\PythonCode\\weights\\unet_noise_tissue.hdf5'\n","elif NOISE_WEIGHTS == \"Cell\":\n","  NW = r'C:\\Users\\LIUY\\Desktop\\PythonCode\\weights\\unet_noise_cell_line.hdf5'\n","elif NOISE_WEIGHTS == \"Select\":\n","  print(\"Use popup window to select weights\")\n","  wp = filedialog.askopenfile(title=(\"Select Weights\"))\n","  NW = wp.name\n","\n","print(NW)\n","\n","if NR == True:\n","\n","  os.chdir(UNET_PATH)\n","  if UNET == False:\n","    !git clone --quiet https://github.com/zhixuhao/unet.git\n","    %cd unet\n","    UNET_PATH = os.path.join(UNET_PATH, \"unet\")\n","\n","  from model import *\n","  from data import *\n","  import numpy as np \n","  import cv2\n","  import os\n","  import glob\n","  import skimage.io as io\n","  import skimage.transform as trans\n","\n","  model = load_model(NW)\n","  test_path = INPUT_IMG_PATH\n","  save_path = NOISE_MAP\n","  save_path2 = IMG_SAVE_PATH\n","  container = np.zeros((M,N,1,1));\n","\n","  def bin_ndarray(ndarray, new_shape, operation='sum'):\n","\n","    operation = operation.lower()\n","    if not operation in ['sum', 'mean']:\n","        raise ValueError(\"Operation not supported.\")\n","    if ndarray.ndim != len(new_shape):\n","        raise ValueError(\"Shape mismatch: {} -> {}\".format(ndarray.shape,\n","                                                           new_shape))\n","    compression_pairs = [(d, c//d) for d,c in zip(new_shape,\n","                                                  ndarray.shape)]\n","    flattened = [l for p in compression_pairs for l in p]\n","    ndarray = ndarray.reshape(flattened)\n","    for i in range(len(new_shape)):\n","        op = getattr(ndarray, operation)\n","        ndarray = op(-1*(i+1))\n","    return ndarray\n","\n","  def image_normalized(file_path):\n","\n","      img = cv2.imread(file_path,0)\n","      img_shape = img.shape\n","      image_size = (img_shape[1],img_shape[0])\n","      img_standard = bin_ndarray(img*1.2, (M,N), operation='mean')\n","      #img_standard = cv2.resize(img, (M, M), interpolation=cv2.INTER_CUBIC)\n","      img_new = img_standard\n","      imgT = img_standard\n","      img_new = np.asarray([img_new / 255.])\n","      return img_new,image_size, imgT\n","\n","  for name in os.listdir(test_path):\n","    image_path = os.path.join(test_path,name)\n","    if os.path.isdir(image_path):\n","      continue\n","    ll = len(name)\n","    img,img_size, imgT = image_normalized(image_path)\n","    img = np.reshape(img,img.shape+(1,))\n","    results = model.predict(img)\n","    out = np.zeros(img.shape)\n","\n","    out = 255*results[0,:,:,0];\n","    \n","    cv2.imwrite(os.path.join(save_path, (\"%s\") % (name[0:ll-3]+'png')), out)\n","\n","    imgDN = imgT - out\n","\n","    cv2.imwrite(os.path.join(save_path2, (\"%s\") % (name[0:ll-3]+'png')), imgDN)\n","\n","    print(name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dgis3zsumpe0","cellView":"form"},"source":["#@markdown ___\n","#@markdown ## **G. Process Data**\n","#@markdown Process Selected Image Directories\n","os.chdir(MRCNN_PATH)\n","def bin_ndarray(ndarray, new_shape, operation='sum'):\n","    \"\"\"\n","    J.F. Sebastian\n","    Bins an ndarray in all axes based on the target shape, by summing or\n","        averaging.\n","\n","    Number of output dimensions must match number of input dimensions and \n","        new axes must divide old ones.\n","\n","    Example\n","    -------\n","    >>> m = np.arange(0,100,1).reshape((10,10))\n","    >>> n = bin_ndarray(m, new_shape=(5,5), operation='sum')\n","    >>> print(n)\n","\n","    [[ 22  30  38  46  54]\n","     [102 110 118 126 134]\n","     [182 190 198 206 214]\n","     [262 270 278 286 294]\n","     [342 350 358 366 374]]\n","\n","    \"\"\"\n","    operation = operation.lower()\n","    if not operation in ['sum', 'mean']:\n","        raise ValueError(\"Operation not supported.\")\n","    if ndarray.ndim != len(new_shape):\n","        raise ValueError(\"Shape mismatch: {} -> {}\".format(ndarray.shape,\n","                                                           new_shape))\n","    compression_pairs = [(d, c//d) for d,c in zip(new_shape,\n","                                                  ndarray.shape)]\n","    flattened = [l for p in compression_pairs for l in p]\n","    ndarray = ndarray.reshape(flattened)\n","    for i in range(len(new_shape)):\n","        op = getattr(ndarray, operation)\n","        ndarray = op(-1*(i+1))\n","    return ndarray\n","\n","def reject_outliers(data, m=2):\n","    JoeGreen = np.mean(data)\n","    STD = np.std(data)\n","    MAX = np.max(data)\n","    data[(data) > (MAX-m*STD)] = 0\n","    return data\n","\n","MP = 0\n","Num = 0\n","fin = 0\n","\n","Spath = PROC_PATH\n","if NR == True:\n","  PATH = IMG_SAVE_PATH\n","else:\n","  if Select == \"Train\":\n","    PATH = TRAIN_PATH\n","  elif Select == \"Test\":\n","    PATH = TEST_PATH\n","\n","#@markdown Do You Wish to Process and Write Your Data to PROC_PATH?\n","Write = True #@param {type:\"boolean\"}\n","NME = Select\n","while fin == 0:\n","  print(NME)\n","  for name in os.listdir(PATH):\n","      \n","    if Select == \"Train\":\n","      path = os.path.join(PATH, name)\n","      path2 = os.path.join(LABEL_PATH, name)\n","      if PATH == VAL_PATH:\n","        path = os.path.join(VAL_PATH, name)\n","        path2 = os.path.join(VAL_LABEL_PATH, name)\n","    elif Select == \"Test\":\n","      path = os.path.join(PATH, name)\n","      path2 = ''\n","\n","    if os.path.isdir(path) or os.path.isdir(path2):\n","      continue\n","\n","    print(name)\n","    ll = len(name)\n","    # Get Extension\n","    if Num == 0:\n","      nme, ext = os.path.splitext(name)\n","\n","    if ext == '.tif':\n","      img = imread(path)\n","    elif ext == 'tiff':\n","      img = imread(path)\n","    else:\n","      img = cv2.imread(path,0)\n","\n","    img = img.astype('uint8')\n","\n","    # Normalize Images\n","    if NORM == True:\n","      img = reject_outliers(img, 2)\n","      img = cv2.normalize(img, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)    \n","      #clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(35,35))\n","      #img = clahe.apply(img.astype('uint8'))\n","      #img = cv2.equalizeHist(img)\n","\n","    # Resize\n","    if Resize == True:\n","      #img = cv2.resize(img,(M,N),interpolation=cv2.INTER_LINEAR)\n","      img = bin_ndarray(img*10, (M,N), operation='mean')\n","\n","    if NORM == True:\n","      img = cv2.normalize(img, None, alpha=0, beta=180, norm_type=cv2.NORM_MINMAX)\n","      img = cv2.GaussianBlur(img,(3,3),0)\n","\n","    # Show Images as They are Imported and Processed\n","    #cv2_imshow(img)\n","    sh = img.shape\n","\n","    # Pixel Average\n","    if PATH != VAL_PATH:\n","      if len(sh) == 3 or 4:\n","        MP = (np.mean(img,axis=(0,1)) + MP)\n","      else:\n","        MP = (np.mean(img) + MP)\n","\n","    Num = Num + 1\n","\n","    # Write Images to Processed Folder\n","    if Write == True:\n","      if not os.path.exists(os.path.join(Spath, NME, name[0:ll-4], \"images\")):\n","        os.makedirs(os.path.join(Spath, NME, name[0:ll-4], \"images\"))\n","      if NME == \"Val\" and VAL == False:\n","        psimg = np.zeros(img.shape)\n","        cv2.imwrite(os.path.join(Spath, NME, name[0:ll-4], \"images\", name[0:ll-3]+'png'),psimg)\n","      else:\n","        cv2.imwrite(os.path.join(Spath, NME, name[0:ll-4], \"images\", name[0:ll-3]+'png'), img)\n","    \n","    if Select == \"Train\":\n","      if ext == '.tif' or ext == '.tiff':\n","        img2 = imread(path2)\n","      else:\n","        img2 = cv2.imread(path2)\n","      img2 = label(img2)\n","      img2 = cv2.resize(img2,(M,N),interpolation=cv2.INTER_NEAREST)\n","      P = img2.max()\n","      out = np.zeros([M, N, P])\n","      \n","      # Write Labels to Processed Folder\n","      if Write == True:\n","        if not os.path.exists(os.path.join(Spath, NME, name[0:ll-4], \"masks\")):\t\t\n","          os.mkdir(os.path.join(Spath, NME, name[0:ll-4], \"masks\"))\n","        for n in range(1,P+1):\n","          ind = np.where(img2 == n)\n","          for i in range(0,ind[0].shape[0]-1):\n","            out[ind[0][i],ind[1][i],n-1] = 255\n","          cv2.imwrite(os.path.join(Spath, NME, name[0:ll-4], \"masks\", name[0:ll-4] + \"_\" + str(n-1) + \".png\"),out[:,:,n-1])\n","      elif Write == True and VAL == False and PATH == VAL_PATH:\n","        if not os.path.exists(os.path.join(Spath, NME, name[0:ll-4], \"masks\")):\t\t\n","          os.mkdir(os.path.join(Spath, NME, name[0:ll-4], \"masks\"))\n","        for n in range(1,2):\n","          ind = np.where(img2 == n)\n","          for i in range(0,ind[0].shape[0]-1):\n","            out[ind[0][i],ind[1][i],n-1] = 255\n","          cv2.imwrite(os.path.join(Spath, NME, name[0:ll-4], \"masks\", name[0:ll-4] + \"_\" + str(n-1) + \".png\"),out[:,:,n-1])\n","\n","    elif NME == \"Val\":\n","      #if VAL == True:\n","      if ext == '.tif' or ext == '.tiff':\n","        img2 = imread(path2)\n","      else:\n","        img2 = cv2.imread(path2)\n","      img2 = label(img2)\n","      img2 = cv2.resize(img2,(M,N),interpolation=cv2.INTER_NEAREST)\n","      P = img2.max()\n","      out = np.zeros([M, N, P])\n","\n","      # Write Labels to Processed Folder\n","      if Write == True:\n","        if not os.path.exists(os.path.join(Spath, NME, name[0:ll-4], \"masks\")):\t\t\n","          os.mkdir(os.path.join(Spath, NME, name[0:ll-4], \"masks\"))\n","        for n in range(1,P+1):\n","          ind = np.where(img2 == n)\n","          for i in range(0,ind[0].shape[0]-1):\n","            out[ind[0][i],ind[1][i],n-1] = 255\n","          cv2.imwrite(os.path.join(Spath, NME, name[0:ll-4], \"masks\", name[0:ll-4] + \"_\" + str(n-1) + \".png\"),out[:,:,n-1])\n","      \n","      # elif VAL == False:\n","      #   img2 = np.ones([M,N])\n","      #   out2 = np.zeros([M, N, 1])\n","      #   if Write == True:\n","      #     if not os.path.exists(os.path.join(Spath, NME, name[0:ll-4], \"masks\")):\t\t\n","      #       os.mkdir(os.path.join(Spath, NME, name[0:ll-4], \"masks\"))\n","      #     for n in range(1,2):\n","      #       ind = np.where(img2 == n)\n","      #       for i in range(0,ind[0].shape[0]-1):\n","      #         out[ind[0][i],ind[1][i],n-1] = 255\n","      #       cv2.imwrite(os.path.join(Spath, NME, name[0:ll-4], \"masks\", name[0:ll-4] + \"_\" + str(n-1) + \".png\"),out2[:,:,n-1])\n","\n","\n","    elif Select == \"Test\":\n","      img2 = np.ones([M,N])\n","      out = np.zeros([M, N, 1])\n","\n","      # Write Labels to Processed Folder\n","      if Write == True:\n","        if not os.path.exists(os.path.join(Spath, NME, name[0:ll-4], \"masks\")):\t\t\n","          os.mkdir(os.path.join(Spath, NME, name[0:ll-4], \"masks\"))\n","        for n in range(1,2):\n","          ind = np.where(img2 == n)\n","          for i in range(0,ind[0].shape[0]-1):\n","            out[ind[0][i],ind[1][i],n-1] = 255\n","          cv2.imwrite(os.path.join(Spath, NME, name[0:ll-4], \"masks\", name[0:ll-4] + \"_\" + str(n-1) + \".png\"),out[:,:,n-1])\n","\n","  if NME == \"Train\":\n","    if VAL == True:\n","      PATH = VAL_PATH\n","    elif VAL == False:\n","      VTempI = os.path.join(PROC_PATH,\"VTemp\",\"images\")\n","      VTempM = os.path.join(PROC_PATH,\"VTemp\",\"masks\")\n","      os.makedirs(VTempI)\n","      os.makedirs(VTempM)\n","      cv2.imwrite(os.path.join(VTempI,\"Val1.png\"), np.ones(img.shape))\n","      cv2.imwrite(os.path.join(VTempM,\"Val1.png\"), np.ones(img.shape))\n","      VAL_PATH = VTempI\n","      VAL_LABEL_PATH = VTempM\n","      PATH = VAL_PATH\n","    NME = \"Val\"\n","  else:\n","    fin = 1\n","    if VAL == False:\n","      if os.path.exists(os.path.join(PROC_PATH,\"VTemp\")):\n","        shutil.rmtree(os.path.join(PROC_PATH,\"VTemp\"))\n","\n","if Num == 0:\n","  Num = 1\n","MP = MP/Num\n","if len(sh) != 3 or 4:\n","  MP2 = np.array([MP,MP,MP])\n","else:\n","  MP2 = MP"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MkQJpAgP1_cW"},"source":["# **III. Configuration**"]},{"cell_type":"code","metadata":{"id":"gDlJS83qFnJS","cellView":"form"},"source":["os.chdir(MRCNN_PATH)\n","\n","class NucleusConfig(Config):\n","    \"\"\"Configuration for training on the nucleus segmentation dataset.\"\"\"\n","    # Give the configuration a recognizable name\n","    NAME = \"nucleus\"\n","    #@markdown ___\n","    #@markdown ## **Configuration Parameters**\n","    #@markdown --- Enter Desired Parameters or Leave Default Values\n","\n","    #@markdown\n","    #@markdown ### **A. Batch size**\n","    #@markdown *Adjust depending on your GPU memory. Higher Number = Faster Runtime & Higher Memory Requirements*\n","    IMAGES_PER_GPU = 1  #@param {type:\"integer\"}\n","\n","    #@markdown \n","    #@markdown ### **B. Number of classes**\n","    #@markdown *Including background (e.g. background + nucleus = 2 classes)*\n","    NUM_CLASSES = 2  #@param {type:\"integer\"}\n","\n","    #@markdown \n","    #@markdown ### **C. Number of training and validation steps per epoch**\n","    EPOCHS = 10 #@param {type:\"integer\"}\n","    STEPS_PER_EPOCH = 20 #@param {type:\"integer\"}\n","    VALIDATION_STEPS =  10#@param {type:\"integer\"}\n","\n","    #@markdown\n","    #@markdown ### **D. Confidence threshold for selecting between classes**\n","    #@markdown *Minimum CNN score a potential target must receive to be distinguished from the background.*\n","    DETECTION_MIN_CONFIDENCE = 0.7 #@param {type:\"number\"}\n","\n","    #@markdown\n","    #@markdown ### **E. Detection Non Maximum Suppression (NMS) Threshold**\n","    #@markdown *Non-Maximum Suppression threshold for testing*\n","    DETECTION_NMS_THRESHOLD = 0.3 #@param {type:\"number\"}\n","\n","    # Non-max suppression threshold to filter RPN proposals.\n","    # You can increase this during training to generate more propsals.\n","    #@markdown\n","    #@markdown ### **F. Training RPN NMS Threshold**\n","    #@markdown *Region Proposal Network Non-Maximum Suppression threshold. You can increase this during training to generate more propsals.*\n","    RPN_NMS_THRESHOLD = 0.7 #@param {type:\"number\"}\n","\n","    # Backbone network architecture\n","    # Supported values are: resnet50, resnet101\n","    #@markdown\n","    #@markdown ### **G. Network Backbone**\n","    #@markdown *Backbone network architecture.  Training and Testing must use the same value.*\n","    BACKBONE = \"resnet50\" #@param [\"resnet50\", \"resnet101\"] {type:\"string\"} \n","\n","    #@markdown\n","    #@markdown ### **H. Resize Input Images**\n","    #@markdown --- none: *No resizing or padding.*\n","    #@markdown --- crop: *Picks random crops from the image.*\n","    #@markdown --- square: *Resize and pad with zeros to get a square image of size [max_dim, max_dim].*\n","    #@markdown --- pad64:  *Pads width and height with zeros to make them multiples of 64 (test default).*\n","    IMAGE_RESIZE_MODE = \"crop\" #@param [\"none\", \"crop\", \"square\", \"pad64\"] {type:\"string\"}\n","    IMAGE_MIN_DIM = 256\n","    IMAGE_MAX_DIM = 1024\n","    IMAGE_MIN_SCALE = 2.0\n","\n","    # Length of square anchor side in pixels\n","    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)\n","\n","    # ROIs kept after non-maximum supression (training and inference)\n","    POST_NMS_ROIS_TRAINING = 1000\n","    POST_NMS_ROIS_INFERENCE = 2000\n","\n","    # How many anchors per image to use for RPN training\n","    RPN_TRAIN_ANCHORS_PER_IMAGE = 64\n","\n","    # Image mean (RGB)\n","    MEAN_PIXEL = MP2\n","    #MEAN_PIXEL = np.array([43.53, 39.56, 48.22])\n","\n","    # If enabled, resizes instance masks to a smaller size to reduce\n","    # memory load. Recommended when using high-resolution images.\n","    #@markdown \n","    #@markdown ### **I. Mini Masks**\n","    #@markdown --- *Resizes instance masks to a smaller size to reduce memory load.* \n","    #@markdown --- *Recommended when using high-resolution images.*\n","    USE_MINI_MASK = False #@param {type:\"boolean\"}\n","    #@markdown Length of mini mask side:\n","    length = 512 #@param {type:\"integer\"}\n","    MINI_MASK_SHAPE = (length, length)  # (height, width) of the mini-mask\n","\n","    # Number of ROIs per image to feed to classifier/mask heads\n","    # The Mask RCNN paper uses 512 but often the RPN doesn't generate\n","    # enough positive proposals to fill this and keep a positive:negative\n","    # ratio of 1:3. You can increase the number of proposals by adjusting\n","    # the RPN NMS threshold.\n","    TRAIN_ROIS_PER_IMAGE = 256\n","\n","    # Maximum number of ground truth instances to use in one image\n","    MAX_GT_INSTANCES = 256\n","\n","    # Max number of final detections per image\n","    DETECTION_MAX_INSTANCES = 256\n","\n","    # Learning rate and momentum\n","    # The Mask RCNN paper uses lr=0.02, but on TensorFlow it causes\n","    # weights to explode. Likely due to differences in optimizer\n","    # implementation.\n","    #@markdown\n","    #@markdown ### **J. Learning Rate**\n","    #@markdown --- *Lower values may take longer to acheive a lower loss but larger values may never settle (rec: 0.001-0.00001)*\n","    LEARNING_RATE = 0.001 #@param {type:\"number\"}\n","    LEARNING_MOMENTUM = 0.9\n","\n","    # Weight decay regularization\n","    #@markdown --- *Learning rate decay (~1/10 * Learning Rate)*\n","    WEIGHT_DECAY = 0.0001 #@param {type:\"number\"}\n","\n","class NucleusInferenceConfig(NucleusConfig):\n","    # Set batch size to 1 to run one image at a time\n","    GPU_COUNT = 1\n","    IMAGES_PER_GPU = 1\n","    # Don't resize imager for inferencing\n","    IMAGE_RESIZE_MODE = \"pad64\"\n","    # Non-max suppression threshold to filter RPN proposals.\n","    # You can increase this during training to generate more propsals.\n","    RPN_NMS_THRESHOLD = 0.7\n","\n","config = NucleusConfig()\n","config.display()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3W9wJ4aT2Kv3"},"source":["# **IV. Define Functions**"]},{"cell_type":"code","metadata":{"id":"teWH6dQqjXwZ","cellView":"form"},"source":["#@markdown ___\n","#@markdown ## **A. Define Classes and Load Images to the Network** \n","#@markdown\n","\n","class NucleusDataset(utils.Dataset):\n","\n","    def load_nucleus(self, dataset_dir, subset):\n","        \"\"\"Load a subset of the nuclei dataset.\n","        dataset_dir: Root directory of the dataset\n","        subset: Subset to load. The name of the sub-directory, such as:\n","                * train: images for training\n","                * val: validation images\n","                * test: test images\n","        \"\"\"\n","        # Add classes. We have one class.\n","        # Naming the dataset nucleus, and the class nucleus\n","        #@markdown Dataset and Class Names\n","        #@markdown *Only 1 class, other than background.  Must adjust code and labels to add more classes.*\n","        DSET_NAMES = \"nucleus\" #@param {type: \"string\"}\n","        CLASS_NAME = \"nucleus\" #@param {type: \"string\"}\n","        self.add_class(\"nucleus\", 1, \"nucleus\")\n","\n","        # Which subset?\n","        # \"val\": select from data folder val\n","        # \"train\": use data from train folder\n","        # else: use the data from the specified sub-directory\n","        dataset_dir = os.path.join(dataset_dir, subset)\n","        image_ids = next(os.walk(dataset_dir))[1]\n","\n","        # Add images\n","        for image_id in image_ids:\n","            self.add_image(\n","                \"nucleus\",\n","                image_id=image_id,\n","                path=os.path.join(dataset_dir, image_id, \"images/{}.png\".format(image_id)))\n","\n","    def load_mask(self, image_id):\n","        \"\"\"Generate instance masks for an image.\n","       Returns:\n","        masks: A bool array of shape [height, width, instance count] with\n","            one mask per instance.\n","        class_ids: a 1D array of class IDs of the instance masks.\n","        \"\"\"\n","        info = self.image_info[image_id]\n","        # Get mask directory from image path\n","        mask_dir = os.path.join(os.path.dirname(os.path.dirname(info['path'])), \"masks\")\n","\n","        # Read mask files from .png image\n","        mask = []\n","        for f in next(os.walk(mask_dir))[2]:\n","            if ~os.path.isdir(f):\n","                m = skimage.io.imread(os.path.join(mask_dir, f)).astype(np.bool)\n","                mask.append(m)\n","        mask = np.stack(mask, axis=-1)\n","        # Return mask, and array of class IDs of each instance. Since we have\n","        # one class ID, we return an array of ones\n","        return mask, np.ones([mask.shape[-1]], dtype=np.int32)\n","\n","    def image_reference(self, image_id):\n","        \"\"\"Return the path of the image.\"\"\"\n","        info = self.image_info[image_id]\n","        if info[\"source\"] == \"nucleus\":\n","            return info[\"id\"]\n","        else:\n","            super(self.__class__, self).image_reference(image_id)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"unf8fYCdokDF","cellView":"form"},"source":["#@markdown ___\n","#@markdown ## **B. Training Module**\n","#@markdown\n","\n","def train(model, dataset_dir, subset):\n","    \"\"\"Train the model.\"\"\"\n","    # Training dataset.\n","    dataset_train = NucleusDataset()\n","    dataset_train.load_nucleus(dataset_dir, subset)\n","    dataset_train.prepare()\n","\n","    # Validation dataset\n","    dataset_val = NucleusDataset()\n","    dataset_val.load_nucleus(dataset_dir, \"Val\")\n","    dataset_val.prepare()\n","\n","    # Image augmentation\n","    # http://imgaug.readthedocs.io/en/latest/source/augmenters.html\n","    #@markdown ### **Select Image Augmentation Parameters**\n","    #@markdown Conduct Augmentation?\n","    AUG = True #@param  {type:\"boolean\"}\n","    #@markdown\n","    #@markdown ##### Fraction of Augmented Images to Flip Left/Right or Up/Down\n","    Flip_LR = 0.5 #@param {type: \"number\"}\n","    Flip_UD = 0.5 #@param {type: \"number\"}  \n","    #@markdown ##### Random Rotation Angles \n","    ROT1 = 90  #@param {type: \"number\"}\n","    ROT2 = 180  #@param {type: \"number\"}\n","    ROT3 = 270  #@param {type: \"number\"}\n","    #@markdown ##### Random Scaling Low and High Value Range\n","    MULT_LO = 0.8  #@param {type: \"number\"}\n","    MULT_HI = 1.5  #@param {type: \"number\"}\n","    #@markdown ##### Low and High Range for Sigma Values for RandomBlurring\n","    SIG_LO = 0  #@param {type: \"number\"}\n","    SIG_HI = 5  #@param {type: \"number\"}\n","    #@markdown\n","    augmentation = iaa.SomeOf((0, 2), [\n","        iaa.Fliplr(Flip_LR),\n","        iaa.Flipud(Flip_UD),\n","        iaa.OneOf([iaa.Affine(rotate=ROT1),\n","                   iaa.Affine(rotate=ROT2),\n","                   iaa.Affine(rotate=ROT3)]),\n","        iaa.Multiply((MULT_LO, MULT_HI)),\n","        iaa.GaussianBlur(sigma=(SIG_LO, SIG_HI))\n","    ])\n","    if AUG == True:\n","      AUG_TYPE = augmentation\n","    else:\n","      AUG_TYPE = None\n","    #@markdown\n","\n","    #@markdown Train Heads (Top Layers) or All Layers\n","    TRAIN_LAYERS = \"all\" #@param [\"all\", \"heads\"] {type:\"string\"}\n","    \n","    #@markdown *Training Using Multiple Learning Rates or Training on All Layers and then Heads can be done.  Double Click to Adjust Code.*\n","    \n","    # If starting from imagenet, train heads only for a bit\n","    # since they have random weights\n","    model.train(dataset_train, dataset_val,\n","                learning_rate=config.LEARNING_RATE,\n","                epochs=config.EPOCHS,\n","                augmentation=augmentation,\n","                layers=TRAIN_LAYERS)\n","    \n","    # Add additional train sessions here, after the first, to continue training using different settings \n","    #model.train(dataset_train, dataset_val,\n","     #       learning_rate=1e-4,\n","      #      epochs=EPOCHS+100,\n","       #     augmentation=augmentation,\n","        #    layers='heads')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vF1_ZfjIp67W","cellView":"form"},"source":["#@markdown ___\n","#@markdown ## **C. Detection Module**\n","#@markdown Prepare the test module\n","\n","#@markdown\n","\n","#@markdown ### **Conduct post-processing on predictions?**\n","#@markdown Overlap removal (experimental)\n","utc = pytz.utc\n","utc_dt = datetime.datetime.now()\n","eastern = timezone('US/Eastern')\n","loc_dt = utc_dt.astimezone(eastern)\n","\n","import colorspacious\n","from glasbey import Glasbey\n","from skimage.color import label2rgb\n","import math\n","import codecs\n","from IPython.display import Image\n","\n","color = np.array(([1,0,0],[0,1,0],[0,0,1],[1,1,0],[0,1,1],[1,0,1],[1,0.5,0],[0.5,1,0],[0,1,0.5],[0,0.5,1],[1,0,0.5],[0.5,0,1],[1,0.5,0.25],[0.25,0.5,1],[1,0.25,0.5],[0.5,0.25,1],[0.5,1,0.25],[0.25,1,0.5]),np.float32)\n","gb = Glasbey(base_palette=color, chroma_range = (60,100), no_black=True)\n","c4 = gb.generate_palette(size=18)\n","color4 = c4[1:]\n","\n","def normalized(rgb):\n","\n","        norm=np.zeros((512,512,3),np.float32)\n","        norm_rgb=np.zeros((512,512,3),np.uint8)\n","\n","        b=rgb[:,:,0]\n","        g=rgb[:,:,1]\n","        r=rgb[:,:,2]\n","\n","        sum=b+g+r\n","\n","        norm[:,:,0]=b/sum*255.0\n","        norm[:,:,1]=g/sum*255.0\n","        norm[:,:,2]=r/sum*255.0\n","\n","        norm_rgb=cv2.convertScaleAbs(norm)\n","        return norm_rgb\n","\n","def overlay(mask, orig, clr):\n","  maskPR = label(mask)\n","  labels = label2rgb(label=maskPR, bg_label=0, bg_color=(0, 0, 0), colors=clr)\n","  L2 = normalized(labels)\n","  if len(orig.shape) < 3: \n","    O2 = cv2.cvtColor(orig.astype('uint8'), cv2.COLOR_GRAY2BGR)\n","  else:\n","    O2 = orig\n","  comb = cv2.addWeighted(L2.astype('float64'),0.5,O2.astype('float64'),0.5,0)\n","  return comb\n","\n","PROC = True #@param {type:\"boolean\"}\n","def detect(model, dataset_dir, subset, RESULTS_DIR):\n","    \"\"\"Run detection on images in the given directory.\"\"\"\n","    print(\"Running on {}\".format(dataset_dir))\n","        \n","    # Read dataset\n","    dataset = NucleusDataset()\n","    dataset.load_nucleus(dataset_dir, subset)\n","    dataset.prepare()\n","    \n","    #@markdown\n","    #@markdown ### **Results Output Folder Name**\n","    #Out_Folder = 'Tissue_Nucleus'  + '_' +  loc_dt.strftime('%Y-%m-%d_%H:%M:%S_%Z%z') #@param {type: \"raw\"}\n","    Out_Folder = 'Tissue' #@param {type: \"raw\"}\n","    submit_dir = Out_Folder\n","    #print(submit_dir)\n","    tme = str(loc_dt.strftime('_%Y_%m_%d_%Hh-%Mm-%Ss'))\n","    submit_dir = os.path.join(RESULTS_DIR, submit_dir + tme)\n","    mask_dir = os.path.join(submit_dir, 'masks')\n","    print(mask_dir)\n","    if not os.path.exists(mask_dir):\n","      os.makedirs(mask_dir)\n","\n","    # Load over images\n","    init = 0\n","    submission = []\n","    for image_id in dataset.image_ids:\n","        # Load image and run detection\n","        image = dataset.load_image(image_id)\n","        # Detect objects\n","        r = model.detect([image], verbose=0)[0]\n","        # Encode image to RLE. Returns a string of multiple lines\n","        source_id = dataset.image_info[image_id][\"id\"]\n","        rle = mask_to_rle(source_id, r[\"masks\"], r[\"scores\"])\n","        submission.append(rle)\n","        # Save image with masks\n","        visualize.display_instances(\n","            image, r['rois'], r['masks'], r['class_ids'],\n","            dataset.class_names, #r['scores'],\n","            show_bbox=False, show_mask=True,\n","            title=\"Predictions\", captions = None)\n","        plt.savefig(\"{}/{}.png\".format(submit_dir, dataset.image_info[image_id][\"id\"]))\n","\n","        masks = r['masks'].astype(np.uint8)\n","        mask = np.zeros([masks.shape[0], masks.shape[1]], dtype='uint8')\n","        maskD = np.zeros([masks.shape[0], masks.shape[1]], dtype='uint8')\n","        diff = np.zeros([masks.shape[0], masks.shape[1]], dtype='uint8')\n","        props = np.zeros((masks.shape[2]))\n","        for n in range(0,masks.shape[2]):\n","            if PROC == False:\n","              mask = mask + (n+1)*masks[:,:,n]\n","            elif PROC == True:\n","              M2 = label(masks[:,:,n])\n","              props2 = regionprops(M2)\n","              for m in range(0,M2.max()):\n","                if props2[m].area < 100:\n","                  M2[M2==m+1] = 0\n","              M2[M2 > 0] = 1\n","              masks[:,:,n] = M2*masks[:,:,n]\n","              props2 = regionprops(masks[:,:,n])\n","\n","              maskD = maskD + masks[:,:,n]\n","              \n","              if maskD.max() <= 1:\n","                mask = mask + (n+1)*masks[:,:,n]\n","              else:\n","                try:\n","                  diff[maskD > 1] = 1\n","                  diff2 = diff.copy()\n","                  pd = regionprops(diff)\n","\n","                  area2 = props2[0].area \n","                  aread = pd[0].area\n","                  Vals = diff*mask # Find value of existing region label, under new overlap\n","                  vals = Vals[Vals>0] # Not zero\n","                  vals = vals[vals != n+1] # Not the current label\n","                  vals = list(set(vals)) # Really should only be one left\n","                  props1 = regionprops(masks[:,:,vals[0]])\n","                  area1 = props1[0].area\n","                  div1 = aread/area1\n","                  div2 = aread/area2\n","                  dd = vals[0] + n+1\n","                  \n","                  mask = mask + (n+1)*masks[:,:,n]\n","                  if div1 < 0.15 and div2 < 0.15:\n","                      mask[diff > 0] = vals[0]\n","                  elif div1 < 0.15 and div2 > 0.15:\n","                      mask[diff > 0] = n+1\n","                      mask[mask==vals[0]] = n+1\n","                  elif div1 > 0.15 and div2 < 0.15:\n","                      mask[diff > 0] = vals[0]\n","                      mask[mask==n+1] = vals[0]\n","                  elif div1 > 0.15 and div2 > 0.15 and div1 < 0.6 and div2 < 0.6:\n","\n","                      y0, x0 = pd[0].centroid\n","                      orientation = pd[0].orientation\n","\n","                      x1 = x0 - math.sin(orientation) * 0.55 * pd[0].major_axis_length\n","                      y1 = y0 - math.cos(orientation) * 0.55 * pd[0].major_axis_length\n","                      x2 = x0 + math.sin(orientation) * 0.55 * pd[0].major_axis_length\n","                      y2 = y0 + math.cos(orientation) * 0.55 * pd[0].major_axis_length \n","\n","                      cv2.line(diff, (int(x2),int(y2)), (int(x0),int(y0)), (0, 0, 0), thickness=2)\n","                      cv2.line(diff, (int(x1),int(y1)), (int(x0),int(y0)), (0, 0, 0), thickness=2)\n","\n","                      lbl1 = label(diff)\n","                      lbl1 = lbl1.astype('uint8')\n","                      cv2.line(lbl1, (int(x2),int(y2)), (int(x0),int(y0)), (1, 1, 1), thickness=2)\n","                      cv2.line(lbl1, (int(x1),int(y1)), (int(x0),int(y0)), (1, 1, 1), thickness=2)\n","                      lbl2 = lbl1*diff2\n","                      mask[lbl2 == 2] = n+1\n","                      mask[lbl2 == 1] = vals[0]\n","                                       \n","                  elif div1 > 0.6 or div2 > 0.6:\n","                    if area1 > area2:\n","                      mask[diff > 0] = vals[0]\n","                      mask[mask==n+1] = vals[0]\n","                    elif area2 > area1:\n","                      mask[diff > 0] = n+1\n","                      mask[mask==vals[0]] = n+1\n","                except Exception:\n","                  continue\n","              maskD[maskD > 1] = 1\n","              diff = np.zeros([masks.shape[0], masks.shape[1]], dtype='uint8')\n","\n","        #print(dataset_dir+ '/' + dataset.image_info[image_id][\"id\"])\n","        cv2.imwrite(submit_dir + '/masks/' + dataset.image_info[image_id][\"id\"] + '.png', mask)\n","        ovr = overlay(mask, image, color4)\n","        cv2.imwrite(submit_dir + '/' + dataset.image_info[image_id][\"id\"] + '.png', ovr)\n","        if PROC:\n","          print(\"Processed Overlay\")\n","          _, ax = plt.subplots(1, figsize=(16, 16))\n","          ax.axis('off')\n","          plt.imshow(ovr.astype('uint8'),clim=(0.0, 1.0))\n","          plt.show()\n","          init = init + 1\n","\n","    # Save to csv file\n","    submission = \"ImageId,EncodedPixels\\n\" + \"\\n\".join(submission)\n","    file_path = os.path.join(submit_dir, \"submit.csv\")\n","    with open(file_path, \"w\") as f:\n","        f.write(submission)\n","    print(\"Saved to \", submit_dir)\n","\n","    return submit_dir"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I5qSou1NqSMn","cellView":"form"},"source":["#@markdown ___\n","#@markdown ## **D. RLE Encoding and Decoding**\n","#@markdown\n","\n","def rle_encode(mask):\n","    \"\"\"Encodes a mask in Run Length Encoding (RLE).\n","    Returns a string of space-separated values.\n","    \"\"\"\n","    assert mask.ndim == 2, \"Mask must be of shape [Height, Width]\"\n","    # Flatten it column wise\n","    m = mask.T.flatten()\n","    # Compute gradient. Equals 1 or -1 at transition points\n","    g = np.diff(np.concatenate([[0], m, [0]]), n=1)\n","    # 1-based indicies of transition points (where gradient != 0)\n","    rle = np.where(g != 0)[0].reshape([-1, 2]) + 1\n","    # Convert second index in each pair to lenth\n","    rle[:, 1] = rle[:, 1] - rle[:, 0]\n","    return \" \".join(map(str, rle.flatten()))\n","\n","\n","def rle_decode(rle, shape):\n","    \"\"\"Decodes an RLE encoded list of space separated\n","    numbers and returns a binary mask.\"\"\"\n","    rle = list(map(int, rle.split()))\n","    rle = np.array(rle, dtype=np.int32).reshape([-1, 2])\n","    rle[:, 1] += rle[:, 0]\n","    rle -= 1\n","    mask = np.zeros([shape[0] * shape[1]], np.bool)\n","    for s, e in rle:\n","        assert 0 <= s < mask.shape[0]\n","        assert 1 <= e <= mask.shape[0], \"shape: {}  s {}  e {}\".format(shape, s, e)\n","        mask[s:e] = 1\n","    # Reshape and transpose\n","    mask = mask.reshape([shape[1], shape[0]]).T\n","    return mask\n","\n","\n","def mask_to_rle(image_id, mask, scores):\n","    \"Encodes instance masks to submission format.\"\n","    assert mask.ndim == 3, \"Mask must be [H, W, count]\"\n","    # If mask is empty, return line with image ID only\n","    if mask.shape[-1] == 0:\n","        return \"{},\".format(image_id)\n","    # Remove mask overlaps\n","    # Multiply each instance mask by its score order\n","    # then take the maximum across the last dimension\n","    order = np.argsort(scores)[::-1] + 1  # 1-based descending\n","    mask = np.max(mask * np.reshape(order, [1, 1, -1]), -1)\n","    # Loop over instance masks\n","    lines = []\n","    for o in order:\n","        m = np.where(mask == o, 1, 0)\n","        # Skip if empty\n","        if m.sum() == 0.0:\n","            continue\n","        rle = rle_encode(m)\n","        lines.append(\"{}, {}\".format(image_id, rle))\n","    return \"\\n\".join(lines)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5Bz7l9Q32vRY"},"source":["# **V. Run the Network**"]},{"cell_type":"code","metadata":{"id":"755mz9Qn6ATK","cellView":"form"},"source":["#@markdown ___\n","#@markdown ## **A. Select Weights**\n","\n","os.chdir(MRCNN_PATH)\n","\n","ROOT_DIR = MRCNN_PATH\n","\n","# Select training/testing weights\n","\n","#@markdown Select pre-trained weights for testing or to continue training on.\n","#@markdown\n","#@markdown Choose the \"Select\" option to upload other weights.\n","Weights = \"coco\" #@param [\"coco\", \"imagenet\", \"Kaggle\", \"Storm_Tissue\", \"Storm_Cell\", \"Select\"] {type:\"string\"}\n","if Weights == \"coco\":\n","  weights_path = r'C:\\Users\\LIUY\\Desktop\\PythonCode\\weights\\mask_rcnn_coco.h5'\n","elif Weights == \"imagenet\":\n","  weights_path = model.get_imagenet_weights()\n","elif Weights == \"Kaggle\":\n","  weights_path = r'C:\\Users\\LIUY\\Desktop\\PythonCode\\weights\\mask_rcnn_kaggle_v1.h5'\n","elif Weights == \"Storm_Tissue\":\n","  weights_path = r'C:\\Users\\LIUY\\Desktop\\PythonCode\\weights\\mask_rcnn_nucleus_tissue.h5'\n","elif Weights == \"Storm_Cell\":\n","  weights_path = r'C:\\Users\\LIUY\\Desktop\\PythonCode\\weights\\mask_rcnn_nucleus_cell.h5'\n","elif Weights == \"Select\":\n","  print('Use popup window to select weights')\n","  weights = filedialog.askopenfile(title=('Select Weights'))\n","  weights_path = weights.name\n","\n","print(weights_path) \n","#@markdown\n","\n","#@markdown ### **Select Network Training Log Directory**\n","#@markdown Where your newly trained weights will be saved.\n","DEFAULT_LOGS_DIR = 'C:\\\\Users\\\\LIUY\\\\Desktop\\\\PythonCode\\\\Mask_RCNN\\\\logs' #@param {type: \"string\"}\n","if not os.path.exists(DEFAULT_LOGS_DIR):\n","  os.makedirs(DEFAULT_LOGS_DIR)\n","#@markdown\n","\n","#@markdown ### **Select Segmentation Results Directory**\n","#@markdown Where your test results will be saved\n","RESULTS_DIR = 'C:\\\\Users\\\\LIUY\\\\Desktop\\\\PythonCode\\\\Mask_RCNN\\\\Results' #@param {type: \"string\"}\n","if not os.path.exists(RESULTS_DIR):\n","  os.makedirs(RESULTS_DIR)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rNnz7xTWtkmb","cellView":"form"},"source":["#@markdown ___\n","#@markdown ## **B. Run Network**\n","\n","#@markdown ### Test or Train?\n","command = 'train' #@param [\"test\", \"train\"] {type: \"string\"}\n","\n","# Configurations\n","if command == \"train\":\n","    config = NucleusConfig()\n","    log_dir = DEFAULT_LOGS_DIR\n","    #if not os.path.exists(weights_path):\n","     # os.makedirs(weights_path)\n","else:\n","    config = NucleusInferenceConfig()\n","#config.display()\n","\n","print(weights_path)\n","# Create model\n","if command == \"train\":\n","    model = modellib.MaskRCNN(mode=\"training\", config=config,\n","                              model_dir=log_dir)\n","else:\n","    model = modellib.MaskRCNN(mode=\"inference\", config=config,\n","                              model_dir=weights_path)\n","    \n","if Weights == \"coco\":\n","  model.load_weights(weights_path, by_name=True, exclude=[\n","  \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n","  \"mrcnn_bbox\", \"mrcnn_mask\"])\n","else:\n","  model.load_weights(weights_path, by_name=True)\n","\n","# Train or evaluate\n","if command == \"train\":\n","    train(model, PROC_PATH, subset='Train')\n","elif command == \"test\":\n","    sdir = detect(model, PROC_PATH, RESULTS_DIR=RESULTS_DIR, subset='Test',)\n","else:\n","    print(\"'{}' is not recognized. \"\n","          \"Use 'train' or 'detect'\".format(command))"],"execution_count":null,"outputs":[]}]}