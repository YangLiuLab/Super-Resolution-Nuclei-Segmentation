{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"UNet.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMmnOuf4AW4vb5641kT7bkm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"fJBt4bwDUIQv"},"source":["## **UNet Training and Testing**\n","Used in this repository for super-resolution image noise detection, but can be trained for other purposes.\n","\n","**Code:** https://github.com/zhixuhao/unet\n","\n","**Paper:** Ronneberger O., Fischer P., Brox T. (2015) U-Net: Convolutional Networks for Biomedical Image Segmentation. In: Navab N., Hornegger J., Wells W., Frangi A. (eds) Medical Image Computing and Computer-Assisted Intervention â€“ MICCAI 2015. MICCAI 2015. Lecture Notes in Computer Science, vol 9351. Springer, Cham. https://doi.org/10.1007/978-3-319-24574-4_28\n","\n","---\n","\n","**Begin:**  The first step, is to gather your data into two directories (folders).  One for the original images to be processed and one for data labels.\n","\n","Additionally, if you are testing only and do not have labels, that is fine.  If you are conducting training, labels are required.  Annotation files are not required.\n","\n","---\n","NOTE: To activate GPU, go to Runtime (tab at top) --> Change runtime type, then select GPU under Hardware accelerator\n","\n","---\n","\n","**Next:**  Run all sections of the code.  Use defaults if unsure. \n","\n","---\n","\n","**Then:**  Train or Test\n","\n","---\n","\n","**NOTES:**  Click folder on the left side <----- to see files. Then click \"up arrow on folder\" icon to get full list."]},{"cell_type":"code","metadata":{"id":"23BmAwuoUHL4","cellView":"form"},"source":["#@markdown ___\n","#@markdown ## **I. Install Required Packages**\n","\n","%cd\n","!git clone --quiet https://github.com/zhixuhao/unet.git\n","\n","!pip uninstall -y tensorflow\n","!pip install tensorflow_gpu==1.14\n","!pip install keras==2.2.4"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3DB09vZ4WExu","cellView":"form"},"source":["#@markdown ___\n","#@markdown ## **II. Import Libraries and Connect to Drive**\n","from google.colab import files\n","from google.colab import drive\n","import os\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import skimage\n","\n","#@markdown Connect to Drive?\n","DRIVE = True #@param {type : \"boolean\"}\n","if DRIVE == True:\n","  drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3lyKjUkvq0-P","cellView":"form"},"source":["%cd\n","#@markdown ___\n","#@markdown ## **III. Import Image Data**\n","#@markdown From local PC to cloud, or from drive folder\n","\n","#@markdown A. Import from PC or Drive?\n","IMPORT = 'PC' #@param [\"PC\",\"Drive\"] {type:\"string\"}\n","\n","#@markdown B. Specify Whether you will be Conducting Training or Testing?\n","ToT = \"Train\" #@param [\"Train\",\"Test\"] {type:\"string\"}\n","#@markdown  . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n","\n","#@markdown Additional Options:\n","\n","#@markdown -- If uploading data from your PC, specify cloud save paths (default examples shown).\n","\n","#@markdown -- If using data in Drive, specify path to images\n","\n","#@markdown A. Path to training images\n","TRAIN_IMG = '/root/train' #@param {type:'string'}\n","\n","#@markdown B. Path to training labels\n","TRAIN_LBL = '/root/label' #@param {type:'string'}\n","\n","#@markdown C. Path to test images\n","TEST_IMG = '/root/test' #@param {type:'string'}\n","\n","if IMPORT == 'PC':\n","\n","  if ToT == \"Train\":\n","    if not os.path.exists(TRAIN_IMG):\n","      os.makedirs(TRAIN_IMG)\n","    if not os.path.exists(TRAIN_LBL):\n","      os.makedirs(TRAIN_LBL)\n","    print(\"Select Trainig Images to Upload\")\n","    os.chdir(TRAIN_IMG)\n","    images = files.upload()\n","    print(\"Select Trainig Labels to Upload\")\n","    os.chdir(TRAIN_LBL)\n","    labels = files.upload()\n","  elif ToT == \"Test\":\n","    if not os.path.exists(TEST_IMG):\n","      os.makedirs(TEST_IMG)\n","    print(\"Select Test Images to Upload\")\n","    os.chdir(TEST_IMG)\n","    imagesT = files.upload()\n","\n","elif IMPORT == 'Drive':\n","  if ToT == \"Train\":\n","    if not os.path.exists(TRAIN_IMG):\n","      os.makedirs(TRAIN_IMG)\n","    if not os.path.exists(TRAIN_LBL):\n","      os.makedirs(TRAIN_LBL)\n","    \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hyMGukwlXJMh","cellView":"form"},"source":["#@markdown ## **IV. Configuration**\n","#@markdown\n","\n","#@markdown A. Path to root directory\n","ROOT_PATH = '/root' #@param {type:'string'}\n","\n","#@markdown B. Folder in root for training images\n","TRAIN_IMG = \"train\" #@param {type:'raw'}\n","\n","#@markdown C. Path to test images\n","TEST_IMG = TEST_IMG #@param {type:'raw'}\n","\n","#@markdown D. Folder in root for training labels\n","TRAIN_LBL = \"label\" #@param {type:'raw'}\n","\n","#@markdown E. Save path for test images\n","SAVE_PATH = '/root/results' #@param {type:'string'}\n","if not os.path.exists(os.path.join(ROOT_PATH,SAVE_PATH)):\n","      os.makedirs(os.path.join(ROOT_PATH,SAVE_PATH))\n","\n","#@markdown F. Load path for pre-trained weights to test with\n","WEIGHT_PATH = '/content/drive/My Drive/Colab Notebooks/weights/unet_noise_tissue.hdf5' #@param {type:'string'}\n","\n","#@markdown G. File name for newly trained weights\n","SAVE_NAME = '/content/drive/My Drive/Colab Notebooks/weights/unet_new_model.hdf5' #@param {type:'string'}\n","\n","#@markdown H. Image file extension (e.g. png, tif, jpg)\n","ext = 'png' #@param ['png','tif','jpg']{type:'string'}\n","\n","#@markdown I. Image color mode (grayscale, rgb)\n","COLOR = 'grayscale' #@param ['grayscale','rgb','rgba']{type:'string'}\n","\n","#@markdown J. Select metric to monitor\n","METRIC = 'loss' #@param ['loss','val_loss','accuracy','val_accuracy']{type:'string'}\n","\n","#@markdown K. How often to display training info\n","VERBOSE = 2 #@param {type:\"slider\", min:0, max:100, step:1}\n","\n","#@markdown L. Save best weight or last weight\n","SAVE_BEST = False #@param {type:\"boolean\"}\n","\n","#@markdown M. Number of steps per epoch\n","STEPS = 10 #@param {type: \"integer\"}\n","\n","#@markdown N. Number of epochs\n","EPOCHS = 10 #@param {type: \"integer\"}\n","\n","#@markdown O. Size of Image (MxN; resize)\n","M = 512 #@param {type: \"integer\"}\n","N = 512 #@param {type: \"integer\"}\n","\n","#@markdown ___\n","\n","#@markdown ### Data Augmentation Arguements\n","#@markdown Augmentations are randomly assigned\n","\n","#@markdown P. Rotation Range (degrees)\n","ROT = 45 #@param {type:\"slider\", min:0, max:90, step:1}\n","ROT = ROT/100\n","\n","#@markdown Q. Width Shift Range (fraction of total image width)\n","WSR = 0.15 #@param {type:\"slider\", min:0, max:0.5, step:0.05}\n","\n","#@markdown R. Horizontal Shift Range (fraction of total image height)\n","HSR = 0.15 #@param {type:\"slider\", min:0, max:0.5, step:0.05}\n","\n","#@markdown S. Shear angle in counter-clockwise direction (degrees) \n","SHEAR = 0 #@param {type:\"slider\", min:0, max:90, step:1}\n","SHEAR = SHEAR/100\n","\n","#@markdown T. Zoom Scale Range\n","ZOOM = 0.15 #@param {type:\"slider\", min:0, max:0.50, step:0.05}\n","\n","#@markdown U. Horizontal Flip\n","HF = True #@param {type:\"boolean\"}\n","\n","#@markdown V. Vertical Flip\n","VF = True #@param {type:\"boolean\"}\n","\n","#@markdown W. Fill mode\n","FM = 'nearest' #@param [\"constant\", \"nearest\", \"reflect\",\"wrap\"]{type:\"string\"}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zymy4bAJWmfK","cellView":"form"},"source":["%cd ~/unet/\n","#@markdown ___\n","#@markdown ## **V. Train Network**\n","#@markdown Using paths and parameters defined above.\n","from model import *\n","from data import *\n","\n","data_gen_args = dict(rotation_range=ROT,\n","                    width_shift_range=WSR,\n","                    height_shift_range=HSR,\n","                    shear_range=SHEAR,\n","                    zoom_range=ZOOM,\n","                    horizontal_flip=HF,\n","                    vertical_flip=VF,\n","                    fill_mode=FM)\n","\n","print(ROOT_PATH)\n","print(TRAIN_IMG)\n","print(TRAIN_LBL)\n","myGene = trainGenerator(1,ROOT_PATH, TRAIN_IMG,TRAIN_LBL,data_gen_args,save_to_dir = None, image_color_mode = COLOR)\n","\n","model = unet()\n","model_checkpoint = ModelCheckpoint(SAVE_NAME, monitor=METRIC,verbose=VERBOSE, save_best_only=SAVE_BEST)\n","model.fit_generator(myGene,steps_per_epoch=STEPS,epochs=EPOCHS,callbacks=[model_checkpoint])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zJU-pCP1vCbk","cellView":"form"},"source":["%cd ~/unet/\n","#@markdown ___\n","#@markdown ## **VI. Test Network**\n","#@markdown Test pretrained network\n","#@markdown\n","#@markdown NOTE: If using one of our pretrained models, resize images to 512x512\n","from model import *\n","from data import *\n","from matplotlib import pyplot as plt\n","\n","model = load_model(WEIGHT_PATH)\n","test_path = TEST_IMG\n","save_path = SAVE_PATH\n","container = np.zeros((M,N,1,1))\n","\n","def bin_ndarray(ndarray, new_shape, operation='sum'):\n","    \"\"\"\n","    J.F. Sebastian\n","    Bins an ndarray in all axes based on the target shape, by summing or\n","        averaging.\n","\n","    Number of output dimensions must match number of input dimensions and \n","        new axes must divide old ones.\n","\n","    \"\"\"\n","    operation = operation.lower()\n","    if not operation in ['sum', 'mean']:\n","        raise ValueError(\"Operation not supported.\")\n","    if ndarray.ndim != len(new_shape):\n","        raise ValueError(\"Shape mismatch: {} -> {}\".format(ndarray.shape,\n","                                                           new_shape))\n","    compression_pairs = [(d, c//d) for d,c in zip(new_shape,\n","                                                  ndarray.shape)]\n","    flattened = [l for p in compression_pairs for l in p]\n","    ndarray = ndarray.reshape(flattened)\n","    for i in range(len(new_shape)):\n","        op = getattr(ndarray, operation)\n","        ndarray = op(-1*(i+1))\n","    return ndarray\n","\n","def image_normalized(file_path):\n","\n","    #img = cv2.imread(file_path,0)\n","    img = skimage.io.imread(file_path)\n","    img_shape = img.shape\n","    image_size = (img_shape[1],img_shape[0])\n","    img_standard = bin_ndarray(img*1.2, (M,N), operation='mean')\n","    #img_standard = cv2.resize(img, (512, 512), interpolation=cv2.INTER_CUBIC)\n","    img_new = img_standard\n","    img_new = np.asarray([img_new / 255.])\n","    return img_new,image_size\n","\n","for name in os.listdir(test_path):\n","  image_path = os.path.join(test_path,name)\n","  if os.path.isdir(image_path):\n","    continue\n","  img,img_size = image_normalized(image_path)\n","  img = np.reshape(img,img.shape+(1,))\n","  results = model.predict(img)\n","  out = np.zeros(img.shape)\n","  #out = np.zeros((512,512));\n","  #print(results.shape)\n","  #out[results[0,:,:,0] > 0] = 1;\n","  out = 255*results[0,:,:,0];\n","\n","  _, ax = plt.subplots(1, figsize=(16, 16))\n","  ax.axis('off')\n","  plt.imshow(out.astype('uint8'),clim=(0.0, 1.0))\n","  plt.show()\n","\n","  skimage.io.imsave(os.path.join(save_path, (\"%s\") % (name)), out)\n","  #cv2.imwrite(os.path.join(save_path, (\"%s\") % (name)), out)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"FhynjI50rzGY"},"source":["#@markdown ## **V. Zip and Download Predictions to Local Drive**\r\n","#@markdown If download does not occur, check if browser is blocking.\r\n","import shutil\r\n","\r\n","output_filename = 'New' #@param {type: 'string'}\r\n","dir_name = SAVE_PATH\r\n","shutil.make_archive(output_filename, 'zip', dir_name, verbose=1)\r\n","\r\n","files.download(output_filename + '.zip')"],"execution_count":null,"outputs":[]}]}