{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of ANCIS.ipynb","private_outputs":true,"provenance":[{"file_id":"1NWgd2DKlQETOQ7M8on_2KY3H0HSkoWXC","timestamp":1609192837488},{"file_id":"1XQKRSkWfRVamCGxgvbBQtM4P4MIgO35N","timestamp":1603756685999}],"collapsed_sections":["G5Br139VBZdH"],"toc_visible":true,"authorship_tag":"ABX9TyMqw9uBarXfeOLei53jmLVJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"G8xvUy2xh2ry"},"source":["## **ANCIS Training and Detection**\n","Attentive neural cell instance segmentation, \n","\n","**Code:** ANCIS-Pythorch https://github.com/yijingru/ANCIS-Pytorch\n","\n","**Paper:** Jingru Yi, Pengxiang Wu, Menglin Jiang, Qiaoying Huang, Daniel J. Hoeppner, Dimitris N. Metaxas, Attentive neural cell instance segmentation, Medical Image Analysis, Volume 55, 2019, Pages 228-240, https://doi.org/10.1016/j.media.2019.05.004.\n","\n","---\n","\n","**Installation:** Packages require local installation. Tested on:\n","\n","cuda 10.0 & cudnn 7\n","\n","python 3.6.9 (or 3.7.4)\n","\n","pytorch > 0.4.0\n","*(if you receive a \"...torch.cuda.is_available() is False...\" error, it may be nessecary to manually install an alternate version of pytorch, as described here: https://pytorch.org/get-started/previous-versions/)*\n","\n","numpy, scipy, Pillow, pickle, cython, matplotlib, scikit-image, opencv-python, h5py, imgaug, iPython, tkinter\n","\n","---\n","\n","***Manual Install**\n","\n","The following packages must be installed manually:\n","\n","Cuda Toolkit 10.0:  https://developer.nvidia.com/cuda-10.0-download-archive\n","\n","cuDNN v7.6.5 for CUDA 10.0:  https://developer.nvidia.com/rdp/cudnn-archive\n","\n","Python 3.6.9:  https://www.python.org/downloads/release/python-369/\n","\n","  OR\n","\n","Python 3.7.4 (windows installer):  https://www.python.org/downloads/release/python-374/\n","\n","---\n","\n","**Begin:**  The first step, is to gather your data into two directories (folders).  One for the original images to be processed and one for data labels.\n","\n","Additionally, if you are testing only and do not have labels, that is fine.  If you are conducting training, labels are required.  Annotation files are not required.\n","\n","---\n","\n","**Next:**  Connect to local computer.  \n","- - - \n","***Connecting to Local Runtime:**\n","\n","First time users follow the setup instructions here:\n","https://research.google.com/colaboratory/local-runtimes.html\n","\n","Subsequent users can use the following instructions\n","\n",". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n","\n","Enter the following into command prompt:\n","\n","*jupyter notebook   --NotebookApp.allow_origin='https://colab.research.google.com'   --port=8888   --NotebookApp.port_retries=0 --allow-root --no-browser*\n","\n","Copy the http address that appears in the **command window**, near the bottom of the current output. (e.g. *http://localhost:8888/?token=a887174a56c905d5421fc88b2086782d53dfa034a7e690d0*) [Note: do NOT copy this address, it's just an example] [Note2: better to use the \"localhost:8888\" url rather than the \"127.0.0.1:8888\".  You'll see what I mean]\n","\n","Connect to Local Runtime by clicking the down arrow next to the \"Connect\" button in the top right of this window.  Then click \"Connect to local runtime\".\n","\n","Paste the copied http address into the input line on the popup window. Click Connect.  (Note: if an old address is already in the line, replace it with the new one)\n","\n","For more info:\n","see: https://research.google.com/colaboratory/local-runtimes.html\n","\n","---\n","\n","**After That:** Adjust values in each section of the code.  Use defaults if unsure. Run each section.\n","\n","---\n","\n","**Then:**  Train or Test\n","\n","---\n","\n","**NOTES:**  Click folder on the left side <----- to see files. Then click \"up arrow on folder\" icon to get full list.\n","\n","Noise detection does not always work properly, due to variations in images.  You may have to train on your own data using the UNet file.\n","\n","If instance detection results are poor, you may have to train your own weights."]},{"cell_type":"markdown","metadata":{"id":"GTsN7klrWa8j"},"source":["# **I. Download Requirements and Import Libraries**"]},{"cell_type":"code","metadata":{"id":"X0Lv26nRjKtz","cellView":"form"},"source":["#@markdown ___\n","#@markdown ## **A. Install Dependencies**\n","#@markdown Do you need to install dependencies (only required to install once)?\n","INSTALL = False #@param {type: 'boolean'}\n","\n","if INSTALL:\n","\n","  !pip install opencv-python numpy scikit-image shutil\n","  !pip install torch>0.4.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jab0jQ3nmWIu","cellView":"form"},"source":["#@markdown ___\r\n","#@markdown ## **B. Install ANCIS**\r\n","import os\r\n","#@markdown Set path to install ANCIS, or path to existing ANCIS installation:\r\n","ANCIS_PATH = 'C:\\\\Users\\\\CAM417\\\\Python Code\\\\ANCIS-Pytorch' #@param {type: 'string'}\r\n","\r\n","if INSTALL:\r\n","  os.chdir(ANCIS_PATH)\r\n","  !git clone --quiet https://github.com/yijingru/ANCIS-Pytorch.git\r\n","  ANCIS_PATH = os.path.join(ANCIS_PATH,\"ANCIS-Pytorch\")\r\n","  \r\n","os.chdir(ANCIS_PATH)\r\n","print(ANCIS_PATH)\r\n","\r\n","#@markdown NOTE: For windows, in **ANCIS-Pytorch\\dec_utils** & **ANCIS-Pytorch\\seg_utils** folders:\r\n","\r\n","#@markdown in **dec_kaggle_dataset.py** & **seg_kaggle_dataset.py** files:\r\n","\r\n","#@markdown replace in lines 50 & 52, respectively:\r\n","\r\n","#@markdown barcode = img_file.split('/')[-1].split('.')[0] *with* barcode = img_file.split('\\\\\\\\')[-1].split('.')[0]\r\n","\r\n","#@markdown *use ('/') for Linux, windows will recognize this as 'endline'*\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XMD0OVjMsMlq","cellView":"form"},"source":["#@markdown ___\n","#@markdown ## **C. Import Libraries**\n","\n","import os\n","import cv2\n","import numpy as np\n","import pickle\n","import skimage\n","from skimage.measure import label, regionprops\n","import shutil\n","from tifffile import imread\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","\n","import tkinter as tk\n","from tkinter import filedialog\n","\n","root = tk.Tk()\n","root.withdraw()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z0cogEjBWsvL"},"source":["# **II. Set Data Paths, Import Data and Process**"]},{"cell_type":"code","metadata":{"id":"g36HSS1mjIjk","cellView":"form"},"source":["#@markdown ___\r\n","\r\n","#@markdown ## **A. Testing or Training?**\r\n","Select = 'Train' #@param [\"Test\", \"Train\"] {type:\"string\"}\r\n","#@markdown If Training, are You Using Validation Images (check for yes)?\r\n","VAL = False #@param {type: 'boolean'}\r\n","NR = False\r\n","\r\n","#@markdown ## **B. Provide Processed Image Path** \r\n","#@markdown Your Images will be Processed to Fit the Network Requirements, and Saved to this Path for use in Testing or Training.\r\n","PROC_PATH = \"D:\\\\Images\\\\Proc\" #@param {type: \"string\"}\r\n","if not os.path.exists(PROC_PATH):\r\n","  os.makedirs(PROC_PATH)\r\n","\r\n","#@markdown ## **C. Set Data Paths**\r\n","#@markdown --- Run this Cell and Use the File Prompt to Select Your Image Directories. (New window opens behind current window, in some cases)\r\n","\r\n","#@markdown *You Must Select an Image Directory for Testing.*\r\n","\r\n","#@markdown *For Training, Both and Image and a Label Directory are Required. Validation Set Image and Label Directories are Recommended, but not Required.*\r\n","TRAIN_PATH = \"/home/chris/Trunk/PythonProjects/Images\"\r\n","LABEL_PATH = \"/home/chris/Trunk/PythonProjects/Images\"\r\n","VAL_PATH = \"/home/chris/Trunk/PythonProjects/Images\"\r\n","VAL_LABEL_PATH = \"/home/chris/Trunk/PythonProjects/Images\"\r\n","TEST_PATH = \"/home/chris/Trunk/PythonProjects/Images\"\r\n","\r\n","if Select == 'Train':\r\n","  print(\"Select Training Image Directory\")\r\n","  TRAIN_PATH = filedialog.askdirectory(title=\"Select Training Image Directory\")\r\n","  print(TRAIN_PATH)\r\n","  print('**********************************************************************')\r\n","  print(\"Select Training Label Directory\")\r\n","  LABEL_PATH = filedialog.askdirectory(title=\"Select Training Label Directory\")\r\n","  annoDir = LABEL_PATH\r\n","  print(LABEL_PATH)\r\n","  root.destroy\r\n","  if VAL == True:\r\n","    print('**********************************************************************')\r\n","    print(\"Select Validation Image Directory\")\r\n","    VAL_PATH = filedialog.askdirectory(title=\"Select Validation Image Directory\")\r\n","    print(VAL_PATH)\r\n","    print('**********************************************************************')\r\n","    print(\"Select Validation Label Directory\")\r\n","    VAL_LABEL_PATH = filedialog.askdirectory(title=\"Select Validation Label Directory\")\r\n","    print(VAL_LABEL_PATH)\r\n","    root.destroy\r\n","elif Select == 'Test':\r\n","  print(\"Select Testing Image Directory\")\r\n","  TEST_PATH = filedialog.askdirectory(title=\"Select Testing Image Directory\")\r\n","  print(TEST_PATH)\r\n","  root.destroy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"j_sAxulxja0z"},"source":["#@markdown ___\r\n","#@markdown ## **D. Resizing Images**\r\n","#@markdown\r\n","\r\n","#@markdown Do You Want to Resize Your Images?\r\n","\r\n","#@markdown *Downsizing your data can decrease training time and memory requirements.\r\n","#@markdown If you are using one of our pretrained models, (512x512) is required.*\r\n","#@markdown\r\n","\r\n","Resize = False #@param  {type:\"boolean\"}\r\n","\r\n","#@markdown Resize to MxN\r\n","M = 512 #@param {type:\"integer\"}\r\n","N = 512 #@param {type:\"integer\"}\r\n","\r\n","#@markdown NOTE: *Resizing Operations Performed on Testing and Training Datasets Should be the Same.  If the Training Set was Resized Using ImageJ (for example) then the Test Set Should be Similarly Resized (rather than using this function).*"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"jb6MNMm2jjJ7"},"source":["#@markdown ___\r\n","#@markdown ## **E. Normalization**\r\n","\r\n","#@markdown Conduct Normalization?\r\n","NORM = False #@param {type:\"boolean\"}\r\n","\r\n","#@markdown *Useful when testing low contrast images*\r\n","\r\n","#@markdown *May have unintended side effects on normal or high contrast images*"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lb7WgnyIjonb","cellView":"form"},"source":["#@markdown ___\r\n","#@markdown ## **F. Noise Detection and Removal**\r\n","\r\n","#@markdown Would you like to conduct noise detection and removal (check for yes)?\r\n","\r\n","#@markdown *For Test Images.  Makes Little Difference on Training Set.*\r\n","NR = False #@param {type: \"boolean\"}\r\n","\r\n","if NR == True:\r\n","  #@markdown --- Select Path to Input Images (*Default is Test Image Path*)\r\n","  INPUT_IMG_PATH =  TEST_PATH #@param {type: \"raw\"}\r\n","  print(INPUT_IMG_PATH)\r\n","  #@markdown --- Select Path to Save DeNoised Images\r\n","  IMG_SAVE_PATH = \"D:\\\\Images\\\\imagesDN\" #@param {type: \"string\"}\r\n","  if not os.path.exists(IMG_SAVE_PATH):\r\n","    os.makedirs(IMG_SAVE_PATH)\r\n","  #@markdown --- Select Path to Save Noise Detection Maps\r\n","  NOISE_MAP = \"D:\\\\Images\\\\Nmap\" #@param {type:\"string\"}\r\n","  if not os.path.exists(NOISE_MAP):\r\n","    os.makedirs(NOISE_MAP)\r\n","  #@markdown\r\n","\r\n","#@markdown **Do you Have UNET Installed?**\r\n","UNET = True #@param {type:'boolean'}\r\n","#@markdown --- If Yes, Provide the Path Below\r\n","\r\n","#@markdown --- If No, Install to the Folder Below\r\n","UNET_PATH = \"C:\\\\Users\\\\CAM417\\\\Python Code\\\\unet\" #@param {type: 'string'}\r\n","#@markdown\r\n","\r\n","#@markdown --- Select UNet CNN Weights to use for Noise Detection.\r\n","\r\n","#@markdown *adjust paths to your system*\r\n","NOISE_WEIGHTS = \"Tissue\" #@param [\"Tissue\", \"Cell\", \"Select\"] {type: \"string\"}\r\n","if NOISE_WEIGHTS == \"Tissue\":\r\n","  #@markdown Tissue\r\n","  NW = 'D:\\\\Weights\\\\unet_noise_cell_line.hdf5' #@param {type:\"string\"}\r\n","elif NOISE_WEIGHTS == \"Cell\":\r\n","  #@markdown Cell\r\n","  NW = 'D:\\\\Weights\\\\unet_noise_cell_line.hdf5' #@param {type:\"string\"}\r\n","elif NOISE_WEIGHTS == \"Select\":\r\n","  print(\"Use popup window to select weights\")\r\n","  wp = filedialog.askopenfile(title=(\"Select Weights\"))\r\n","  NW = wp.name\r\n","\r\n","print(NW)\r\n","\r\n","if NR == True:\r\n","\r\n","  os.chdir(UNET_PATH)\r\n","  if UNET == False:\r\n","    !git clone --quiet https://github.com/zhixuhao/unet.git\r\n","    %cd unet\r\n","    UNET_PATH = os.path.join(UNET_PATH, \"unet\")\r\n","\r\n","  from model import *\r\n","  from data import *\r\n","  import numpy as np \r\n","  import cv2\r\n","  import os\r\n","  import glob\r\n","  import skimage.io as io\r\n","  import skimage.transform as trans\r\n","\r\n","  model = load_model(NW)\r\n","  test_path = INPUT_IMG_PATH\r\n","  save_path = NOISE_MAP\r\n","  save_path2 = IMG_SAVE_PATH\r\n","  container = np.zeros((M,N,1,1));\r\n","\r\n","  def bin_ndarray(ndarray, new_shape, operation='sum'):\r\n","\r\n","    operation = operation.lower()\r\n","    if not operation in ['sum', 'mean']:\r\n","        raise ValueError(\"Operation not supported.\")\r\n","    if ndarray.ndim != len(new_shape):\r\n","        raise ValueError(\"Shape mismatch: {} -> {}\".format(ndarray.shape,\r\n","                                                           new_shape))\r\n","    compression_pairs = [(d, c//d) for d,c in zip(new_shape,\r\n","                                                  ndarray.shape)]\r\n","    flattened = [l for p in compression_pairs for l in p]\r\n","    ndarray = ndarray.reshape(flattened)\r\n","    for i in range(len(new_shape)):\r\n","        op = getattr(ndarray, operation)\r\n","        ndarray = op(-1*(i+1))\r\n","    return ndarray\r\n","\r\n","  def image_normalized(file_path):\r\n","\r\n","      img = cv2.imread(file_path,0)\r\n","      img_shape = img.shape\r\n","      image_size = (img_shape[1],img_shape[0])\r\n","      img_standard = bin_ndarray(img*1.2, (M,N), operation='mean')\r\n","      #img_standard = cv2.resize(img, (M, M), interpolation=cv2.INTER_CUBIC)\r\n","      img_new = img_standard\r\n","      imgT = img_standard\r\n","      img_new = np.asarray([img_new / 255.])\r\n","      return img_new,image_size, imgT\r\n","\r\n","  for name in os.listdir(test_path):\r\n","    image_path = os.path.join(test_path,name)\r\n","    if os.path.isdir(image_path):\r\n","      continue\r\n","    ll = len(name)\r\n","    img,img_size, imgT = image_normalized(image_path)\r\n","    img = np.reshape(img,img.shape+(1,))\r\n","    results = model.predict(img)\r\n","    out = np.zeros(img.shape)\r\n","\r\n","    out = 255*results[0,:,:,0];\r\n","    \r\n","    cv2.imwrite(os.path.join(save_path, (\"%s\") % (name[0:ll-3]+'png')), out)\r\n","\r\n","    imgDN = imgT - out\r\n","\r\n","    cv2.imwrite(os.path.join(save_path2, (\"%s\") % (name[0:ll-3]+'png')), imgDN)\r\n","\r\n","    print(name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0DvedYGXj0Xk","cellView":"form"},"source":["#@markdown ___\r\n","#@markdown ## **G. Process Data**\r\n","#@markdown Process Selected Image Directories\r\n","os.chdir(ANCIS_PATH)\r\n","def bin_ndarray(ndarray, new_shape, operation='sum'):\r\n","    \"\"\"\r\n","    J.F. Sebastian\r\n","    Bins an ndarray in all axes based on the target shape, by summing or\r\n","        averaging.\r\n","\r\n","    Number of output dimensions must match number of input dimensions and \r\n","        new axes must divide old ones.\r\n","\r\n","    Example\r\n","    -------\r\n","    >>> m = np.arange(0,100,1).reshape((10,10))\r\n","    >>> n = bin_ndarray(m, new_shape=(5,5), operation='sum')\r\n","    >>> print(n)\r\n","\r\n","    [[ 22  30  38  46  54]\r\n","     [102 110 118 126 134]\r\n","     [182 190 198 206 214]\r\n","     [262 270 278 286 294]\r\n","     [342 350 358 366 374]]\r\n","\r\n","    \"\"\"\r\n","    operation = operation.lower()\r\n","    if not operation in ['sum', 'mean']:\r\n","        raise ValueError(\"Operation not supported.\")\r\n","    if ndarray.ndim != len(new_shape):\r\n","        raise ValueError(\"Shape mismatch: {} -> {}\".format(ndarray.shape,\r\n","                                                           new_shape))\r\n","    compression_pairs = [(d, c//d) for d,c in zip(new_shape,\r\n","                                                  ndarray.shape)]\r\n","    flattened = [l for p in compression_pairs for l in p]\r\n","    ndarray = ndarray.reshape(flattened)\r\n","    for i in range(len(new_shape)):\r\n","        op = getattr(ndarray, operation)\r\n","        ndarray = op(-1*(i+1))\r\n","    return ndarray\r\n","\r\n","def reject_outliers(data, m=2):\r\n","    JoeGreen = np.mean(data)\r\n","    STD = np.std(data)\r\n","    MAX = np.max(data)\r\n","    data[(data) > (MAX-m*STD)] = 0\r\n","    return data\r\n","\r\n","MP = 0\r\n","Num = 0\r\n","fin = 0\r\n","\r\n","Spath = PROC_PATH\r\n","if NR == True:\r\n","  PATH = IMG_SAVE_PATH\r\n","else:\r\n","  if Select == \"Train\":\r\n","    PATH = TRAIN_PATH\r\n","  elif Select == \"Test\":\r\n","    PATH = TEST_PATH\r\n","\r\n","if not os.path.exists(os.path.join(Spath, \"Labels\")):\r\n","  os.makedirs(os.path.join(Spath, \"Labels\"))\r\n","annoDir = os.path.join(Spath, \"Labels\")\r\n","\r\n","#@markdown Do You Wish to Process and Write Your Data to PROC_PATH?\r\n","Write = False #@param {type:\"boolean\"}\r\n","NME = Select\r\n","while fin == 0:\r\n","  print(NME)\r\n","  for name in os.listdir(PATH):\r\n","      \r\n","    if Select == \"Train\":\r\n","      path = os.path.join(PATH, name)\r\n","      path2 = os.path.join(LABEL_PATH, name)\r\n","      if PATH == VAL_PATH:\r\n","        path = os.path.join(VAL_PATH, name)\r\n","        path2 = os.path.join(VAL_LABEL_PATH, name)\r\n","    elif Select == \"Test\":\r\n","      path = os.path.join(PATH, name)\r\n","      path2 = ''\r\n","\r\n","    if os.path.isdir(path) or os.path.isdir(path2):\r\n","      continue\r\n","\r\n","    print(name)\r\n","    ll = len(name)\r\n","    # Get Extension\r\n","    if Num == 0:\r\n","      nme, ext = os.path.splitext(name)\r\n","\r\n","    if ext == '.tif' or ext == 'tiff':\r\n","      img = imread(path)\r\n","    else:\r\n","      img = cv2.imread(path,0)\r\n","\r\n","    img = img.astype('uint8')\r\n","\r\n","    # Normalize Images\r\n","    if NORM == True:\r\n","      img = reject_outliers(img, 2)\r\n","      img = cv2.normalize(img, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)    \r\n","\r\n","    # Resize\r\n","    if Resize == True:\r\n","      #img = cv2.resize(img,(M,N),interpolation=cv2.INTER_LINEAR)\r\n","      img = bin_ndarray(img*10, (M,N), operation='mean')\r\n","\r\n","    if NORM == True:\r\n","      img = cv2.normalize(img, None, alpha=0, beta=180, norm_type=cv2.NORM_MINMAX)\r\n","      img = cv2.GaussianBlur(img,(3,3),0)\r\n","\r\n","    # Show Images as They are Imported and Processed\r\n","    #cv2_imshow(img)\r\n","    sh = img.shape\r\n","\r\n","    # Pixel Average\r\n","    if PATH != VAL_PATH:\r\n","      if len(sh) == 3 or 4:\r\n","        MP = (np.mean(img,axis=(0,1)) + MP)\r\n","      else:\r\n","        MP = (np.mean(img) + MP)\r\n","\r\n","    Num = Num + 1\r\n","\r\n","    # Write Images to Processed Folder\r\n","    if Write == True:\r\n","      if not os.path.exists(os.path.join(Spath, NME, name[0:ll-4], \"images\")):\r\n","        os.makedirs(os.path.join(Spath, NME, name[0:ll-4], \"images\"))\r\n","      if NME == \"Val\" and VAL == False:\r\n","        psimg = np.zeros(img.shape)\r\n","        lbl = np.ones(img.shape)\r\n","        cv2.imwrite(os.path.join(Spath, NME, name[0:ll-4], \"images\", name[0:ll-3]+'png'),psimg)\r\n","        cv2.imwrite(os.path.join(Spath,\"Labels\",\"Val1.png\"),lbl)\r\n","      else:\r\n","        cv2.imwrite(os.path.join(Spath, NME, name[0:ll-4], \"images\", name[0:ll-3]+'png'), img)\r\n","    \r\n","    if Select == \"Train\":\r\n","      if ext == '.tif' or ext == '.tiff':\r\n","        img2 = imread(path2)\r\n","      else:\r\n","        img2 = cv2.imread(path2)\r\n","      img2 = label(img2)\r\n","      img2 = cv2.resize(img2,(M,N),interpolation=cv2.INTER_NEAREST)\r\n","      P = img2.max()\r\n","      out = np.zeros([M, N, P])\r\n","      \r\n","      # Write Labels to Processed Folder\r\n","      if Write == True:\r\n","        cv2.imwrite(os.path.join(Spath,\"Labels\",name[0:ll-3]+'png'),img2)\r\n","        if not os.path.exists(os.path.join(Spath, NME, name[0:ll-4], \"masks\")):\t\t\r\n","          os.mkdir(os.path.join(Spath, NME, name[0:ll-4], \"masks\"))\r\n","        for n in range(1,P+1):\r\n","          ind = np.where(img2 == n)\r\n","          for i in range(0,ind[0].shape[0]-1):\r\n","            out[ind[0][i],ind[1][i],n-1] = 255\r\n","          cv2.imwrite(os.path.join(Spath, NME, name[0:ll-4], \"masks\", name[0:ll-4] + \"_\" + str(n-1) + \".png\"),out[:,:,n-1])\r\n","      elif Write == True and VAL == False and PATH == VAL_PATH:\r\n","        if not os.path.exists(os.path.join(Spath, NME, name[0:ll-4], \"masks\")):\t\t\r\n","          os.mkdir(os.path.join(Spath, NME, name[0:ll-4], \"masks\"))\r\n","        for n in range(1,2):\r\n","          ind = np.where(img2 == n)\r\n","          for i in range(0,ind[0].shape[0]-1):\r\n","            out[ind[0][i],ind[1][i],n-1] = 255\r\n","          cv2.imwrite(os.path.join(Spath, NME, name[0:ll-4], \"masks\", name[0:ll-4] + \"_\" + str(n-1) + \".png\"),out[:,:,n-1])\r\n","\r\n","    elif NME == \"Val\":\r\n","      #if VAL == True:\r\n","      if ext == '.tif' or ext == '.tiff':\r\n","        img2 = imread(path2)\r\n","      else:\r\n","        img2 = cv2.imread(path2)\r\n","      img2 = label(img2)\r\n","      img2 = cv2.resize(img2,(M,N),interpolation=cv2.INTER_NEAREST)\r\n","      P = img2.max()\r\n","      out = np.zeros([M, N, P])\r\n","\r\n","      # Write Labels to Processed Folder\r\n","      if Write == True:\r\n","        cv2.imwrite(os.path.join(Spath,\"Labels\",name[0:ll-3]+'png'),img2)\r\n","        if not os.path.exists(os.path.join(Spath, NME, name[0:ll-4], \"masks\")):\t\t\r\n","          os.mkdir(os.path.join(Spath, NME, name[0:ll-4], \"masks\"))\r\n","        for n in range(1,P+1):\r\n","          ind = np.where(img2 == n)\r\n","          for i in range(0,ind[0].shape[0]-1):\r\n","            out[ind[0][i],ind[1][i],n-1] = 255\r\n","          cv2.imwrite(os.path.join(Spath, NME, name[0:ll-4], \"masks\", name[0:ll-4] + \"_\" + str(n-1) + \".png\"),out[:,:,n-1])\r\n","\r\n","    elif Select == \"Test\":\r\n","      img2 = np.ones([M,N])\r\n","      out = np.zeros([M, N, 1])\r\n","\r\n","      # Write Labels to Processed Folder\r\n","      if Write == True:\r\n","        if not os.path.exists(os.path.join(Spath, NME, name[0:ll-4], \"masks\")):\t\t\r\n","          os.mkdir(os.path.join(Spath, NME, name[0:ll-4], \"masks\"))\r\n","        if not os.path.exists(os.path.join(Spath, \"Labels\")):\t\t\r\n","          os.mkdir(os.path.join(Spath, \"Labels\"))\r\n","        for n in range(1,2):\r\n","          ind = np.where(img2 == n)\r\n","          for i in range(0,ind[0].shape[0]-1):\r\n","            out[ind[0][i],ind[1][i],n-1] = 255\r\n","          cv2.imwrite(os.path.join(Spath, NME, name[0:ll-4], \"masks\", name[0:ll-4] + \"_\" + str(n-1) + \".png\"),out[:,:,n-1])\r\n","          cv2.imwrite(os.path.join(Spath,\"Labels\",name),out)\r\n","\r\n","  if NME == \"Train\":\r\n","    if VAL == True:\r\n","      PATH = VAL_PATH\r\n","    elif VAL == False:\r\n","      VTempI = os.path.join(PROC_PATH,\"VTemp\",\"images\")\r\n","      VTempM = os.path.join(PROC_PATH,\"VTemp\",\"masks\")\r\n","      os.makedirs(VTempI)\r\n","      os.makedirs(VTempM)\r\n","      cv2.imwrite(os.path.join(VTempI,\"Val1.png\"), np.ones(img.shape))\r\n","      cv2.imwrite(os.path.join(VTempM,\"Val1.png\"), np.ones(img.shape))\r\n","      VAL_PATH = VTempI\r\n","      VAL_LABEL_PATH = VTempM\r\n","      PATH = VAL_PATH\r\n","    NME = \"Val\"\r\n","  else:\r\n","    fin = 1\r\n","    if VAL == False:\r\n","      if os.path.exists(os.path.join(PROC_PATH,\"VTemp\")):\r\n","        shutil.rmtree(os.path.join(PROC_PATH,\"VTemp\"))\r\n","      VAL_PATH = os.path.join(PROC_PATH,\"Val\")\r\n","\r\n","if Num == 0:\r\n","  Num = 1\r\n","MP = MP/Num\r\n","if len(sh) != 3 or 4:\r\n","  MP2 = np.array([MP,MP,MP])\r\n","else:\r\n","  MP2 = MP"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G5Br139VBZdH"},"source":["# **III. Configuration**\n"]},{"cell_type":"markdown","metadata":{"id":"ApbRHFVD-gky"},"source":["\n","### **Configuration Parameters**\n","\n","Breif explanation of the configuration parameters available below.\n","\n","--**trainDir**: Training Directory Containing Images (default = /root/dataset/Train)\n","\n","--**valDir**: Validation Image Directory for Training (default = /root/dataset/Validation)\n","\n","--**cacheDir**: Directory for Training Cache Files (default = /root/ANCIS-Pytorch/cache)\n","\n","--**batch_size**: Number of Images Processed at a Time.  More = faster, but the number is limited by available memory (default = 2)\n","\n","--**multi_gpu**: Train Using Multiple GPUs, where Available (default = False)\n","\n","--**num_workers**: Number of Batches Loaded at a Time (default = 4)\n","\n","--**init_lr**: Initial Learning Rate (default = 0.001)\n","\n","--**num_epochs**: Number of Training Epochs. More may result in better training at the cost of time. Too many could lead to overfitting and reduced accuracy. (default = 200)\n","\n","--**decayEpochs**: Which Epoch to Begin Decaying the Learning Rate (default = 100)\n","\n","--**Dec_weight_Dst**: Saving Directory for Trained Detection Network Weights. (default = /content/drive/My Drive/Colab Notebooks/ANCIS/Dec_Weights)\n","\n","--**Seg_weight_Dst**: Saving Directory for Trained Segmentation Network Weights. (default = /content/drive/My Drive/Colab Notebooks/ANCIS/Seg_Weights)\n","\n","--**Dec_log_Files**: Saving Directory for Training Statistics Log Files. (default = /content/drive/My Drive/Colab Notebooks/ANCIS/Dec_Weights)\n","\n","--**Seg_log_Files**: Saving Directory for Training Statistics Log Files. (default = /content/drive/My Drive/Colab Notebooks/ANCIS/Seg_Weights)\n","\n","--**img_height**: Height, or Rows, of Training Images (default = 512)\n","\n","--**img_width**: Width, or Columns, or Training Images (default = 512)\n","\n","--**num_classes**: Number of Classes to Train on, as in \"Nucleus\" and \"Background\". (default = 2)\n","\n","--**top_k**: Maximum Number of Training Instances to Use. (default = 200)\n","\n","--**conf_thresh**: Confidence Threshold. Minimum Confidence Score for a Positive Detection for Testing or Validation. (default = 0.5)\n","\n","--**nms_thresh**: Near Maximum Suppression (NMS). Higher values allow for more detections, at the cost of more overlaps. (default = 0.7)\n","\n","--**seg_thresh**: Segmentation Threshold. Minimum score for a positive segmentation. (default = 0.5)"]},{"cell_type":"code","metadata":{"id":"6pB-x1mygO8w","cellView":"form"},"source":["#@markdown ___\n","#@markdown ## **1. Network Configuration Parameters**\n","#@markdown\n","%cd C:\\\\Users\\\\CAM417\\\\Python Code\\\\ANCIS-Pytorch\n","\n","#@markdown ### **A. Train Directory**\n","trainDir = PROC_PATH + \"\\Train\" #@param {type: \"raw\"}\n","#@markdown ### **B. Test Directory**\n","testDir = PROC_PATH + \"\\Test\" #@param {type: \"raw\"}\n","#@markdown ### **C. Validation Directory**\n","valDir = VAL_PATH #@param {type: \"raw\"}\n","annoDir = os.path.join(PROC_PATH, \"Labels\")\n","#@markdown ### **D. Cache Directory**\n","cacheDir = \"C:\\\\Users\\\\CAM417\\\\Python Code\\\\ANCIS-Pytorch\\\\cache\" #@param {type: \"string\"}\n","if not os.path.exists(cacheDir):\n","  os.makedirs(cacheDir)\n","#@markdown ### **E. Batch Size**\n","batch_size =  2#@param {type: \"integer\"}\n","#@markdown ### **F. Use Multiple GPUs (local)**\n","multi_gpu = False #@param {type: \"boolean\"}\n","#@markdown ### **G. Number of Workers**\n","num_workers =  0#@param {type: \"integer\"}\n","#@markdown ### **H. Initial Learning Rate**\n","init_lr = 0.001 #@param {type: \"number\"}\n","#@markdown ### **I. Number of Epochs**\n","num_epochs =  5#@param {type: \"integer\"}\n","#@markdown ### **J. Epoch to Begin Learning Rate Decay**\n","decayEpoch =  4#@param {type: \"integer\"}\n","#@markdown ### **K. Detection Weights Save Path**\n","Dec_weight_Dst = \"C:\\\\Users\\\\CAM417\\\\Python Code\\\\ANCIS-Pytorch\\\\Dec_Weights\" #@param {type: \"string\"}\n","if not os.path.exists(Dec_weight_Dst):\n","  os.makedirs(Dec_weight_Dst)\n","#@markdown ### **L. Save Path for Segmentation Weights**\n","Seg_weight_Dst = \"C:\\\\Users\\\\CAM417\\\\Python Code\\\\ANCIS-Pytorch\\\\Seg_Weights\" #@param {type: \"string\"}\n","if not os.path.exists(Seg_weight_Dst):\n","  os.makedirs(Seg_weight_Dst)\n","#@markdown ### **M. Save Path for Detection Training Logs**\n","Dec_log_Files = \"C:\\\\Users\\\\CAM417\\\\Python Code\\\\ANCIS-Pytorch\\\\Dec_Weights\" #@param {type: \"string\"}\n","if not os.path.exists(Dec_log_Files):\n","  os.makedirs(Dec_log_Files)\n","#@markdown ### **N. Save Path for Segmentation Training Logs**\n","Seg_log_Files = \"C:\\\\Users\\\\CAM417\\\\Python Code\\\\ANCIS-Pytorch\\\\Seg_Weights\" #@param {type: \"string\"}\n","if not os.path.exists(Seg_log_Files):\n","  os.makedirs(Seg_log_Files)\n","#@markdown ### **O. Number of Classes**\n","num_classes = 2 #@param {type: \"integer\"}\n","#@markdown ### **P. Number of Detections to Keep**\n","top_k = 200 #@param {type: \"integer\"}\n","#@markdown ### **Q. Confidence Threshold**\n","conf_thresh = 0.5 #@param {type: \"number\"}\n","#@markdown ### **R. NMS Threshold**\n","nms_thresh = 0.7 #@param {type: \"number\"}\n","#@markdown ### **S. Segmentation threshold**\n","seg_thresh = 0.5 #@param {type: \"number\"}\n","#@markdown ### **T. Visualize Augmented Training Datasets**\n","vis = False #@param {type: \"boolean\"}\n","\n","imgSuffix = '.png'\n","annoSuffix = '.png'\n","img_height = M\n","img_width = M"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"COkggCvEiv7E"},"source":["# **III. Detection (Region Proposal) Network**"]},{"cell_type":"code","metadata":{"id":"kVI3NB5-EupZ","cellView":"form"},"source":["os.chdir(ANCIS_PATH)\n","#@markdown ___\n","#@markdown ## **1. Train Detection Network**\n","#@markdown\n","\n","#@markdown Train the Single Shot Detector (SSD) Used by ANCIS for region detection.\n","\n","from dec_utils import *\n","from models import dec_net\n","from dec_utils import dec_transforms, dec_eval, dec_dataset_kaggle\n","\n","def collater(data):\n","    imgs = []\n","    bboxes = []\n","    labels = []\n","    for sample in data:\n","        imgs.append(sample[0])\n","        bboxes.append(sample[1])\n","        labels.append(sample[2])\n","    return torch.stack(imgs,0), bboxes, labels\n","\n","data_transforms = {\n","'train': dec_transforms.Compose([dec_transforms.ConvertImgFloat(),\n","                                dec_transforms.PhotometricDistort(),\n","                                dec_transforms.Expand(),\n","                                dec_transforms.RandomSampleCrop(),\n","                                dec_transforms.RandomMirror_w(),\n","                                dec_transforms.RandomMirror_h(),\n","                                dec_transforms.Resize(img_height, img_width),\n","                                dec_transforms.ToTensor()]),\n","\n","'val': dec_transforms.Compose([dec_transforms.ConvertImgFloat(),\n","                              dec_transforms.Resize(img_height, img_width),\n","                              dec_transforms.ToTensor()])\n","}\n","\n","dsets = {'train': dec_dataset_kaggle.NucleiCell(trainDir, annoDir, data_transforms['train'],\n","                                            imgSuffix=imgSuffix, annoSuffix=annoSuffix),\n","    'val': dec_dataset_kaggle.NucleiCell(valDir, annoDir, data_transforms['val'],\n","                                          imgSuffix=imgSuffix, annoSuffix=annoSuffix)}\n","\n","dataloader = torch.utils.data.DataLoader(dsets['train'],\n","                                    batch_size = batch_size,\n","                                    shuffle = True,\n","                                    num_workers = num_workers,\n","                                    collate_fn = collater,\n","                                    pin_memory = True)\n","\n","model = dec_net.resnetssd50(pretrained=True, num_classes=num_classes)\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","if multi_gpu:\n","  model = nn.DataParallel(model)\n","model = model.to(device)\n","\n","optimizer = optim.SGD(model.parameters(), lr=init_lr, momentum=0.9)\n","scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[decayEpoch, num_epochs], gamma=0.1)\n","criterion = DecLoss(img_height=img_height,\n","                img_width= img_width,\n","                num_classes=num_classes,\n","                variances=[0.1, 0.2])\n","\n","if vis:\n","  for idx in range(len(dsets['train'])):\n","      img, bboxes, labels = dsets['train'].__getitem__(idx)\n","      img = img.numpy().transpose(1, 2, 0)*255\n","      bboxes = bboxes.numpy()\n","      labels = labels.numpy()\n","      for bbox in bboxes:\n","          y1, x1, y2, x2 = bbox\n","          cv2.rectangle(img, (x1, y1), (x2, y2), (255, 255, 255), 2, lineType=1)\n","      cv2_imshow(np.uint8(img))\n","      k = cv2.waitKey(0)\n","      if k & 0xFF == ord('q'):\n","          cv2.destroyAllWindows()\n","          exit()\n","  cv2.destroyAllWindows()\n","\n","# for validation data -----------------------------------\n","detector = Detect(num_classes=num_classes,\n","              top_k=top_k,\n","              conf_thresh=conf_thresh,\n","              nms_thresh=nms_thresh,\n","              variance=[0.1, 0.2])\n","anchorGen = Anchors(img_height, img_width)\n","anchors = anchorGen.forward()\n","if not os.path.exists(cacheDir):\n","  os.mkdir(cacheDir)\n","# --------------------------------------------------------\n","train_loss_dict = []\n","ap05_dict = []\n","ap07_dict = []\n","for epoch in range(num_epochs):\n","  print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","  print('-' * 10)\n","\n","  for phase in ['train', 'val']:\n","      if phase == 'train':\n","          scheduler.step()\n","          model.train()\n","          running_loss = 0.0\n","          for inputs, bboxes, labels in dataloader:\n","              inputs = inputs.to(device)\n","              # zero the parameter gradients\n","              optimizer.zero_grad()\n","\n","              # forward\n","              # track history if only in train\n","              with torch.set_grad_enabled(phase == 'train'):\n","                  outputs = model(inputs)\n","                  loss_locs, loss_conf = criterion(outputs, bboxes, labels)\n","                  loss = loss_locs + loss_conf\n","                  # backward + optimize only if in training phase\n","                  if phase == 'train':\n","                      loss.backward()\n","                      optimizer.step()\n","\n","              # statistics\n","              running_loss += loss.item() * inputs.size(0)\n","\n","          epoch_loss = running_loss / len(dsets[phase])\n","\n","          print('{} Loss: {:.4f}'.format(phase, epoch_loss))\n","          train_loss_dict.append(epoch_loss)\n","          np.savetxt(Dec_log_Files + '/dec_train_loss.txt', train_loss_dict, fmt='%.6f')\n","          if epoch % 5 == 0:\n","              torch.save(model.state_dict(),\n","                        os.path.join(Dec_weight_Dst, '{:d}_{:.4f}_model.pth'.format(epoch, epoch_loss)))\n","          torch.save(model.state_dict(), os.path.join(Dec_weight_Dst, 'end_model.pth'))\n","\n","      else:\n","          model.eval()   # Set model to evaluate mode\n","          #model.eval()   # Set model to evaluate mode\n","          det_file = os.path.join(cacheDir, 'detections.pkl')\n","          all_boxes = [[[] for _ in range(len(dsets['val']))] for _ in range(num_classes)]\n","          for img_idx in range(len(dsets['val'])):\n","              ori_img = dsets['val'].load_img(img_idx)\n","              h,w,c = ori_img.shape\n","              inputs, gt_bboxes, gt_labels = dsets['val'].__getitem__(img_idx)  # [3, 512, 640], [3, 4], [3, 1]\n","              # run model\n","              inputs = inputs.unsqueeze(0).to(device)\n","              with torch.no_grad():\n","                  locs, conf = model(inputs)\n","              detections = detector(locs, conf, anchors)\n","              for cls_idx in range(1, detections.size(1)):\n","                  dets = detections[0, cls_idx, :]\n","                  mask = dets[:, 0].gt(0.).expand(5, dets.size(0)).t()\n","                  dets = torch.masked_select(dets, mask).view(-1, 5)\n","                  if dets.shape[0] == 0:\n","                      continue\n","                  pred_boxes = dets[:, 1:].cpu().numpy()\n","                  pred_score = dets[:, 0].cpu().numpy()\n","                  pred_boxes[:,0] /= img_height\n","                  pred_boxes[:,1] /= img_width\n","                  pred_boxes[:,2] /= img_height\n","                  pred_boxes[:,3] /= img_width\n","                  pred_boxes[:,0] *= h\n","                  pred_boxes[:,1] *= w\n","                  pred_boxes[:,2] *= h\n","                  pred_boxes[:,3] *= w\n","                  cls_dets = np.hstack((pred_boxes, pred_score[:, np.newaxis])).astype(np.float32, copy=False)\n","                  all_boxes[cls_idx][img_idx] = cls_dets\n","\n","          with open(det_file, 'wb') as f:\n","              pickle.dump(all_boxes, f, pickle.HIGHEST_PROTOCOL)\n","              f.close()\n","\n","          for cls_ind, cls in enumerate(dsets['val'].labelmap):\n","              filename = dec_eval.get_voc_results_file_template('test', cls, cacheDir)\n","              with open(filename, 'wt') as f:\n","                  for im_ind, index in enumerate(dsets['val'].img_files):\n","                      dets = all_boxes[cls_ind+1][im_ind]\n","                      if dets == []:\n","                          continue\n","                      for k in range(dets.shape[0]):\n","                          # format: [img_file  confidence, y1, x1, y2, x2] save to call for multiple times\n","                          f.write('{:s} {:.3f} {:.1f} {:.1f} {:.1f} {:.1f}\\n'.format(index,\n","                                                                                    dets[k, -1],\n","                                                                                    dets[k, 0],\n","                                                                                    dets[k, 1],\n","                                                                                    dets[k, 2],\n","                                                                                    dets[k, 3]))\n","\n","          #ap05, ap07 = dec_eval.do_python_eval(dsets=dsets['val'],\n","          #                                    output_dir=cacheDir,\n","          #                                    offline=False,\n","          #                                    use_07=True)\n","          #print('ap05:{:.4f}, ap07:{:.4f}'.format(ap05, ap07))\n","          #ap05_dict.append(ap05)\n","          #np.savetxt(Dec_log_Files + '/dec_ap_05.txt', ap05_dict, fmt='%.6f')\n","          #ap07_dict.append(ap07)\n","          #np.savetxt(Dec_log_Files + '/dec_ap_07.txt', ap07_dict, fmt='%.6f')\n","print('Finish')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"96sqaKDj__VW","cellView":"form"},"source":["#@markdown ___\n","#@markdown ## **2. Test Detection Network**\n","os.chdir(ANCIS_PATH)\n","print(os.getcwd())\n","#@markdown Test Region Proposal (Detection) Network using pre-trained weights\n","\n","#@markdown ### **A. Select Detection Network Weights for Testing**\n","#@markdown *Update paths to reflect local directories. Use Select to find alternate weights.*\n","DECWEIGHT = 'Combine' #@param ['Tissue', 'Cell', 'Combine', 'Kaggle', 'Select'] {type: 'string'}\n","if DECWEIGHT == 'Tissue':\n","  #@markdown Tissue:\n","  weightTst = \"D:\\\\Weights\\\\ANCIS\\\\DecWeights\\\\ANCIS_DecWeight_Cell\\\\end_model.pth\" #@param {type: \"string\"}\n","elif DECWEIGHT == 'Cell':\n","  #@markdown Cell:\n","  weightTst = \"D:\\\\Weights\\\\ANCIS\\\\DecWeights\\\\ANCIS_DecWeight_Cell\\\\end_model.pth\" #@param {type: \"string\"}\n","elif DECWEIGHT == 'Combine':\n","  #@markdown Combine:\n","  weightTst = \"D:\\Weights\\ANCIS\\DecWeights\\ANCIS_DecWeight_Combine\\end_model.pth\" #@param {type: \"string\"}\n","elif DECWEIGHT == 'Kaggle':\n","  #@markdown Kaggle:\n","  weightTst = \"D:\\Weights\\ANCIS\\DecWeights\\ANCIS_DecWeight_Kaggle\\end_model.pth\" #@param {type: \"string\"}\n","elif DECWEIGHT == 'Select':\n","  print('Use popup window to select weights')\n","  weights = filedialog.askopenfile(title=('Select Weights'))\n","  weightTst = weights.name\n","\n","#@markdown ### **B. Detection Test Result Save Path**\n","SAVE_PATH = \"D:\\\\Images\\\\Results\" #@param {type: \"string\"}\n","if not os.path.exists(SAVE_PATH):\n","  os.makedirs(SAVE_PATH)\n","\n","import argparse\n","\n","from dec_utils import *\n","from models import dec_net\n","#from dec_utils import dec_transforms\n","import cv2\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from dec_utils import dec_transforms, dec_eval, dec_dataset_kaggle\n","\n","def load_dec_weights(dec_model, dec_weights):\n","    print('Resuming detection weights from {} ...'.format(dec_weights))\n","    dec_dict = torch.load(dec_weights, map_location=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))\n","    dec_dict_update = {}\n","    for k in dec_dict:\n","        if k.startswith('module') and not k.startswith('module_list'):\n","            dec_dict_update[k[7:]] = dec_dict[k]\n","        else:\n","            dec_dict_update[k] = dec_dict[k]\n","    dec_model.load_state_dict(dec_dict_update, strict=True)\n","    return dec_model\n","\n","data_transforms = dec_transforms.Compose([dec_transforms.ConvertImgFloat(),\n","                                    dec_transforms.Resize(M, M),\n","                                    dec_transforms.ToTensor()])\n","\n","#TD = os.path.join(PROC_PATH,\"Test\")\n","print(testDir)\n","print(annoDir)\n","dsets = dec_dataset_kaggle.NucleiCell(testDir, annoDir, data_transforms,\n","                    imgSuffix=imgSuffix, annoSuffix=annoSuffix)\n","\n","model = dec_net.resnetssd50(pretrained=True, num_classes=num_classes)\n","model = load_dec_weights(model, weightTst)\n","\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","model.eval()\n","detector = Detect(num_classes=num_classes,\n","                  top_k=top_k,\n","                  conf_thresh=conf_thresh,\n","                  nms_thresh=nms_thresh,\n","                  variance=[0.1, 0.2])\n","anchorGen = Anchors(M, M)\n","anchors = anchorGen.forward()\n","#cv2.namedWindow('img')\n","names = dsets.load_img_ids()\n","#print(names[0].split(\"\\\\\")[-1].split(\".\")[0])\n","for img_idx in range(len(dsets)):\n","    ori_img = dsets.load_img(img_idx)\n","    h,w,c = ori_img.shape\n","    inputs, gt_bboxes, _ = dsets.__getitem__(img_idx)  # [3, 512, 640], [3, 4], [3, 1]\n","    inputs = inputs.unsqueeze(0).to(device)\n","    ames = names[img_idx]\n","    ame = (os.path.basename(ames))\n","    print(ame)\n","    with torch.no_grad():\n","        locs, conf = model(inputs)\n","    detections = detector(locs, conf, anchors)\n","    for cls_idx in range(1, detections.size(1)):\n","        dets = detections[0, cls_idx, :]\n","        mask = dets[:, 0].gt(0.).expand(5, dets.size(0)).t()\n","        dets = torch.masked_select(dets, mask).view(-1, 5)\n","        if dets.shape[0] == 0:\n","            continue\n","        dets = dets.cpu().numpy()\n","        for i in range(dets.shape[0]):\n","            box = dets[i,1:]\n","            score = dets[i,0]\n","            y1,x1,y2,x2 = box\n","            y1 = float(y1)/M\n","            x1 = float(x1)/M\n","            y2 = float(y2)/M\n","            x2 = float(x2)/M\n","            y1 = int(float(y1)*h)\n","            x1 = int(float(x1)*w)\n","            y2 = int(float(y2)*h)\n","            x2 = int(float(x2)*w)\n","            cv2.rectangle(ori_img, (x1, y1), (x2, y2), (0, 255, 0), 2, 2)\n","            cv2.putText(ori_img, \"%.2f\"%score, (x1, y1 + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6,\n","                        (255, 0, 255))\n","    _, ax = plt.subplots(1, figsize=(16, 16))\n","    ax.axis('off')\n","    plt.imshow(ori_img.astype('uint8'),clim=(0.0, 1.0))\n","    plt.show()\n","    cv2.imwrite(os.path.join(SAVE_PATH, ame), ori_img)\n","    #k = cv2.waitKey(0)\n","    #if k & 0xFF == ord('q'):\n","       # cv2.destroyAllWindows()\n","      #  exit()\n","cv2.destroyAllWindows()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rBmNbjb93-Rd"},"source":["# **IV. Instance Segmentation**"]},{"cell_type":"code","metadata":{"id":"zRDR9l3ju5LV","cellView":"form"},"source":["os.chdir(ANCIS_PATH)\n","#@markdown ___\n","#@markdown ## **1. Train Segmentation Network**\n","\n","#@markdown Train the Instance Segmentation Network.  Must either train the detection (region proposal network) first, or upload pretrained weights.\n","#@markdown\n","\n","#@markdown ### **A. Select Detection Network Weights to use for Segmentation Training**\n","DECWEIGHT = 'Combine' #@param ['Tissue', 'Cell', 'Combine', 'Kaggle', 'Select'] {type: 'string'}\n","if DECWEIGHT == 'Tissue':\n","  #@markdown Tissue:\n","  dec_weights = \"D:\\\\Weights\\\\ANCIS\\\\DecWeights\\\\ANCIS_DecWeight_Cell\\\\end_model.pth\" #@param {type: \"string\"}\n","elif DECWEIGHT == 'Cell':\n","  #@markdown Cell:\n","  dec_weights = \"D:\\\\Weights\\\\ANCIS\\\\DecWeights\\\\ANCIS_DecWeight_Cell\\\\end_model.pth\" #@param {type: \"string\"}\n","elif DECWEIGHT == 'Combine':\n","  #@markdown Combine:\n","  dec_weights = \"D:\\Weights\\ANCIS\\DecWeights\\ANCIS_DecWeight_Combine\\end_model.pth\" #@param {type: \"string\"}\n","elif DECWEIGHT == 'Kaggle':\n","  #@markdown Kaggle:\n","  dec_weights = \"D:\\Weights\\ANCIS\\DecWeights\\ANCIS_DecWeight_Kaggle\\end_model.pth\" #@param {type: \"string\"}\n","elif DECWEIGHT == 'Select':\n","  print('Use popup window to select weights')\n","  weights = filedialog.askopenfile(title=('Select Weights'))\n","  dec_weights = weights.name\n","\n","import argparse\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","\n","from seg_utils import *\n","from dec_utils import *\n","from seg_utils import seg_transforms, seg_dataset_kaggle, seg_eval_kaggle\n","\n","from models import dec_net_seg, seg_net\n","import cv2\n","import os\n","parser = argparse.ArgumentParser(description='Detection Training (MultiGPU)')\n","parser.add_argument('--img_height', default=img_height, type=str, help='train image height')\n","parser.add_argument('--img_width', default=img_width, type=str, help='train image width')\n","parser.add_argument('--conf_thresh', default=conf_thresh, type=str, help='Detection Confidence Threshold')\n","parser.add_argument('--seg_thresh', default=seg_thresh, type=str, help='Detection Segmentation Threshold')\n","args = parser.parse_args(\"\")\n","def collater(data):\n","    imgs = []\n","    bboxes = []\n","    labels = []\n","    masks = []\n","    for sample in data:\n","        imgs.append(sample[0])\n","        bboxes.append(sample[1])\n","        labels.append(sample[2])\n","        masks.append(sample[3])\n","    return torch.stack(imgs,0), bboxes, labels, masks\n","\n","def load_dec_weights(dec_model, dec_weights):\n","    print('Resuming detection weights from {} ...'.format(dec_weights))\n","    dec_dict = torch.load(dec_weights)\n","    dec_dict_update = {}\n","    for k in dec_dict:\n","        if k.startswith('module') and not k.startswith('module_list'):\n","            dec_dict_update[k[7:]] = dec_dict[k]\n","        else:\n","            dec_dict_update[k] = dec_dict[k]\n","    dec_model.load_state_dict(dec_dict_update, strict=True)\n","    return dec_model\n","\n","# ................. Training Code .................\n","\n","#-----------------load detection model -------------------------\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","dec_model = dec_net_seg.resnetssd50(pretrained=False, num_classes=num_classes)\n","dec_model = load_dec_weights(dec_model, dec_weights)\n","dec_model = dec_model.to(device)\n","#-------------------------------------------------------------------\n","dec_model.eval()        # detector set to 'evaluation' mode\n","for param in dec_model.parameters():\n","    param.requires_grad = False\n","#-----------------load segmentation model -------------------------\n","seg_model =  seg_net.SEG_NET(num_classes=num_classes)\n","seg_model= seg_model.to(device)\n","##--------------------------------------------------------------\n","data_transforms = {\n","    'train': seg_transforms.Compose([seg_transforms.ConvertImgFloat(),\n","                                      seg_transforms.PhotometricDistort(),\n","                                      seg_transforms.Expand(),\n","                                      seg_transforms.RandomSampleCrop(),\n","                                      seg_transforms.RandomMirror_w(),\n","                                      seg_transforms.RandomMirror_h(),\n","                                      seg_transforms.Resize(img_height, img_width),\n","                                      seg_transforms.ToTensor()]),\n","\n","    'val': seg_transforms.Compose([seg_transforms.ConvertImgFloat(),\n","                                    seg_transforms.Resize(img_height, img_width),\n","                                    seg_transforms.ToTensor()])\n","}\n","\n","\n","dsets = {'train': seg_dataset_kaggle.NucleiCell(trainDir, annoDir, data_transforms['train'],\n","                              imgSuffix=imgSuffix, annoSuffix=annoSuffix),\n","          'val': seg_dataset_kaggle.NucleiCell(valDir, annoDir, data_transforms['val'],\n","                              imgSuffix=imgSuffix, annoSuffix=annoSuffix)}\n","\n","dataloader = torch.utils.data.DataLoader(dsets['train'],\n","                                          batch_size = batch_size,\n","                                          shuffle = True,\n","                                          num_workers = num_workers,\n","                                          collate_fn = collater,\n","                                          pin_memory = True)\n","\n","\n","\n","optimizer = optim.Adam(params=filter(lambda p: p.requires_grad, seg_model.parameters()), lr=init_lr)\n","scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.98, last_epoch=-1)\n","criterion = SEG_loss(height=img_height, width=img_width)\n","\n","\n","if vis:\n","    cv2.namedWindow('img')\n","    for idx in range(len(dsets['train'])):\n","        img, bboxes, labels, masks = dsets['train'].__getitem__(idx)\n","        img = img.numpy().transpose(1, 2, 0).copy()*255\n","        print(img.shape)\n","        bboxes = bboxes.numpy()\n","        labels = labels.numpy()\n","        masks = masks.numpy()\n","        for idx in range(bboxes.shape[0]):\n","            y1, x1, y2, x2 = bboxes[idx,:]\n","            y1 = int(y1)\n","            x1 = int(x1)\n","            y2 = int(y2)\n","            x2 = int(x2)\n","            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 255, 255), 2, lineType=1)\n","            mask = masks[idx, :, :]\n","            img = map_mask_to_image(mask, img, color=np.random.rand(3))\n","        cv2.imshow('img', img)\n","        k = cv2.waitKey(0)\n","        if k & 0xFF == ord('q'):\n","            cv2.destroyAllWindows()\n","            exit()\n","    cv2.destroyAllWindows()\n","\n","# for validation data -----------------------------------\n","detector = Detect(num_classes=num_classes,\n","                  top_k=top_k,\n","                  conf_thresh=conf_thresh,\n","                  nms_thresh=nms_thresh,\n","                  variance=[0.1, 0.2])\n","anchorGen = Anchors(img_height, img_width)\n","anchors = anchorGen.forward()\n","# --------------------------------------------------------\n","train_loss_dict = []\n","ap05_dict = []\n","ap07_dict = []\n","loss2 = 0.5\n","for epoch in range(num_epochs):\n","    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","    print('-' * 10)\n","\n","    for phase in ['train', 'val']:\n","        if phase == 'train':\n","            scheduler.step()\n","            seg_model.train()\n","            running_loss = 0.0\n","            for inputs, bboxes, labels, masks in dataloader:\n","                inputs = inputs.to(device)\n","                with torch.no_grad():\n","                    locs, conf, feat_seg = dec_model(inputs)\n","                    detections = detector(locs, conf, anchors)\n","\n","                optimizer.zero_grad()\n","                with torch.enable_grad():\n","                    outputs = seg_model(detections, feat_seg)\n","                    loss = criterion(outputs, bboxes, labels, masks)\n","                    if loss is None:\n","                        loss = loss2\n","                    else:\n","                        loss2 = loss\n","                        loss.backward()\n","                    optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","\n","            epoch_loss = running_loss / len(dsets[phase])\n","\n","            print('{} Loss: {:.4f}'.format(phase, epoch_loss))\n","            train_loss_dict.append(epoch_loss)\n","            np.savetxt(Seg_log_Files + '/seg_train_loss.txt', train_loss_dict, fmt='%.6f')\n","            if epoch % 50 == 0:\n","                torch.save(seg_model.state_dict(),\n","                            os.path.join(Seg_weight_Dst, '{:d}_{:.4f}_model.pth'.format(epoch, epoch_loss)))\n","            torch.save(seg_model.state_dict(), os.path.join(Seg_weight_Dst, 'end_model.pth'))\n","\n","        #else:\n","        #    if epoch % 50 == 0:\n","        #        seg_model.eval()   # Set model to evaluate mode\n","        #        ap_05, ap_07 = seg_eval_kaggle.do_python_eval(dsets=dsets[phase], dec_model=dec_model, seg_model=seg_model,\n","        #                                                detector=detector, anchors=anchors, device=device,\n","        #                                                args=args, offline=False)\n","        #        # print('ap05:{:.4f}, ap07:{:.4f}'.format(ap05, ap07))\n","        #        ap05_dict.append(ap_05)\n","        #        np.savetxt(Seg_log_Files + '/seg_ap_05.txt', ap05_dict, fmt='%.6f')\n","        #        ap07_dict.append(ap_07)\n","        #        np.savetxt(Seg_log_Files + '/seg_ap_07.txt', ap07_dict, fmt='%.6f')\n","\n","print('Finish')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ABb48FjnDoPM","cellView":"form"},"source":["os.chdir(ANCIS_PATH)\n","\n","#@markdown ___\n","#@markdown ## **2. Test Segmentation Network**\n","\n","#@markdown Test the Instance Segmentation Network.  \n","#@markdown\n","#@markdown ### **A. Select Segmentation Weights**\n","#@markdown *Update paths to reflect local directories. Use Select to find alternate weights.*\n","SEGWEIGHT = 'Tissue' #@param ['Tissue', 'Cell', 'Combine', 'Kaggle', 'Select'] {type: 'string'}\n","if SEGWEIGHT == 'Tissue':\n","  #@markdown Tissue:\n","  seg_weights = \"D:\\\\Weights\\\\ANCIS\\\\SegWeights\\\\ANCIS_SegWeight_Tissue\\\\end_model.pth\" #@param {type: \"string\"}\n","elif SEGWEIGHT == 'Cell':\n","  #@markdown Cell:\n","  seg_weights = \"D:\\\\Weights\\\\ANCIS\\\\SegWeights\\\\ANCIS_SegWeight_Cell\\\\end_model.pth\" #@param {type: \"string\"}\n","elif SEGWEIGHT == 'Combine':\n","  #@markdown Combined:\n","  seg_weights = \"D:\\Weights/ANCIS/SegWeights/ANCIS_SegWeight_Combine/end_model.pth\" #@param {type: \"string\"}\n","elif SEGWEIGHT == 'Kaggle':\n","  #@markdown Kaggle:\n","  seg_weights = \"D:\\Weights/ANCIS/SegWeights/ANCIS_SegWeight_Kaggle/end_model.pth\" #@param {type: \"string\"}\n","elif SEGWEIGHT == 'Select':\n","  print('Use popup window to select weights')\n","  weights = filedialog.askopenfile(title=('Select Weights'))\n","  seg_weights = weights.name\n","\n","#@markdown ___\n","#@markdown ### **B. Select Detection Weights**\n","DECWEIGHT = 'Tissue' #@param ['Tissue', 'Cell', 'Combine', 'Kaggle', 'Select'] {type: 'string'}\n","if DECWEIGHT == 'Tissue':\n","  #@markdown Tissue:\n","  dec_weights = \"D:\\\\Weights\\\\ANCIS\\\\DecWeights\\\\ANCIS_DecWeight_Cell\\\\end_model.pth\" #@param {type: \"string\"}\n","elif DECWEIGHT == 'Cell':\n","  #@markdown Cell:\n","  dec_weights = \"D:\\\\Weights\\\\ANCIS\\\\DecWeights\\\\ANCIS_DecWeight_Cell\\\\end_model.pth\" #@param {type: \"string\"}\n","elif DECWEIGHT == 'Combine':\n","  #@markdown Combine:\n","  dec_weights = \"D:\\Weights\\ANCIS\\DecWeights\\ANCIS_DecWeight_Combine\\end_model.pth\" #@param {type: \"string\"}\n","elif DECWEIGHT == 'Kaggle':\n","  #@markdown Kaggle:\n","  dec_weights = \"D:\\Weights\\ANCIS\\DecWeights\\ANCIS_DecWeight_Kaggle\\end_model.pth\" #@param {type: \"string\"}\n","elif DECWEIGHT == 'Select':\n","  print('Use popup window to select weights')\n","  weights = filedialog.askopenfile(title=('Select Weights'))\n","  dec_weights = weights.name\n","\n","#@markdown ___\n","#@markdown ### **C. Segmented Image Save Path**\n","SAVE_PATH = \"D:\\Images\\Results\\ANCIS\\Seg\" #@param {type: \"string\"}\n","if not os.path.exists(SAVE_PATH):\n","  os.makedirs(SAVE_PATH)\n","\n","#@markdown ___\n","#@markdown ### **D. Conduct Additional Segmentation Post-Processing?**\n","#@markdown *Overlap Removal (experimental)*\n","PROC = True #@param {type: 'boolean'}\n","\n","#@markdown ### **E. Overlay Post-processed Images for Display (requires more time to setup)**\n","OVER = True #@param {type: 'boolean'}\n","\n","if OVER:\n","  if INSTALL:\n","    !pip install colorspacious\n","    !git clone --quiet https://github.com/taketwo/glasbey.git\n","    INSTALL = False\n","  import colorspacious\n","  from glasbey import Glasbey\n","  from skimage.color import label2rgb\n","\n","  color = np.array(([1,0,0],[0,1,0],[0,0,1],[1,1,0],[0,1,1],[1,0,1],[1,0.5,0],[0.5,1,0],[0,1,0.5],[0,0.5,1],[1,0,0.5],[0.5,0,1],[1,0.5,0.25],[0.25,0.5,1],[1,0.25,0.5],[0.5,0.25,1],[0.5,1,0.25],[0.25,1,0.5]),np.float32)\n","  gb = Glasbey(base_palette=color, chroma_range = (60,100), no_black=True)\n","  c4 = gb.generate_palette(size=18)\n","  color4 = c4[1:]\n","\n","  def normalized(rgb):\n","    norm=np.zeros((512,512,3),np.float32)\n","    norm_rgb=np.zeros((512,512,3),np.uint8)\n","\n","    b=rgb[:,:,0]\n","    g=rgb[:,:,1]\n","    r=rgb[:,:,2]\n","\n","    sum=b+g+r\n","\n","    norm[:,:,0]=b/sum*255.0\n","    norm[:,:,1]=g/sum*255.0\n","    norm[:,:,2]=r/sum*255.0\n","\n","    norm_rgb=cv2.convertScaleAbs(norm)\n","    return norm_rgb\n","\n","  def overlay(mask, orig, clr):\n","    maskPR = label(mask)\n","    labels = label2rgb(label=maskPR, bg_label=0, bg_color=(0, 0, 0), colors=clr)\n","    L2 = normalized(labels)\n","    if len(orig.shape) < 3: \n","      O2 = cv2.cvtColor(orig.astype('uint8'), cv2.COLOR_GRAY2BGR)\n","    else:\n","      O2 = orig\n","    comb = cv2.addWeighted(L2.astype('float64'),0.5,O2.astype('float64'),0.5,0)\n","    return comb\n","\n","\n","import argparse\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","from seg_utils import *\n","from dec_utils import *\n","from seg_utils import seg_transforms, seg_dataset_kaggle, seg_eval\n","\n","from models import dec_net_seg, seg_net\n","import cv2\n","import os\n","\n","def load_dec_weights(dec_model, dec_weights):\n","    print('Resuming detection weights from {} ...'.format(dec_weights))\n","    dec_dict = torch.load(dec_weights, map_location=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))\n","    dec_dict_update = {}\n","    for k in dec_dict:\n","        if k.startswith('module') and not k.startswith('module_list'):\n","            dec_dict_update[k[7:]] = dec_dict[k]\n","        else:\n","            dec_dict_update[k] = dec_dict[k]\n","    dec_model.load_state_dict(dec_dict_update, strict=True)\n","    return dec_model\n","\n","#-----------------load detection model -------------------------\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","dec_model = dec_net_seg.resnetssd50(pretrained=False, num_classes=num_classes)\n","dec_model = load_dec_weights(dec_model, dec_weights)\n","dec_model = dec_model.to(device)\n","dec_model.eval()\n","#-----------------load segmentation model -------------------------\n","seg_model =  seg_net.SEG_NET(num_classes=num_classes)\n","seg_model.load_state_dict(torch.load(seg_weights, map_location=torch.device('cpu')))\n","seg_model= seg_model.to(device)\n","seg_model.eval()\n","##--------------------------------------------------------------\n","data_transforms = seg_transforms.Compose([seg_transforms.ConvertImgFloat(),\n","                                    seg_transforms.Resize(img_height, img_width),\n","                                    seg_transforms.ToTensor()])\n","\n","\n","dsets = seg_dataset_kaggle.NucleiCell(testDir, annoDir, data_transforms,\n","                                      imgSuffix=imgSuffix, annoSuffix=annoSuffix)\n","\n","# for validation data -----------------------------------\n","names = dsets.load_img_ids()\n","detector = Detect(num_classes=num_classes,\n","                  top_k=top_k,\n","                  conf_thresh=conf_thresh,\n","                  nms_thresh=nms_thresh,\n","                  variance=[0.1, 0.2])\n","anchorGen = Anchors(img_height, img_width)\n","anchors = anchorGen.forward()\n","if not os.path.exists(os.path.join(SAVE_PATH ,'masks')):\n","    os.makedirs(os.path.join(SAVE_PATH,'masks'))\n","if not os.path.exists(os.path.join(SAVE_PATH,'seg')):\n","    os.makedirs(os.path.join(SAVE_PATH,'seg'))\n","# for img_idx in [1,55,57,72,78,123]:\n","for img_idx in range(len(dsets)):\n","  print('loading {}/{} image'.format(img_idx, len(dsets)))\n","  inputs, gt_boxes, gt_classes, gt_masks = dsets.__getitem__(img_idx)\n","  ori_img = dsets.load_img(img_idx)\n","  image = ori_img.copy()\n","  #ori_img_copy = ori_img.copy()\n","  #bboxes, labels, masks = dsets.load_annotation(dsets.img_files[img_idx])\n","  #for mask in masks:\n","  #    ori_img = map_mask_to_image(mask, ori_img, color=np.random.rand(3))\n","  h,w,c = ori_img.shape\n","  x = inputs.unsqueeze(0)\n","  x = x.to(device)\n","  locs, conf, feat_seg = dec_model(x)\n","  detections = detector(locs, conf, anchors)\n","  outputs = seg_model(detections, feat_seg)\n","  mask_patches, mask_dets = outputs\n","  ames = names[img_idx]\n","  ame = (os.path.basename(ames))\n","  print(ame)\n","  # For batches\n","  zees = np.zeros([img_height, img_width], dtype='uint8')\n","  maskD = np.zeros([zees.shape[0], zees.shape[1]], dtype='uint8')\n","  diff = np.zeros([zees.shape[0], zees.shape[1]], dtype='uint8')\n","  for b_mask_patches, b_mask_dets in zip(mask_patches, mask_dets):\n","    nd = len(b_mask_dets)\n","    # Step1: rearrange mask_patches and mask_dets\n","    for d in range(nd):\n","      d_mask = np.zeros((img_height, img_width), dtype=np.float32)\n","      d_mask_det = b_mask_dets[d].data.cpu().numpy()\n","      d_mask_patch = b_mask_patches[d].data.cpu().numpy()\n","      d_bbox = d_mask_det[0:4]\n","      d_conf = d_mask_det[4]\n","      d_class = d_mask_det[5]\n","      if d_conf < conf_thresh:\n","        continue\n","      [y1, x1, y2, x2] = d_bbox\n","      y1 = np.maximum(0, np.int32(np.round(y1)))\n","      x1 = np.maximum(0, np.int32(np.round(x1)))\n","      y2 = np.minimum(np.int32(np.round(y2)), img_height - 1)\n","      x2 = np.minimum(np.int32(np.round(x2)), img_width - 1)\n","      d_mask_patch = cv2.resize(d_mask_patch, (x2 - x1 + 1, y2 - y1 + 1))\n","      d_mask_patch = np.where(d_mask_patch >= seg_thresh, 1., 0.)\n","      d_mask[y1:y2 + 1, x1:x2 + 1] = d_mask_patch\n","      d_mask = cv2.resize(d_mask, dsize=(w,h), interpolation=cv2.INTER_NEAREST)\n","      ori_img = map_mask_to_image(d_mask, ori_img, color=np.random.rand(3))\n","      #zees = (d+1)*d_mask + zees\n","\n","      # Additional Post-Processing\n","\n","      #for n in range(0,masks.shape[2]):\n","      if PROC == False:\n","        zees = (d+1)*d_mask + zees\n","      elif PROC == True:\n","        d_mask = d_mask.astype('uint8')\n","        #d_mask[d_mask>0] = 1\n","        M2 = label(d_mask)\n","        props2 = regionprops(M2)\n","        for m in range(0,M2.max()):\n","          if props2[m].area < 750:\n","            M2[M2==props2[m].label] = 0\n","        M2[M2 > 0] = 1\n","        d_mask = M2*d_mask\n","        props2 = regionprops(d_mask)\n","        maskD = maskD + d_mask\n","        if maskD.max() <= 1:\n","          zees = zees + (d+1)*d_mask\n","        else:\n","          try:\n","            diff[maskD > 1] = 1\n","            diff2 = diff.copy()\n","            pd = regionprops(diff)\n","\n","            area2 = props2[0].area \n","            aread = pd[0].area\n","            Vals = diff*zees # Find value of existing region label, under new overlap\n","            vals = Vals[Vals>0] # Not zero\n","            vals = vals[vals != d+1] # Not the current label\n","            vals = list(set(vals)) # Really should only be one left\n","            z2 = np.zeros([img_height, img_width], dtype='uint8')\n","            z2[zees == vals[0]] = 1\n","            props1 = regionprops(z2)\n","            area1 = props1[0].area\n","            div1 = aread/area1\n","            div2 = aread/area2\n","            zees = zees + (d+1)*d_mask\n","\n","            if div1 < 0.15 and div2 < 0.15:\n","              zees[diff > 0] = vals[0]\n","              #zees[zees==d+1] = vals[0]\n","            elif div1 < 0.15 and div2 > 0.15:\n","              zees[diff > 0] = d+1\n","              #zees[zees==vals[0]] = d+1\n","            elif div1 > 0.15 and div2 < 0.15:\n","              zees[diff > 0] = vals[0]\n","              #zees[zees==d+1] = vals[0]\n","            elif div1 > 0.15 and div2 > 0.15 and div1 < 0.6 and div2 < 0.6:\n","              y0, x0 = pd[0].centroid\n","              orientation = pd[0].orientation\n","\n","              x1 = x0 - math.sin(orientation) * 0.55 * pd[0].major_axis_length\n","              y1 = y0 - math.cos(orientation) * 0.55 * pd[0].major_axis_length\n","              x2 = x0 + math.sin(orientation) * 0.55 * pd[0].major_axis_length\n","              y2 = y0 + math.cos(orientation) * 0.55 * pd[0].major_axis_length \n","\n","              cv2.line(diff, (int(x2),int(y2)), (int(x0),int(y0)), (0, 0, 0), thickness=2)\n","              cv2.line(diff, (int(x1),int(y1)), (int(x0),int(y0)), (0, 0, 0), thickness=2)\n","\n","              lbl1 = label(diff)\n","              lbl1 = lbl1.astype('uint8')\n","              cv2.line(lbl1, (int(x2),int(y2)), (int(x0),int(y0)), (1, 1, 1), thickness=2)\n","              cv2.line(lbl1, (int(x1),int(y1)), (int(x0),int(y0)), (1, 1, 1), thickness=2)\n","              lbl2 = lbl1*diff2\n","              zees[lbl2 == 2] = d+1\n","              zees[lbl2 == 1] = vals[0]\n","                                      \n","            elif div1 > 0.6 or div2 > 0.6:\n","              if area1 > area2:\n","                zees[diff > 0] = vals[0]\n","                zees[zees==d+1] = vals[0]\n","              elif area2 > area1:\n","                zees[diff > 0] = d+1\n","                zees[zees==vals[0]] = d+1\n","            \n","          except Exception as e:\n","            print(e)\n","            continue\n","\n","      maskD[maskD > 1] = 1\n","      diff = np.zeros([zees.shape[0], zees.shape[1]], dtype='uint8')\n","\n","  zees = label(zees)\n","  propsz = regionprops(zees)\n","  try:\n","    for m in range(0,zees.max()):\n","      if propsz[m].area < 750:\n","        zees[zees==propsz[m].label] = 0\n","  except Exception as e:\n","    print(e)\n","\n","  _, ax = plt.subplots(1, figsize=(16, 16))\n","  ax.axis('off')\n","  plt.imshow(ori_img.astype('uint8'),clim=(0.0, 1.0))\n","  plt.show()\n","  if OVER and PROC:\n","    ovr = overlay(zees, image, color4)\n","    print('Processed ...')\n","    _, ax = plt.subplots(1, figsize=(16, 16))\n","    ax.axis('off')\n","    plt.imshow(ovr.astype('uint8'),clim=(0.0, 1.0))\n","    plt.show()\n","\n","  cv2.imwrite(os.path.join(SAVE_PATH,'masks',ame), zees)\n","  if OVER and PROC:\n","    cv2.imwrite(os.path.join(SAVE_PATH,'seg',ame), ovr)\n","  else:\n","    cv2.imwrite(os.path.join(SAVE_PATH,'seg',ame), ori_img)\n","cv2.destroyAllWindows()\n","print('Finish')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jeXTZS3L9KJ7","cellView":"form"},"source":["#@markdown ## **3. Zip and Download Predictions to Local Drive**\n","#@markdown If download does not occur, check if browser is blocking.\n","\n","import shutil\n","\n","output_filename = 'Results' #@param {type: 'string'}\n","dir_name = SAVE_PATH\n","shutil.make_archive(output_filename, 'zip', dir_name, verbose=1)\n","\n","files.download(output_filename + '.zip')"],"execution_count":null,"outputs":[]}]}