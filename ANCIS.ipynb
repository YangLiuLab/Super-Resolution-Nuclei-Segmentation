{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ANCIS.ipynb","private_outputs":true,"provenance":[{"file_id":"1XQKRSkWfRVamCGxgvbBQtM4P4MIgO35N","timestamp":1603756685999}],"collapsed_sections":["GTsN7klrWa8j","Z0cogEjBWsvL","G5Br139VBZdH","COkggCvEiv7E","rBmNbjb93-Rd"],"toc_visible":true,"authorship_tag":"ABX9TyM90tLfcTG4ZVHcaq8agk39"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"G8xvUy2xh2ry"},"source":["## **ANCIS Training and Detection**\n","Attentive neural cell instance segmentation, \n","\n","**Code:** ANCIS-Pythorch https://github.com/yijingru/ANCIS-Pytorch\n","\n","**Paper:** Jingru Yi, Pengxiang Wu, Menglin Jiang, Qiaoying Huang, Daniel J. Hoeppner, Dimitris N. Metaxas, Attentive neural cell instance segmentation, Medical Image Analysis, Volume 55, 2019, Pages 228-240, https://doi.org/10.1016/j.media.2019.05.004.\n","\n","---\n","\n","**Begin:**  The first step, is to gather your data into two directories (folders).  One for the original images to be processed and one for data labels.\n","\n","Additionally, if you are testing only and do not have labels, that is fine.  \n","\n","If you are conducting training, labels are required.  Annotation files are not required.\n","\n","Validation images are recommended for training.\n","\n","---\n","NOTE: To activate GPU, go to Runtime (tab at top) --> Change runtime type, then select GPU under Hardware accelerator\n","\n","---\n","\n","**Next:**  Run all sections of the code.  Use defaults if unsure. \n","\n","---\n","\n","**Then:**  Train or Test\n","\n","---\n","\n","**NOTES:**  Click folder on the left side <----- to see files. Then click \"up arrow on folder\" icon to get full list.\n","\n","Noise detection function may vary, due to variations in images."]},{"cell_type":"markdown","metadata":{"id":"GTsN7klrWa8j"},"source":["# **I. Download Requirements and Import Libraries**"]},{"cell_type":"code","metadata":{"cellView":"form","id":"lJsGlUtxooZc"},"source":["#@markdown ___\n","#@markdown ## **A. Mount Drive**\n","#@markdown Using Drive?:\n","DRV = True #@param {type: \"boolean\"}\n","from google.colab import files\n","from google.colab import drive\n","if DRV == True:\n","  drive.mount('/content/drive')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X0Lv26nRjKtz","cellView":"form"},"source":["#@markdown ___\n","#@markdown ## **B. Install Dependencies**\n","if DRV:\n","  %cd /content/drive/My Drive/Colab Notebooks/ANCIS\n","else:\n","  %cd\n","  !git clone --quiet https://github.com/yijingru/ANCIS-Pytorch.git\n","  %cd ANCIS\n","\n","!pip install opencv-python\n","!pip install torch>0.4.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XMD0OVjMsMlq","cellView":"form"},"source":["%cd\n","#@markdown ___\n","#@markdown ## **C. Import Libraries**\n","\n","import os\n","import cv2\n","import numpy as np\n","import pickle\n","import skimage\n","from skimage.measure import label, regionprops\n","import shutil\n","\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z0cogEjBWsvL"},"source":["# **II. Set Data Paths, Import Data and Process**"]},{"cell_type":"code","metadata":{"id":"zqftxsMBkIYR","cellView":"form"},"source":["#@markdown ___\n","%cd\n","\n","#@markdown ## **1. Set Data Paths and Load Images**\n","\n","#@markdown\n","#@markdown ### **A. Uploading New Images?**\n","New = True #@param {type:\"boolean\"}\n","#@markdown\n","\n","#@markdown ### **B. Training or Testing?**\n","#@markdown Both Training and Validation data is required for the \"Train\" option.\n","\n","#@markdown *The Validation Set can be about 10-20% the size of the training set.*\n","\n","#@markdown *Additionally, image labels are required for training and validation, but not for testing.*\n","Select = 'Test' #@param [\"Test\", \"Train\"] {type:\"string\"}\n","#@markdown\n","\n","# Run Only to Clear Data\n","#@markdown ### **C. Do You Want to Clear Old Image Data?**\n","#@markdown New data will be added to your path.  If images are already in that path,\n","#@markdown they will remain.  You can also create new paths folders for your new i (default=off)\n","Clr = True #@param {type:\"boolean\"} \n","#@markdown\n","\n","#@markdown . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n","\n","#@markdown Advanced Options:\n","#@markdown ### **D. Select Datapaths** \n","#@markdown Paths set in the cloud; leave defaults unless adding new separate datasets.\n","\n","#@markdown Can also set Drive paths here, if images in Drive folder\n","DATA_PATH = \"/root/datasets\" #@param{type:\"string\"}\n","TRAIN_PATH = \"/root/datasets/train\" #@param{type:\"string\"}\n","LABEL_PATH = \"/root/datasets/labels\" #@param{type:\"string\"}\n","VAL_PATH = \"/root/datasets/val\" #@param{type:\"string\"}\n","VAL_LABEL_PATH = \"/root/datasets/vallabel\" #@param{type:\"string\"}\n","TEST_PATH = \"/root/datasets/test\" #@param{type:\"string\"}\n","TEST_LABEL_PATH = \"/root/datasets/testlabel\" #@param{type:\"string\"}\n","#@markdown *Test set does not require labels.*\n","\n","annoDir = \"/root/datasets/Labels\"\n","\n","#@markdown\n","\n","if Clr == True:\n","\n","  if os.path.exists(LABEL_PATH):\n","    shutil.rmtree(LABEL_PATH)\n","  if os.path.exists(TRAIN_PATH):\n","    shutil.rmtree(TRAIN_PATH)\n","  if os.path.exists(TEST_PATH):\n","    shutil.rmtree(TEST_PATH)\n","  if os.path.exists(VAL_PATH):\n","    shutil.rmtree(VAL_PATH)\n","  if os.path.exists(TEST_LABEL_PATH):\n","    shutil.rmtree(TEST_LABEL_PATH)\n","  if os.path.exists(VAL_LABEL_PATH):\n","    shutil.rmtree(VAL_LABEL_PATH)\n","  if os.path.exists(DATA_PATH):\n","    shutil.rmtree(DATA_PATH)\n","  if os.path.exists(annoDir):\n","    shutil.rmtree(annoDir)\n","#@markdown \n","if not os.path.exists(annoDir):\n","  os.makedirs(annoDir)\n","\n","#@markdown . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n","\n","#@markdown ### **E. Use buttons below and pop-up windows to select all desired images and labels**\n","#@markdown You must select each desired image, Colab doesn't like directories. Just click and drag, shift click, crl+a, etc...\n","if New == True:\n","  if Select == \"Train\":\n","    if not os.path.exists(TRAIN_PATH):\n","      os.makedirs(TRAIN_PATH)\n","    os.chdir(TRAIN_PATH)\n","    print('****************************************')\n","    print('Select all training images')\n","    print('****************************************')\n","    imagesTr = files.upload()\n","\n","    if not os.path.exists(LABEL_PATH):\n","      os.makedirs(LABEL_PATH)\n","    os.chdir(LABEL_PATH)\n","    print('****************************************')\n","    print('Select all corresponding training labels')\n","    print('****************************************')\n","    labelsTr = files.upload()\n","  \n","    if not os.path.exists(VAL_PATH):\n","      os.makedirs(VAL_PATH)\n","    os.chdir(VAL_PATH)\n","    print('****************************************')\n","    print('Select all validation images')\n","    print('****************************************')\n","    imagesV = files.upload()\n","\n","    if not os.path.exists(VAL_LABEL_PATH):\n","      os.makedirs(VAL_LABEL_PATH)\n","    os.chdir(VAL_LABEL_PATH)\n","    print('****************************************')\n","    print('Select all corresponding validation labels')\n","    print('****************************************')\n","    labelsV = files.upload()\n","\n","  elif Select == \"Test\":\n","    if not os.path.exists(TEST_PATH):\n","      os.makedirs(TEST_PATH)\n","    os.chdir(TEST_PATH)\n","    print('****************************************')\n","    print('Select all test images')\n","    print('****************************************')\n","    imagesTe = files.upload()\n","\n","    if not os.path.exists(TEST_LABEL_PATH):\n","      os.makedirs(TEST_LABEL_PATH)\n","    os.chdir(TEST_LABEL_PATH)\n","    print('****************************************')\n","    print('Select all corresponding test labels, or hit cancel')\n","    print('****************************************')\n","    labelsTe = files.upload()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RK8JVB6AHwyK","cellView":"form"},"source":["#@markdown ___\n","#@markdown ## **2. Noise Detection and Removal**\n","%cd\n","#@markdown Would you like to conduct noise detection and removal?\n","\n","#@markdown *Noise removal is only beneficial for test images.*\n","NR = False #@param {type: \"boolean\"}\n","#@markdown\n","\n","#@markdown --- Select Noise Weights.  Load pre-trained, or upload your own.\n","NOISE_WEIGHTS = \"Tissue\" #@param [\"Tissue\", \"Cell\", \"Select\"] {type: \"string\"}\n","\n","def bin_ndarray(ndarray, new_shape, operation='sum'):\n","\n","    operation = operation.lower()\n","    if not operation in ['sum', 'mean']:\n","        raise ValueError(\"Operation not supported.\")\n","    if ndarray.ndim != len(new_shape):\n","        raise ValueError(\"Shape mismatch: {} -> {}\".format(ndarray.shape,\n","                                                           new_shape))\n","    compression_pairs = [(d, c//d) for d,c in zip(new_shape,\n","                                                  ndarray.shape)]\n","    flattened = [l for p in compression_pairs for l in p]\n","    ndarray = ndarray.reshape(flattened)\n","    for i in range(len(new_shape)):\n","        op = getattr(ndarray, operation)\n","        ndarray = op(-1*(i+1))\n","    return ndarray\n","\n","#@markdown  . . . . . . . . . . . . . . . . . . . . . . . . . .  . . . . . . . . . . . . . . . . . . . . . . . . . .  . . . . . . . . . . . . . . . . . . . . . . . . . .  . . . . . . . . . . . . . . . . . . . . . . . . . .\n","\n","#@markdown Advanced Options:\n","\n","#@markdown ### **A. Select Target Noisy Image Path**\n","NOISE_IMG_PATH = \"/root/datasets/test\" #@param {type: \"string\"}\n","#@markdown ### **B. DeNoised Image Save Path**\n","IMG_SAVE_PATH = \"/root/datasets/imagesDN\" #@param {type: \"string\"}\n","if not os.path.exists(IMG_SAVE_PATH):\n","  os.makedirs(IMG_SAVE_PATH)\n","#@markdown ### **C. Noise Detections Save Path**\n","NOISE_MAP = \"/root/datasets/Noise/map\" #@param {type:\"string\"}\n","if not os.path.exists(NOISE_MAP):\n","  os.makedirs(NOISE_MAP)\n","#@markdown\n","\n","if NOISE_WEIGHTS == \"Tissue\":\n","  NW = '/content/drive/My Drive/Colab Notebooks/weights/unet_noise_tissue.hdf5'\n","elif NOISE_WEIGHTS == \"Cell\":\n","  NW = '/content/drive/My Drive/Colab Notebooks/weights/unet_noise_cell_line.hdf5'\n","elif NOISE_WEIGHTS == \"Select\":\n","  nweights = files.upload()\n","  for name, data in nweights.items():\n","    with open(name, 'wb') as f:\n","      print ('saved file', name)\n","    NW = os.path.join(os.getcwd(), name)\n","\n","if NR == True:\n","  %cd /root/\n","  if not os.path.exists('unet'):\n","    !git clone --quiet https://github.com/zhixuhao/unet.git\n","  %cd /root/unet/\n","\n","  from model import *\n","  from data import *\n","  import numpy as np \n","  import cv2\n","  import os\n","  import glob\n","  import skimage.io as io\n","  import skimage.transform as trans\n","\n","  model = load_model(NW)\n","  test_path = NOISE_IMG_PATH\n","  save_path = NOISE_MAP\n","  save_path2 = IMG_SAVE_PATH\n","\n","  def image_normalized(file_path):\n","\n","      #img = cv2.imread(file_path,0)\n","      img = skimage.io.imread(file_path)\n","      img_shape = img.shape\n","      M = img_shape[0]\n","      N = img_shape[1]\n","      container = np.zeros((M,N,1,1))\n","      image_size = (img_shape[1],img_shape[0])\n","      img_standard = bin_ndarray(img*1.2, (M,N), operation='mean')\n","      #img_standard = cv2.resize(img, (M, M), interpolation=cv2.INTER_CUBIC)\n","      img_new = img_standard\n","      imgT = img_standard\n","      img_new = np.asarray([img_new / 255.])\n","      return img_new,image_size, imgT\n","\n","  for name in os.listdir(test_path):\n","    image_path = os.path.join(test_path,name)\n","    if os.path.isdir(image_path):\n","      continue\n","    ll = len(name)\n","    img,img_size, imgT = image_normalized(image_path)\n","    img = np.reshape(img,img.shape+(1,))\n","    results = model.predict(img)\n","    out = np.zeros(img.shape)\n","\n","    out = 255*results[0,:,:,0];\n","    \n","    cv2.imwrite(os.path.join(save_path, (\"%s\") % (name)), out)\n","\n","    imgDN = imgT - out\n","\n","    cv2.imwrite(os.path.join(save_path2, (\"%s\") % (name)), imgDN)\n","\n","    print(name)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9xEZGJBWl505","cellView":"form"},"source":["#@markdown ___\n","#@markdown ## **3. Process Data**\n","#@markdown Resizing, finding data metrics, and rewriting images to network specifications.\n","\n","os.chdir(DATA_PATH)\n","#@markdown ### **A. Do You Want to Resize Your Images?**\n","#@markdown *Downsizing your data can decrease training time and memory requirements.*\n","#@markdown *If you are using one of our pretrained models, this is required (512x512).*\n","#@markdown\n","\n","Resize = True #@param  {type:\"boolean\"}\n","#@markdown Resize to MxN\n","M = 512 #@param {type:\"integer\"}\n","N = 512 #@param {type:\"integer\"}\n","#@markdown\n","\n","#@markdown ### **B. Do you want to write new data to your path?** \n","#@markdown Required if loading new data, not if using data that has been processed already\n","Write = True #@param  {type:\"boolean\"}\n","\n","def bin_ndarray(ndarray, new_shape, operation='sum'):\n","    \"\"\"\n","    J.F. Sebastian\n","    Bins an ndarray in all axes based on the target shape, by summing or\n","        averaging.\n","\n","    Number of output dimensions must match number of input dimensions and \n","        new axes must divide old ones.\n","\n","    Example\n","    -------\n","    >>> m = np.arange(0,100,1).reshape((10,10))\n","    >>> n = bin_ndarray(m, new_shape=(5,5), operation='sum')\n","    >>> print(n)\n","\n","    [[ 22  30  38  46  54]\n","     [102 110 118 126 134]\n","     [182 190 198 206 214]\n","     [262 270 278 286 294]\n","     [342 350 358 366 374]]\n","\n","    \"\"\"\n","    operation = operation.lower()\n","    if not operation in ['sum', 'mean']:\n","        raise ValueError(\"Operation not supported.\")\n","    if ndarray.ndim != len(new_shape):\n","        raise ValueError(\"Shape mismatch: {} -> {}\".format(ndarray.shape,\n","                                                           new_shape))\n","    compression_pairs = [(d, c//d) for d,c in zip(new_shape,\n","                                                  ndarray.shape)]\n","    flattened = [l for p in compression_pairs for l in p]\n","    ndarray = ndarray.reshape(flattened)\n","    for i in range(len(new_shape)):\n","        op = getattr(ndarray, operation)\n","        ndarray = op(-1*(i+1))\n","    return ndarray\n","\n","MP = 0\n","Num = 0\n","fin = 0\n","Spath = DATA_PATH\n","if Select == \"Train\":\n","  PATH = TRAIN_PATH\n","elif Select == \"Test\":\n","  PATH = TEST_PATH\n","\n","NME = Select\n","seti=0\n","\n","while fin == 0:\n","  print(NME)\n","  \n","  if Select == 'Test' and len(os.listdir(TEST_LABEL_PATH)) == 0:\n","    seti = 1\n","  if NME == 'Val':\n","    if len(os.listdir(VAL_LABEL_PATH)) == 0:\n","      seti = 1\n","\n","  for name in os.listdir(PATH):\n","    if Select == \"Train\":\n","      path = os.path.join(TRAIN_PATH, name)\n","      path2 = os.path.join(LABEL_PATH, name)\n","      if NR == True:\n","        path = os.path.join(IMG_SAVE_PATH, name)\n","      if PATH == VAL_PATH:\n","        path = os.path.join(VAL_PATH, name)\n","        path2 = os.path.join(VAL_LABEL_PATH, name)\n","    elif Select == \"Test\":\n","      path = os.path.join(TEST_PATH, name)\n","      path2 = os.path.join(TEST_LABEL_PATH, name)\n","      if NR == True:\n","        path = os.path.join(IMG_SAVE_PATH, name)\n","\n","    ll = len(name)\n","    #img = cv2.imread(path,0)\n","    img = skimage.io.imread(path)\n","    \n","    # Get Extension\n","    if Num == 0:\n","      nme, ext = os.path.splitext(name)\n","    img = img.astype('uint8')\n","\n","    # Resize\n","    if Resize == True:\n","      #img = cv2.resize(img,(M,M),interpolation=cv2.INTER_LINEAR)\n","      img = bin_ndarray(img*1.2, (M,M), operation='mean')\n","    sh = img.shape\n","\n","    # Pixel Average\n","    if PATH != VAL_PATH:\n","      if len(sh) == 3 or 4:\n","        MP = (np.mean(img,axis=(0,1)) + MP)\n","      else:\n","        MP = (np.mean(img) + MP)\n","\n","    Num = Num + 1\n","    print(name)\n","    if Write == True:\n","      if not os.path.exists(os.path.join(Spath, NME, name[0:ll-4], \"images\")):\n","        os.makedirs(os.path.join(Spath, NME, name[0:ll-4], \"images\"))\n","      cv2.imwrite(os.path.join(Spath, NME, name[0:ll-4], \"images\", name[0:ll-4]+ '.png'), img)\n","\n","    if Select == \"Train\" or (Select == \"Test\" and seti == 0):\n","      #img2 = cv2.imread(path2)\n","      img2 = skimage.io.imread(path2)\n","      img2 = label(img2)\n","      img2 = cv2.resize(img2,(M,M),interpolation=cv2.INTER_NEAREST)\n","      P = img2.max()\n","      out = np.zeros([M, N, P])\n","      \n","      if Write == True:\n","        if not os.path.exists(os.path.join(Spath, NME, name[0:ll-4], \"masks\")):\t\t\n","          os.mkdir(os.path.join(Spath, NME, name[0:ll-4], \"masks\"))\n","        if len(img2.shape) > 2:\n","          if img2.shape[2] > 1:\n","            img2 = cv2.cvtColor(img2.astype('uint8'),cv2.COLOR_BGR2GRAY)\n","        cv2.imwrite(os.path.join(annoDir, name[0:ll-4] + '.png'),img2)\n","        for n in range(1,P+1):\n","          ind = np.where(img2 == n)\n","          for i in range(0,ind[0].shape[0]-1):\n","            out[ind[0][i],ind[1][i],n-1] = 1\n","          cv2.imwrite(os.path.join(Spath, NME, name[0:ll-4], \"masks\", name[0:ll-4] + \"_\" + str(n-1) + '.png'),out[:,:,n-1])\n","\n","    elif Select == \"Test\" and seti == 1:\n","      \n","      img3 = np.ones([M,M])\n","      out = np.zeros([M, M,1])\n","      \n","      if Write == True:\n","        cv2.imwrite(os.path.join(TEST_LABEL_PATH, name[0:ll-4] + '.png'),img3)\n","        cv2.imwrite(os.path.join(annoDir, name[0:ll-4] + '.png'),img3)\n","        if not os.path.exists(os.path.join(Spath, NME, name[0:ll-4], \"masks\")):\t\t\n","          os.mkdir(os.path.join(Spath, NME, name[0:ll-4], \"masks\"))\n","        for n in range(1,2):\n","          ind = np.where(img3 == n)\n","          for i in range(0,ind[0].shape[0]-1):\n","            out[ind[0][i],ind[1][i],n-1] = 1\n","          cv2.imwrite(os.path.join(Spath, NME, name[0:ll-4], \"masks\", name[0:ll-4] + \"_\" + str(n-1) + '.png'),img3)\n","  \n","  if NME == \"Train\":\n","    PATH = VAL_PATH\n","    NME = \"Val\"\n","\n","    if len(os.listdir(VAL_PATH)) == 0:\n","      if not os.path.exists(os.path.join(Spath,NME,\"val1\")):\n","        os.makedirs(os.path.join(Spath,NME,\"val1\",\"images\"))\n","        os.makedirs(os.path.join(Spath,NME,\"val1\",\"masks\"))\n","      if len(img2.shape) > 2:\n","        if img2.shape[2] > 1:\n","          img2 = cv2.cvtColor(img2.astype('uint8'),cv2.COLOR_BGR2GRAY)\n","      img3 = np.ones([M,N,1])\n","      cv2.imwrite(os.path.join(Spath,NME,\"val1\",\"images\",\"val1.png\"),img3)\n","      cv2.imwrite(os.path.join(Spath,NME,\"val1\",\"masks\",\"val1_0.png\"),img3)\n","      cv2.imwrite(os.path.join(annoDir,\"val1.png\"),img3)\n","      fin = 1\n","      \n","  else:\n","    fin = 1\n","\n","MP = MP/Num\n","if len(sh) != 3 or 4:\n","  MP2 = np.array([MP,MP,MP])\n","else:\n","  MP2 = MP"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G5Br139VBZdH"},"source":["# **III. Configuration**\n"]},{"cell_type":"markdown","metadata":{"id":"ApbRHFVD-gky"},"source":["\n","### **Configuration Parameters**\n","\n","Breif explanation of the configuration parameters available below.\n","\n","--**trainDir**: Training Directory Containing Images (default = /root/dataset/Train)\n","\n","--**valDir**: Validation Image Directory for Training (default = /root/dataset/Validation)\n","\n","--**cacheDir**: Directory for Training Cache Files (default = /root/ANCIS-Pytorch/cache)\n","\n","--**batch_size**: Number of Images Processed at a Time.  More = faster, but the number is limited by available memory (default = 2)\n","\n","--**multi_gpu**: Train Using Multiple GPUs, where Available (default = False)\n","\n","--**num_workers**: Number of Batches Loaded at a Time (default = 4)\n","\n","--**init_lr**: Initial Learning Rate (default = 0.001)\n","\n","--**num_epochs**: Number of Training Epochs. More may result in better training at the cost of time. Too many could lead to overfitting and reduced accuracy. (default = 200)\n","\n","--**decayEpochs**: Which Epoch to Begin Decaying the Learning Rate (default = 100)\n","\n","--**Dec_weight_Dst**: Saving Directory for Trained Detection Network Weights. (default = /content/drive/My Drive/Colab Notebooks/ANCIS/Dec_Weights)\n","\n","--**Seg_weight_Dst**: Saving Directory for Trained Segmentation Network Weights. (default = /content/drive/My Drive/Colab Notebooks/ANCIS/Seg_Weights)\n","\n","--**Dec_log_Files**: Saving Directory for Training Statistics Log Files. (default = /content/drive/My Drive/Colab Notebooks/ANCIS/Dec_Weights)\n","\n","--**Seg_log_Files**: Saving Directory for Training Statistics Log Files. (default = /content/drive/My Drive/Colab Notebooks/ANCIS/Seg_Weights)\n","\n","--**img_height**: Height, or Rows, of Training Images (default = 512)\n","\n","--**img_width**: Width, or Columns, or Training Images (default = 512)\n","\n","--**num_classes**: Number of Classes to Train on, as in \"Nucleus\" and \"Background\". (default = 2)\n","\n","--**top_k**: Maximum Number of Training Instances to Use. (default = 200)\n","\n","--**conf_thresh**: Confidence Threshold. Minimum Confidence Score for a Positive Detection for Testing or Validation. (default = 0.5)\n","\n","--**nms_thresh**: Near Maximum Suppression (NMS). Higher values allow for more detections, at the cost of more overlaps. (default = 0.7)\n","\n","--**seg_thresh**: Segmentation Threshold. Minimum score for a positive segmentation. (default = 0.5)"]},{"cell_type":"code","metadata":{"id":"6pB-x1mygO8w","cellView":"form"},"source":["#@markdown ___\n","#@markdown ## **1. Network Configuration Parameters**\n","#@markdown\n","%cd /content/drive/My Drive/Colab Notebooks/ANCIS\n","\n","#@markdown ### **A. Train Directory**\n","trainDir = DATA_PATH + \"/Train\" #@param {type: \"raw\"}\n","#@markdown ### **B. Test Directory**\n","testDir = DATA_PATH + \"/Test\" #@param {type: \"raw\"}\n","#@markdown ### **C. Validation Directory**\n","valDir = DATA_PATH + \"/Val\" #@param {type: \"raw\"}\n","#@markdown ### **D. Cache Directory**\n","cacheDir = \"/content/drive/My Drive/Colab Notebooks/ANCIS/cache\" #@param {type: \"string\"}\n","if not os.path.exists(cacheDir):\n","  os.makedirs(cacheDir)\n","#@markdown ### **E. Batch Size**\n","batch_size = 2 #@param {type: \"integer\"}\n","#@markdown ### **F. Use Multiple GPUs (local)**\n","multi_gpu = False #@param {type: \"boolean\"}\n","#@markdown ### **G. Number of Workers**\n","num_workers = 4 #@param {type: \"integer\"}\n","#@markdown ### **H. Initial Learning Rate**\n","init_lr = 0.001 #@param {type: \"number\"}\n","#@markdown ### **I. Number of Epochs**\n","num_epochs =  10#@param {type: \"integer\"}\n","#@markdown ### **J. Epoch to Begin Learning Rate Decay**\n","decayEpoch =  8#@param {type: \"integer\"}\n","#@markdown ### **K. Detection Weights Save Path**\n","Dec_weight_Dst = \"/content/drive/My Drive/Colab Notebooks/ANCIS/Dec_Weights\" #@param {type: \"string\"}\n","if not os.path.exists(Dec_weight_Dst):\n","  os.makedirs(Dec_weight_Dst)\n","#@markdown ### **L. Save Path for Segmentation Weights**\n","Seg_weight_Dst = \"/content/drive/My Drive/Colab Notebooks/ANCIS/Seg_Weights\" #@param {type: \"string\"}\n","if not os.path.exists(Seg_weight_Dst):\n","  os.makedirs(Seg_weight_Dst)\n","#@markdown ### **M. Save Path for Detection Training Logs**\n","Dec_log_Files = \"/content/drive/My Drive/Colab Notebooks/ANCIS/Dec_Weights\" #@param {type: \"string\"}\n","if not os.path.exists(Dec_log_Files):\n","  os.makedirs(Dec_log_Files)\n","#@markdown ### **N. Save Path for Segmentation Training Logs**\n","Seg_log_Files = \"/content/drive/My Drive/Colab Notebooks/ANCIS/Seg_Weights\" #@param {type: \"string\"}\n","if not os.path.exists(Seg_log_Files):\n","  os.makedirs(Seg_log_Files)\n","#@markdown ### **O. Number of Classes**\n","num_classes = 2 #@param {type: \"integer\"}\n","#@markdown ### **P. Number of Detections to Keep**\n","top_k = 200 #@param {type: \"integer\"}\n","#@markdown ### **Q. Confidence Threshold**\n","conf_thresh = 0.5 #@param {type: \"number\"}\n","#@markdown ### **R. NMS Threshold**\n","nms_thresh = 0.7 #@param {type: \"number\"}\n","#@markdown ### **S. Segmentation threshold**\n","seg_thresh = 0.5 #@param {type: \"number\"}\n","#@markdown ### **T. Visualize Augmented Training Datasets**\n","vis = False #@param {type: \"boolean\"}\n","\n","imgSuffix = '.png'\n","annoSuffix = '.png'\n","img_height = M\n","img_width = M"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"COkggCvEiv7E"},"source":["# **III. Detection (Region Proposal) Network**"]},{"cell_type":"code","metadata":{"id":"kVI3NB5-EupZ","cellView":"form"},"source":["%cd /content/drive/My Drive/Colab Notebooks/ANCIS\n","#@markdown ___\n","#@markdown ## **1. Train Detection Network**\n","#@markdown\n","\n","#@markdown Train the Single Shot Detector (SSD) Used by ANCIS for region detection.\n","\n","from dec_utils import *\n","from models import dec_net\n","from dec_utils import dec_transforms, dec_eval, dec_dataset_kaggle\n","\n","def collater(data):\n","    imgs = []\n","    bboxes = []\n","    labels = []\n","    for sample in data:\n","        imgs.append(sample[0])\n","        bboxes.append(sample[1])\n","        labels.append(sample[2])\n","    return torch.stack(imgs,0), bboxes, labels\n","\n","data_transforms = {\n","'train': dec_transforms.Compose([dec_transforms.ConvertImgFloat(),\n","                                dec_transforms.PhotometricDistort(),\n","                                dec_transforms.Expand(),\n","                                dec_transforms.RandomSampleCrop(),\n","                                dec_transforms.RandomMirror_w(),\n","                                dec_transforms.RandomMirror_h(),\n","                                dec_transforms.Resize(img_height, img_width),\n","                                dec_transforms.ToTensor()]),\n","\n","'val': dec_transforms.Compose([dec_transforms.ConvertImgFloat(),\n","                              dec_transforms.Resize(img_height, img_width),\n","                              dec_transforms.ToTensor()])\n","}\n","\n","dsets = {'train': dec_dataset_kaggle.NucleiCell(trainDir, annoDir, data_transforms['train'],\n","                                            imgSuffix=imgSuffix, annoSuffix=annoSuffix),\n","    'val': dec_dataset_kaggle.NucleiCell(valDir, annoDir, data_transforms['val'],\n","                                          imgSuffix=imgSuffix, annoSuffix=annoSuffix)}\n","\n","dataloader = torch.utils.data.DataLoader(dsets['train'],\n","                                    batch_size = batch_size,\n","                                    shuffle = True,\n","                                    num_workers = num_workers,\n","                                    collate_fn = collater,\n","                                    pin_memory = True)\n","\n","model = dec_net.resnetssd50(pretrained=True, num_classes=num_classes)\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","if multi_gpu:\n","  model = nn.DataParallel(model)\n","model = model.to(device)\n","\n","optimizer = optim.SGD(model.parameters(), lr=init_lr, momentum=0.9)\n","scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[decayEpoch, num_epochs], gamma=0.1)\n","criterion = DecLoss(img_height=img_height,\n","                img_width= img_width,\n","                num_classes=num_classes,\n","                variances=[0.1, 0.2])\n","\n","if vis:\n","  for idx in range(len(dsets['train'])):\n","      img, bboxes, labels = dsets['train'].__getitem__(idx)\n","      img = img.numpy().transpose(1, 2, 0)*255\n","      bboxes = bboxes.numpy()\n","      labels = labels.numpy()\n","      for bbox in bboxes:\n","          y1, x1, y2, x2 = bbox\n","          cv2.rectangle(img, (x1, y1), (x2, y2), (255, 255, 255), 2, lineType=1)\n","      cv2_imshow(np.uint8(img))\n","      k = cv2.waitKey(0)\n","      if k & 0xFF == ord('q'):\n","          cv2.destroyAllWindows()\n","          exit()\n","  cv2.destroyAllWindows()\n","\n","# for validation data -----------------------------------\n","detector = Detect(num_classes=num_classes,\n","              top_k=top_k,\n","              conf_thresh=conf_thresh,\n","              nms_thresh=nms_thresh,\n","              variance=[0.1, 0.2])\n","anchorGen = Anchors(img_height, img_width)\n","anchors = anchorGen.forward()\n","if not os.path.exists(cacheDir):\n","  os.mkdir(cacheDir)\n","# --------------------------------------------------------\n","train_loss_dict = []\n","ap05_dict = []\n","ap07_dict = []\n","for epoch in range(num_epochs):\n","  print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","  print('-' * 10)\n","\n","  for phase in ['train', 'val']:\n","      if phase == 'train':\n","          scheduler.step()\n","          model.train()\n","          running_loss = 0.0\n","          for inputs, bboxes, labels in dataloader:\n","              inputs = inputs.to(device)\n","              # zero the parameter gradients\n","              optimizer.zero_grad()\n","\n","              # forward\n","              # track history if only in train\n","              with torch.set_grad_enabled(phase == 'train'):\n","                  outputs = model(inputs)\n","                  loss_locs, loss_conf = criterion(outputs, bboxes, labels)\n","                  loss = loss_locs + loss_conf\n","                  # backward + optimize only if in training phase\n","                  if phase == 'train':\n","                      loss.backward()\n","                      optimizer.step()\n","\n","              # statistics\n","              running_loss += loss.item() * inputs.size(0)\n","\n","          epoch_loss = running_loss / len(dsets[phase])\n","\n","          print('{} Loss: {:.4f}'.format(phase, epoch_loss))\n","          train_loss_dict.append(epoch_loss)\n","          np.savetxt(Dec_log_Files + '/dec_train_loss.txt', train_loss_dict, fmt='%.6f')\n","          if epoch % 5 == 0:\n","              torch.save(model.state_dict(),\n","                        os.path.join(Dec_weight_Dst, '{:d}_{:.4f}_model.pth'.format(epoch, epoch_loss)))\n","          torch.save(model.state_dict(), os.path.join(Dec_weight_Dst, 'end_model.pth'))\n","\n","      else:\n","          model.eval()   # Set model to evaluate mode\n","          #model.eval()   # Set model to evaluate mode\n","          det_file = os.path.join(cacheDir, 'detections.pkl')\n","          all_boxes = [[[] for _ in range(len(dsets['val']))] for _ in range(num_classes)]\n","          for img_idx in range(len(dsets['val'])):\n","              ori_img = dsets['val'].load_img(img_idx)\n","              h,w,c = ori_img.shape\n","              inputs, gt_bboxes, gt_labels = dsets['val'].__getitem__(img_idx)  # [3, 512, 640], [3, 4], [3, 1]\n","              # run model\n","              inputs = inputs.unsqueeze(0).to(device)\n","              with torch.no_grad():\n","                  locs, conf = model(inputs)\n","              detections = detector(locs, conf, anchors)\n","              for cls_idx in range(1, detections.size(1)):\n","                  dets = detections[0, cls_idx, :]\n","                  mask = dets[:, 0].gt(0.).expand(5, dets.size(0)).t()\n","                  dets = torch.masked_select(dets, mask).view(-1, 5)\n","                  if dets.shape[0] == 0:\n","                      continue\n","                  pred_boxes = dets[:, 1:].cpu().numpy()\n","                  pred_score = dets[:, 0].cpu().numpy()\n","                  pred_boxes[:,0] /= img_height\n","                  pred_boxes[:,1] /= img_width\n","                  pred_boxes[:,2] /= img_height\n","                  pred_boxes[:,3] /= img_width\n","                  pred_boxes[:,0] *= h\n","                  pred_boxes[:,1] *= w\n","                  pred_boxes[:,2] *= h\n","                  pred_boxes[:,3] *= w\n","                  cls_dets = np.hstack((pred_boxes, pred_score[:, np.newaxis])).astype(np.float32, copy=False)\n","                  all_boxes[cls_idx][img_idx] = cls_dets\n","\n","          with open(det_file, 'wb') as f:\n","              pickle.dump(all_boxes, f, pickle.HIGHEST_PROTOCOL)\n","              f.close()\n","\n","          for cls_ind, cls in enumerate(dsets['val'].labelmap):\n","              filename = dec_eval.get_voc_results_file_template('test', cls, cacheDir)\n","              with open(filename, 'wt') as f:\n","                  for im_ind, index in enumerate(dsets['val'].img_files):\n","                      dets = all_boxes[cls_ind+1][im_ind]\n","                      if dets == []:\n","                          continue\n","                      for k in range(dets.shape[0]):\n","                          # format: [img_file  confidence, y1, x1, y2, x2] save to call for multiple times\n","                          f.write('{:s} {:.3f} {:.1f} {:.1f} {:.1f} {:.1f}\\n'.format(index,\n","                                                                                    dets[k, -1],\n","                                                                                    dets[k, 0],\n","                                                                                    dets[k, 1],\n","                                                                                    dets[k, 2],\n","                                                                                    dets[k, 3]))\n","\n","          #ap05, ap07 = dec_eval.do_python_eval(dsets=dsets['val'],\n","          #                                    output_dir=cacheDir,\n","          #                                    offline=False,\n","          #                                    use_07=True)\n","          #print('ap05:{:.4f}, ap07:{:.4f}'.format(ap05, ap07))\n","          #ap05_dict.append(ap05)\n","          #np.savetxt(Dec_log_Files + '/dec_ap_05.txt', ap05_dict, fmt='%.6f')\n","          #ap07_dict.append(ap07)\n","          #np.savetxt(Dec_log_Files + '/dec_ap_07.txt', ap07_dict, fmt='%.6f')\n","print('Finish')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"96sqaKDj__VW","cellView":"form"},"source":["#@markdown ___\n","#@markdown ## **2. Test Detection Network**\n","\n","#@markdown Test Region Proposal (Detection) Network using pre-trained weights\n","\n","#@markdown ### **A. Select Detection Network Weights for Testing**\n","DECWEIGHT = 'Tissue' #@param ['Tissue', 'Cell', 'Combine', 'Kaggle', 'Select', 'Drive'] {type: 'string'}\n","if DECWEIGHT == 'Tissue':\n","  weightTst = \"/content/drive/MyDrive/Colab Notebooks/weights/ANCIS/DecWeights/ANCIS_DecWeight_Tissue/end_model.pth\"\n","elif DECWEIGHT == 'Cell':\n","  weightTst = \"/content/drive/MyDrive/Colab Notebooks/weights/ANCIS/DecWeights/ANCIS_DecWeight_Cell/end_model.pth\"\n","elif DECWEIGHT == 'Combine':\n","  weightTst = \"/content/drive/MyDrive/Colab Notebooks/weights/ANCIS/DecWeights/ANCIS_DecWeight_Combine/end_model.pth\"\n","elif DECWEIGHT == 'Kaggle':\n","  weightTst = \"/content/drive/MyDrive/Colab Notebooks/weights/ANCIS/DecWeights/ANCIS_DecWeight_Kaggle/end_model.pth\"\n","elif DECWEIGHT == 'Select':\n","  weights = files.upload()\n","  for name, data in weights.items():\n","    with open(name, 'wb') as f:\n","      print ('saved file', name)\n","    weightTst = os.path.join(os.getcwd(), name)\n","elif DECWEIGHT == 'Drive':\n","  #@markdown -- If selecting detection weights stored in the cloud or Drive, provide path\n","  dec_weights = \"/content/drive/MyDrive/Colab Notebooks/ANCIS/Dec_Weights/end_model.pth\" #@param {type: \"string\"}\n","\n","#@markdown ### **B. Detection Test Result Save Path**\n","SAVE_PATH = \"/root/Save/RPN\" #@param {type: \"string\"}\n","if not os.path.exists(SAVE_PATH):\n","  os.makedirs(SAVE_PATH)\n","\n","%cd /content/drive/MyDrive/Colab Notebooks/ANCIS/\n","\n","import argparse\n","\n","from dec_utils import *\n","from models import dec_net\n","from dec_utils import dec_transforms\n","import cv2\n","import matplotlib\n","from matplotlib.pyplot import imshow\n","from dec_utils import dec_transforms, dec_eval, dec_dataset_kaggle\n","from google.colab.patches import cv2_imshow\n","\n","def load_dec_weights(dec_model, dec_weights):\n","    print('Resuming detection weights from {} ...'.format(dec_weights))\n","    dec_dict = torch.load(dec_weights, map_location=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))\n","    dec_dict_update = {}\n","    for k in dec_dict:\n","        if k.startswith('module') and not k.startswith('module_list'):\n","            dec_dict_update[k[7:]] = dec_dict[k]\n","        else:\n","            dec_dict_update[k] = dec_dict[k]\n","    dec_model.load_state_dict(dec_dict_update, strict=True)\n","    return dec_model\n","\n","data_transforms = dec_transforms.Compose([dec_transforms.ConvertImgFloat(),\n","                                    dec_transforms.Resize(M, M),\n","                                    dec_transforms.ToTensor()])\n","\n","dsets = dec_dataset_kaggle.NucleiCell(testDir, annoDir, data_transforms,\n","                    imgSuffix=imgSuffix, annoSuffix=annoSuffix)\n","\n","model = dec_net.resnetssd50(pretrained=True, num_classes=num_classes)\n","model = load_dec_weights(model, weightTst)\n","\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","model.eval()\n","detector = Detect(num_classes=num_classes,\n","                  top_k=top_k,\n","                  conf_thresh=conf_thresh,\n","                  nms_thresh=nms_thresh,\n","                  variance=[0.1, 0.2])\n","anchorGen = Anchors(M, M)\n","anchors = anchorGen.forward()\n","#cv2.namedWindow('img')\n","names = dsets.load_img_ids()\n","print(names)\n","for img_idx in range(len(dsets)):\n","    ori_img = dsets.load_img(img_idx)\n","    h,w,c = ori_img.shape\n","    inputs, gt_bboxes, _ = dsets.__getitem__(img_idx)  # [3, 512, 640], [3, 4], [3, 1]\n","    inputs = inputs.unsqueeze(0).to(device)\n","    ames = names[img_idx]\n","    ame = (os.path.basename(ames))\n","    print(ame)\n","    with torch.no_grad():\n","        locs, conf = model(inputs)\n","    detections = detector(locs, conf, anchors)\n","    for cls_idx in range(1, detections.size(1)):\n","        dets = detections[0, cls_idx, :]\n","        mask = dets[:, 0].gt(0.).expand(5, dets.size(0)).t()\n","        dets = torch.masked_select(dets, mask).view(-1, 5)\n","        if dets.shape[0] == 0:\n","            continue\n","        dets = dets.cpu().numpy()\n","        for i in range(dets.shape[0]):\n","            box = dets[i,1:]\n","            score = dets[i,0]\n","            y1,x1,y2,x2 = box\n","            y1 = float(y1)/M\n","            x1 = float(x1)/M\n","            y2 = float(y2)/M\n","            x2 = float(x2)/M\n","            y1 = int(float(y1)*h)\n","            x1 = int(float(x1)*w)\n","            y2 = int(float(y2)*h)\n","            x2 = int(float(x2)*w)\n","            cv2.rectangle(ori_img, (x1, y1), (x2, y2), (0, 255, 0), 2, 2)\n","            cv2.putText(ori_img, \"%.2f\"%score, (x1, y1 + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6,\n","                        (255, 0, 255))\n","    #imshow(ori_img)\n","    cv2.imwrite(os.path.join(SAVE_PATH, ame), ori_img)\n","    cv2_imshow(ori_img)\n","    #k = cv2.waitKey(0)\n","    #if k & 0xFF == ord('q'):\n","       # cv2.destroyAllWindows()\n","      #  exit()\n","cv2.destroyAllWindows()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rBmNbjb93-Rd"},"source":["# **IV. Instance Segmentation**"]},{"cell_type":"code","metadata":{"id":"zRDR9l3ju5LV","cellView":"form"},"source":["%cd /content/drive/My Drive/Colab Notebooks/ANCIS\n","#@markdown ___\n","#@markdown ## **1. Train Segmentation Network**\n","\n","#@markdown Train the Instance Segmentation Network.  Must either train the detection (region proposal network) first, or upload pretrained weights.\n","#@markdown\n","\n","#@markdown ### **A. Select Detection Network Weights to use for Segmentation Training**\n","DECWEIGHT = 'Tissue' #@param ['Tissue', 'Cell', 'Combine', 'Kaggle', 'Select', 'Drive'] {type: 'string'}\n","if DECWEIGHT == 'Tissue':\n","  dec_weights = \"/content/drive/MyDrive/Colab Notebooks/weights/ANCIS/DecWeights/ANCIS_DecWeight_Tissue/end_model.pth\"\n","elif DECWEIGHT == 'Cell':\n","  dec_weights = \"/content/drive/MyDrive/Colab Notebooks/weights/ANCIS/DecWeights/ANCIS_DecWeight_Cell/end_model.pth\"\n","elif DECWEIGHT == 'Combine':\n","  dec_weights = \"/content/drive/MyDrive/Colab Notebooks/weights/ANCIS/DecWeights/ANCIS_DecWeight_Combine/end_model.pth\"\n","elif DECWEIGHT == 'Kaggle':\n","  dec_weights = \"/content/drive/MyDrive/Colab Notebooks/weights/ANCIS/DecWeights/ANCIS_DecWeight_Kaggle/end_model.pth\"\n","elif DECWEIGHT == 'Select':\n","  weights = files.upload()\n","  for name, data in weights.items():\n","    with open(name, 'wb') as f:\n","      print ('saved file', name)\n","    dec_weights = os.path.join(os.getcwd(), name)\n","elif DECWEIGHT == 'Drive':\n","  #@markdown -- If selecting detection weights stored in the cloud or Drive, provide path\n","  dec_weights = \"/content/drive/MyDrive/Colab Notebooks/ANCIS/Dec_Weights/end_model.pth\" #@param {type: \"string\"}\n","\n","\n","import argparse\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","\n","from seg_utils import *\n","from dec_utils import *\n","from seg_utils import seg_transforms, seg_dataset_kaggle, seg_eval_kaggle\n","\n","from models import dec_net_seg, seg_net\n","import cv2\n","import os\n","parser = argparse.ArgumentParser(description='Detection Training (MultiGPU)')\n","parser.add_argument('--img_height', default=img_height, type=str, help='train image height')\n","parser.add_argument('--img_width', default=img_width, type=str, help='train image width')\n","parser.add_argument('--conf_thresh', default=conf_thresh, type=str, help='Detection Confidence Threshold')\n","parser.add_argument('--seg_thresh', default=seg_thresh, type=str, help='Detection Segmentation Threshold')\n","args = parser.parse_args(\"\")\n","def collater(data):\n","    imgs = []\n","    bboxes = []\n","    labels = []\n","    masks = []\n","    for sample in data:\n","        imgs.append(sample[0])\n","        bboxes.append(sample[1])\n","        labels.append(sample[2])\n","        masks.append(sample[3])\n","    return torch.stack(imgs,0), bboxes, labels, masks\n","\n","def load_dec_weights(dec_model, dec_weights):\n","    print('Resuming detection weights from {} ...'.format(dec_weights))\n","    dec_dict = torch.load(dec_weights)\n","    dec_dict_update = {}\n","    for k in dec_dict:\n","        if k.startswith('module') and not k.startswith('module_list'):\n","            dec_dict_update[k[7:]] = dec_dict[k]\n","        else:\n","            dec_dict_update[k] = dec_dict[k]\n","    dec_model.load_state_dict(dec_dict_update, strict=True)\n","    return dec_model\n","\n","# ................. Training Code .................\n","\n","#-----------------load detection model -------------------------\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","dec_model = dec_net_seg.resnetssd50(pretrained=False, num_classes=num_classes)\n","dec_model = load_dec_weights(dec_model, dec_weights)\n","dec_model = dec_model.to(device)\n","#-------------------------------------------------------------------\n","dec_model.eval()        # detector set to 'evaluation' mode\n","for param in dec_model.parameters():\n","    param.requires_grad = False\n","#-----------------load segmentation model -------------------------\n","seg_model =  seg_net.SEG_NET(num_classes=num_classes)\n","seg_model= seg_model.to(device)\n","##--------------------------------------------------------------\n","data_transforms = {\n","    'train': seg_transforms.Compose([seg_transforms.ConvertImgFloat(),\n","                                      seg_transforms.PhotometricDistort(),\n","                                      seg_transforms.Expand(),\n","                                      seg_transforms.RandomSampleCrop(),\n","                                      seg_transforms.RandomMirror_w(),\n","                                      seg_transforms.RandomMirror_h(),\n","                                      seg_transforms.Resize(img_height, img_width),\n","                                      seg_transforms.ToTensor()]),\n","\n","    'val': seg_transforms.Compose([seg_transforms.ConvertImgFloat(),\n","                                    seg_transforms.Resize(img_height, img_width),\n","                                    seg_transforms.ToTensor()])\n","}\n","\n","\n","dsets = {'train': seg_dataset_kaggle.NucleiCell(trainDir, annoDir, data_transforms['train'],\n","                              imgSuffix=imgSuffix, annoSuffix=annoSuffix),\n","          'val': seg_dataset_kaggle.NucleiCell(valDir, annoDir, data_transforms['val'],\n","                              imgSuffix=imgSuffix, annoSuffix=annoSuffix)}\n","\n","dataloader = torch.utils.data.DataLoader(dsets['train'],\n","                                          batch_size = batch_size,\n","                                          shuffle = True,\n","                                          num_workers = num_workers,\n","                                          collate_fn = collater,\n","                                          pin_memory = True)\n","\n","\n","\n","optimizer = optim.Adam(params=filter(lambda p: p.requires_grad, seg_model.parameters()), lr=init_lr)\n","scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.98, last_epoch=-1)\n","criterion = SEG_loss(height=img_height, width=img_width)\n","\n","\n","if vis:\n","    cv2.namedWindow('img')\n","    for idx in range(len(dsets['train'])):\n","        img, bboxes, labels, masks = dsets['train'].__getitem__(idx)\n","        img = img.numpy().transpose(1, 2, 0).copy()*255\n","        print(img.shape)\n","        bboxes = bboxes.numpy()\n","        labels = labels.numpy()\n","        masks = masks.numpy()\n","        for idx in range(bboxes.shape[0]):\n","            y1, x1, y2, x2 = bboxes[idx,:]\n","            y1 = int(y1)\n","            x1 = int(x1)\n","            y2 = int(y2)\n","            x2 = int(x2)\n","            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 255, 255), 2, lineType=1)\n","            mask = masks[idx, :, :]\n","            img = map_mask_to_image(mask, img, color=np.random.rand(3))\n","        cv2.imshow('img', img)\n","        k = cv2.waitKey(0)\n","        if k & 0xFF == ord('q'):\n","            cv2.destroyAllWindows()\n","            exit()\n","    cv2.destroyAllWindows()\n","\n","# for validation data -----------------------------------\n","detector = Detect(num_classes=num_classes,\n","                  top_k=top_k,\n","                  conf_thresh=conf_thresh,\n","                  nms_thresh=nms_thresh,\n","                  variance=[0.1, 0.2])\n","anchorGen = Anchors(img_height, img_width)\n","anchors = anchorGen.forward()\n","# --------------------------------------------------------\n","train_loss_dict = []\n","ap05_dict = []\n","ap07_dict = []\n","loss2 = 0.5\n","for epoch in range(num_epochs):\n","    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","    print('-' * 10)\n","\n","    for phase in ['train', 'val']:\n","        if phase == 'train':\n","            scheduler.step()\n","            seg_model.train()\n","            running_loss = 0.0\n","            for inputs, bboxes, labels, masks in dataloader:\n","                inputs = inputs.to(device)\n","                with torch.no_grad():\n","                    locs, conf, feat_seg = dec_model(inputs)\n","                    detections = detector(locs, conf, anchors)\n","\n","                optimizer.zero_grad()\n","                with torch.enable_grad():\n","                    outputs = seg_model(detections, feat_seg)\n","                    loss = criterion(outputs, bboxes, labels, masks)\n","                    if loss is None:\n","                        loss = loss2\n","                    else:\n","                        loss2 = loss\n","                        loss.backward()\n","                    optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","\n","            epoch_loss = running_loss / len(dsets[phase])\n","\n","            print('{} Loss: {:.4f}'.format(phase, epoch_loss))\n","            train_loss_dict.append(epoch_loss)\n","            np.savetxt(Seg_log_Files + '/seg_train_loss.txt', train_loss_dict, fmt='%.6f')\n","            if epoch % 50 == 0:\n","                torch.save(seg_model.state_dict(),\n","                            os.path.join(Seg_weight_Dst, '{:d}_{:.4f}_model.pth'.format(epoch, epoch_loss)))\n","            torch.save(seg_model.state_dict(), os.path.join(Seg_weight_Dst, 'end_model.pth'))\n","\n","        else:\n","            if epoch % 50 == 0:\n","                seg_model.eval()   # Set model to evaluate mode\n","                ap_05, ap_07 = seg_eval_kaggle.do_python_eval(dsets=dsets[phase], dec_model=dec_model, seg_model=seg_model,\n","                                                        detector=detector, anchors=anchors, device=device,\n","                                                        args=args, offline=False)\n","                # print('ap05:{:.4f}, ap07:{:.4f}'.format(ap05, ap07))\n","                ap05_dict.append(ap_05)\n","                np.savetxt(Seg_log_Files + '/seg_ap_05.txt', ap05_dict, fmt='%.6f')\n","                ap07_dict.append(ap_07)\n","                np.savetxt(Seg_log_Files + '/seg_ap_07.txt', ap07_dict, fmt='%.6f')\n","\n","print('Finish')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ABb48FjnDoPM","cellView":"form"},"source":["%cd /content/drive/MyDrive/Colab Notebooks/ANCIS/\n","\n","#@markdown ___\n","#@markdown ## **2. Test Segmentation Network**\n","\n","#@markdown Test the Instance Segmentation Network.  \n","#@markdown\n","#@markdown ### **A. Select Segmentation Weights**\n","SEGWEIGHT = 'Tissue' #@param ['Tissue', 'Cell', 'Combine', 'Kaggle', 'Select', 'Drive'] {type: 'string'}\n","if SEGWEIGHT == 'Tissue':\n","  seg_weights = \"/content/drive/MyDrive/Colab Notebooks/weights/ANCIS/SegWeights/ANCIS_SegWeight_Tissue/end_model.pth\"\n","elif SEGWEIGHT == 'Cell':\n","  seg_weights = \"/content/drive/MyDrive/Colab Notebooks/weights/ANCIS/SegWeights/ANCIS_SegWeight_Cell/end_model.pth\"\n","elif SEGWEIGHT == 'Combine':\n","  seg_weights = \"/content/drive/MyDrive/Colab Notebooks/weights/ANCIS/SegWeights/ANCIS_SegWeight_Combine/end_model.pth\"\n","elif SEGWEIGHT == 'Kaggle':\n","  seg_weights = \"/content/drive/MyDrive/Colab Notebooks/weights/ANCIS/SegWeights/ANCIS_SegWeight_Kaggle/end_model.pth\"\n","elif SEGWEIGHT == 'Select':\n","  weights = files.upload()\n","  for name, data in weights.items():\n","    with open(name, 'wb') as f:\n","      print ('saved file', name)\n","    seg_weights = os.path.join(os.getcwd(), name)\n","elif SEGWEIGHT == 'Drive':\n","  #@markdown --- If Selecting segmentation weights stored in the cloud or Drive, provide path\n","  seg_weights = \"/content/drive/MyDrive/Colab Notebooks/ANCIS/Seg_Weights/end_model.pth\" #@param {type: \"string\"}\n","\n","#@markdown ### **B. Select Detection Weights**\n","DECWEIGHT = 'Tissue' #@param ['Tissue', 'Cell', 'Combine', 'Kaggle', 'Select', 'Drive'] {type: 'string'}\n","if DECWEIGHT == 'Tissue':\n","  dec_weights = \"/content/drive/MyDrive/Colab Notebooks/weights/ANCIS/DecWeights/ANCIS_DecWeight_Tissue/end_model.pth\"\n","elif DECWEIGHT == 'Cell':\n","  dec_weights = \"/content/drive/MyDrive/Colab Notebooks/weights/ANCIS/DecWeights/ANCIS_DecWeight_Cell/end_model.pth\"\n","elif DECWEIGHT == 'Combine':\n","  dec_weights = \"/content/drive/MyDrive/Colab Notebooks/weights/ANCIS/DecWeights/ANCIS_DecWeight_Combine/end_model.pth\"\n","elif DECWEIGHT == 'Kaggle':\n","  dec_weights = \"/content/drive/MyDrive/Colab Notebooks/weights/ANCIS/DecWeights/ANCIS_DecWeight_Kaggle/end_model.pth\"\n","elif DECWEIGHT == 'Select':\n","  weights = files.upload()\n","  for name, data in weights.items():\n","    with open(name, 'wb') as f:\n","      print ('saved file', name)\n","    dec_weights = os.path.join(os.getcwd(), name)\n","elif DECWEIGHT == 'Drive':\n","  #@markdown --- If Selecting detection weights stored in the cloud or Drive, provide path\n","  dec_weights = \"/content/drive/MyDrive/Colab Notebooks/ANCIS/Dec_Weights/end_model.pth\" #@param {type: \"string\"}\n","\n","#@markdown ### **C. Segmented Image Save Path**\n","SAVE_PATH = \"/root/Save/Segment\" #@param {type: \"string\"}\n","if not os.path.exists(SAVE_PATH):\n","  os.makedirs(SAVE_PATH)\n","\n","#@markdown ### **D. Conduct Additional Segmentation Post-Processing?**\n","#@markdown *Overlap Removal (experimental)*\n","PROC = True #@param {type: 'boolean'}\n","\n","#@markdown ### **E. Overlay Post-processed Images for Display (requires more time to setup)**\n","OVER = True #@param {type: 'boolean'}\n","\n","if OVER:\n","  !pip install colorspacious\n","  !git clone --quiet https://github.com/taketwo/glasbey.git\n","  import colorspacious\n","  from glasbey import Glasbey\n","  from skimage.color import label2rgb\n","\n","  color = np.array(([1,0,0],[0,1,0],[0,0,1],[1,1,0],[0,1,1],[1,0,1],[1,0.5,0],[0.5,1,0],[0,1,0.5],[0,0.5,1],[1,0,0.5],[0.5,0,1],[1,0.5,0.25],[0.25,0.5,1],[1,0.25,0.5],[0.5,0.25,1],[0.5,1,0.25],[0.25,1,0.5]),np.float32)\n","  gb = Glasbey(base_palette=color, chroma_range = (60,100), no_black=True)\n","  c4 = gb.generate_palette(size=18)\n","  #c4 = gb.load_palette('/content/drive/MyDrive/Colab Notebooks/ANCIS/glasbey/rgb_cam02ucs_lut.npz')\n","  color4 = c4[1:]\n","\n","  def normalized(rgb):\n","    norm=np.zeros((512,512,3),np.float32)\n","    norm_rgb=np.zeros((512,512,3),np.uint8)\n","\n","    b=rgb[:,:,0]\n","    g=rgb[:,:,1]\n","    r=rgb[:,:,2]\n","\n","    sum=b+g+r\n","\n","    norm[:,:,0]=b/sum*255.0\n","    norm[:,:,1]=g/sum*255.0\n","    norm[:,:,2]=r/sum*255.0\n","\n","    norm_rgb=cv2.convertScaleAbs(norm)\n","    return norm_rgb\n","\n","  def overlay(mask, orig, clr):\n","    maskPR = label(mask)\n","    labels = label2rgb(label=maskPR, bg_label=0, bg_color=(0, 0, 0), colors=clr)\n","    L2 = normalized(labels)\n","    if len(orig.shape) < 3: \n","      O2 = cv2.cvtColor(orig.astype('uint8'), cv2.COLOR_GRAY2BGR)\n","    else:\n","      O2 = orig\n","    comb = cv2.addWeighted(L2.astype('float64'),0.5,O2.astype('float64'),0.5,0)\n","    return comb\n","\n","\n","import argparse\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","\n","from seg_utils import *\n","from dec_utils import *\n","from seg_utils import seg_transforms, seg_dataset_kaggle, seg_eval\n","\n","from models import dec_net_seg, seg_net\n","import cv2\n","import os\n","\n","from google.colab.patches import cv2_imshow\n","\n","def load_dec_weights(dec_model, dec_weights):\n","    print('Resuming detection weights from {} ...'.format(dec_weights))\n","    dec_dict = torch.load(dec_weights, map_location=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))\n","    dec_dict_update = {}\n","    for k in dec_dict:\n","        if k.startswith('module') and not k.startswith('module_list'):\n","            dec_dict_update[k[7:]] = dec_dict[k]\n","        else:\n","            dec_dict_update[k] = dec_dict[k]\n","    dec_model.load_state_dict(dec_dict_update, strict=True)\n","    return dec_model\n","\n","#-----------------load detection model -------------------------\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","dec_model = dec_net_seg.resnetssd50(pretrained=False, num_classes=num_classes)\n","dec_model = load_dec_weights(dec_model, dec_weights)\n","dec_model = dec_model.to(device)\n","dec_model.eval()\n","#-----------------load segmentation model -------------------------\n","seg_model =  seg_net.SEG_NET(num_classes=num_classes)\n","seg_model.load_state_dict(torch.load(seg_weights, map_location=torch.device('cpu')))\n","seg_model= seg_model.to(device)\n","seg_model.eval()\n","##--------------------------------------------------------------\n","data_transforms = seg_transforms.Compose([seg_transforms.ConvertImgFloat(),\n","                                    seg_transforms.Resize(img_height, img_width),\n","                                    seg_transforms.ToTensor()])\n","\n","\n","dsets = seg_dataset_kaggle.NucleiCell(testDir, annoDir, data_transforms,\n","                                      imgSuffix=imgSuffix, annoSuffix=annoSuffix)\n","\n","# for validation data -----------------------------------\n","names = dsets.load_img_ids()\n","detector = Detect(num_classes=num_classes,\n","                  top_k=top_k,\n","                  conf_thresh=conf_thresh,\n","                  nms_thresh=nms_thresh,\n","                  variance=[0.1, 0.2])\n","anchorGen = Anchors(img_height, img_width)\n","anchors = anchorGen.forward()\n","if not os.path.exists(SAVE_PATH + '/masks'):\n","    os.makedirs(os.path.join(SAVE_PATH,'masks'))\n","if not os.path.exists(SAVE_PATH + '/seg'):\n","    os.makedirs(os.path.join(SAVE_PATH,'seg'))\n","# for img_idx in [1,55,57,72,78,123]:\n","for img_idx in range(len(dsets)):\n","  print('loading {}/{} image'.format(img_idx, len(dsets)))\n","  inputs, gt_boxes, gt_classes, gt_masks = dsets.__getitem__(img_idx)\n","  ori_img = dsets.load_img(img_idx)\n","  image = ori_img.copy()\n","  #ori_img_copy = ori_img.copy()\n","  #bboxes, labels, masks = dsets.load_annotation(dsets.img_files[img_idx])\n","  #for mask in masks:\n","  #    ori_img = map_mask_to_image(mask, ori_img, color=np.random.rand(3))\n","  h,w,c = ori_img.shape\n","  x = inputs.unsqueeze(0)\n","  x = x.to(device)\n","  locs, conf, feat_seg = dec_model(x)\n","  detections = detector(locs, conf, anchors)\n","  outputs = seg_model(detections, feat_seg)\n","  mask_patches, mask_dets = outputs\n","  ames = names[img_idx]\n","  ame = (os.path.basename(ames))\n","  print(ame)\n","  # For batches\n","  zees = np.zeros([img_height, img_width], dtype='uint8')\n","  maskD = np.zeros([zees.shape[0], zees.shape[1]], dtype='uint8')\n","  diff = np.zeros([zees.shape[0], zees.shape[1]], dtype='uint8')\n","  for b_mask_patches, b_mask_dets in zip(mask_patches, mask_dets):\n","    nd = len(b_mask_dets)\n","    # Step1: rearrange mask_patches and mask_dets\n","    for d in range(nd):\n","      d_mask = np.zeros((img_height, img_width), dtype=np.float32)\n","      d_mask_det = b_mask_dets[d].data.cpu().numpy()\n","      d_mask_patch = b_mask_patches[d].data.cpu().numpy()\n","      d_bbox = d_mask_det[0:4]\n","      d_conf = d_mask_det[4]\n","      d_class = d_mask_det[5]\n","      if d_conf < conf_thresh:\n","        continue\n","      [y1, x1, y2, x2] = d_bbox\n","      y1 = np.maximum(0, np.int32(np.round(y1)))\n","      x1 = np.maximum(0, np.int32(np.round(x1)))\n","      y2 = np.minimum(np.int32(np.round(y2)), img_height - 1)\n","      x2 = np.minimum(np.int32(np.round(x2)), img_width - 1)\n","      d_mask_patch = cv2.resize(d_mask_patch, (x2 - x1 + 1, y2 - y1 + 1))\n","      d_mask_patch = np.where(d_mask_patch >= seg_thresh, 1., 0.)\n","      d_mask[y1:y2 + 1, x1:x2 + 1] = d_mask_patch\n","      d_mask = cv2.resize(d_mask, dsize=(w,h), interpolation=cv2.INTER_NEAREST)\n","      ori_img = map_mask_to_image(d_mask, ori_img, color=np.random.rand(3))\n","      #zees = (d+1)*d_mask + zees\n","\n","      # Additional Post-Processing\n","\n","      #for n in range(0,masks.shape[2]):\n","      if PROC == False:\n","        zees = (d+1)*d_mask + zees\n","      elif PROC == True:\n","        d_mask = d_mask.astype('uint8')\n","        #d_mask[d_mask>0] = 1\n","        M2 = label(d_mask)\n","        props2 = regionprops(M2)\n","        for m in range(0,M2.max()):\n","          if props2[m].area < 750:\n","            M2[M2==props2[m].label] = 0\n","        M2[M2 > 0] = 1\n","        d_mask = M2*d_mask\n","        props2 = regionprops(d_mask)\n","        maskD = maskD + d_mask\n","        if maskD.max() <= 1:\n","          zees = zees + (d+1)*d_mask\n","        else:\n","          try:\n","            diff[maskD > 1] = 1\n","            diff2 = diff.copy()\n","            pd = regionprops(diff)\n","\n","            area2 = props2[0].area \n","            aread = pd[0].area\n","            Vals = diff*zees # Find value of existing region label, under new overlap\n","            vals = Vals[Vals>0] # Not zero\n","            vals = vals[vals != d+1] # Not the current label\n","            vals = list(set(vals)) # Really should only be one left\n","            z2 = np.zeros([img_height, img_width], dtype='uint8')\n","            z2[zees == vals[0]] = 1\n","            props1 = regionprops(z2)\n","            area1 = props1[0].area\n","            div1 = aread/area1\n","            div2 = aread/area2\n","            zees = zees + (d+1)*d_mask\n","\n","            if div1 < 0.15 and div2 < 0.15:\n","              zees[diff > 0] = vals[0]\n","              #zees[zees==d+1] = vals[0]\n","            elif div1 < 0.15 and div2 > 0.15:\n","              zees[diff > 0] = d+1\n","              #zees[zees==vals[0]] = d+1\n","            elif div1 > 0.15 and div2 < 0.15:\n","              zees[diff > 0] = vals[0]\n","              #zees[zees==d+1] = vals[0]\n","            elif div1 > 0.15 and div2 > 0.15 and div1 < 0.6 and div2 < 0.6:\n","              y0, x0 = pd[0].centroid\n","              orientation = pd[0].orientation\n","\n","              x1 = x0 - math.sin(orientation) * 0.55 * pd[0].major_axis_length\n","              y1 = y0 - math.cos(orientation) * 0.55 * pd[0].major_axis_length\n","              x2 = x0 + math.sin(orientation) * 0.55 * pd[0].major_axis_length\n","              y2 = y0 + math.cos(orientation) * 0.55 * pd[0].major_axis_length \n","\n","              cv2.line(diff, (int(x2),int(y2)), (int(x0),int(y0)), (0, 0, 0), thickness=2)\n","              cv2.line(diff, (int(x1),int(y1)), (int(x0),int(y0)), (0, 0, 0), thickness=2)\n","\n","              lbl1 = label(diff)\n","              lbl1 = lbl1.astype('uint8')\n","              cv2.line(lbl1, (int(x2),int(y2)), (int(x0),int(y0)), (1, 1, 1), thickness=2)\n","              cv2.line(lbl1, (int(x1),int(y1)), (int(x0),int(y0)), (1, 1, 1), thickness=2)\n","              lbl2 = lbl1*diff2\n","              zees[lbl2 == 2] = d+1\n","              zees[lbl2 == 1] = vals[0]\n","                                      \n","            elif div1 > 0.6 or div2 > 0.6:\n","              if area1 > area2:\n","                zees[diff > 0] = vals[0]\n","                zees[zees==d+1] = vals[0]\n","              elif area2 > area1:\n","                zees[diff > 0] = d+1\n","                zees[zees==vals[0]] = d+1\n","            \n","          except Exception as e:\n","            print(e)\n","            continue\n","\n","      maskD[maskD > 1] = 1\n","      diff = np.zeros([zees.shape[0], zees.shape[1]], dtype='uint8')\n","\n","  zees = label(zees)\n","  propsz = regionprops(zees)\n","  try:\n","    for m in range(0,zees.max()):\n","      if propsz[m].area < 750:\n","        zees[zees==propsz[m].label] = 0\n","  except Exception as e:\n","    print(e)\n","  #cv2_imshow(ori_img)\n","  if OVER and PROC:\n","    ovr = overlay(zees, image, color4)\n","    cv2_imshow(ovr)\n","  #k = cv2.waitKey(0)\n","  #if k&0xFF==ord('q'):\n","  #    cv2.destroyAllWindows()\n","  #    exit()\n","  #elif k&0xFF==ord('s'):\n","      # cv2.imwrite('kaggle_imgs/{}_ori.png'.format(img_idx), ori_img_copy)\n","  cv2.imwrite(SAVE_PATH + '/masks/' + ame, zees)\n","  if OVER and PROC:\n","    cv2.imwrite(SAVE_PATH + '/seg/' + ame, ovr)\n","  else:\n","    cv2.imwrite(SAVE_PATH + '/seg/' + ame, ori_img)\n","cv2.destroyAllWindows()\n","print('Finish')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jeXTZS3L9KJ7","cellView":"form"},"source":["#@markdown ## **3. Zip and Download Predictions to Local Drive**\n","#@markdown If download does not occur, check if browser is blocking.\n","\n","import shutil\n","\n","output_filename = 'Results' #@param {type: 'string'}\n","dir_name = SAVE_PATH\n","shutil.make_archive(output_filename, 'zip', dir_name, verbose=1)\n","\n","files.download(output_filename + '.zip')"],"execution_count":null,"outputs":[]}]}